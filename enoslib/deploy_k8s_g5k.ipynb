{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a6f19e1",
   "metadata": {},
   "source": [
    "# Importations et Configuration Initiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60918c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING]: failed to patch stdout/stderr for fork-safety: 'OutStream' object\n",
      "has no attribute 'buffer'\n",
      "[WARNING]: failed to reconfigure stdout/stderr with custom encoding error\n",
      "handler: 'OutStream' object has no attribute 'reconfigure'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration initiale chargée.\n"
     ]
    }
   ],
   "source": [
    "import enoslib as en\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# --- Configuration de l'expérience ---\n",
    "\n",
    "# Configurez le logging pour avoir un retour clair sur les étapes\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "\n",
    "G5K_SITE = \"rennes\"  # Site Grid'5000 à utiliser\n",
    "\n",
    "# Nom du job pour la réservation sur Grid'5000\n",
    "JOB_NAME = \"K8sEnoslibDeploy\"\n",
    "\n",
    "# Clé SSH, par défaut enoslib cherche ~/.ssh/id_rsa\n",
    "# Si vous en utilisez une autre, décommentez et modifiez la ligne suivante :\n",
    "# en.set_config(ssh_key=\"~/.ssh/ma_cle_ssh\")\n",
    "\n",
    "# Création du chemin pour les sorties (par exemple, inventaire)\n",
    "Path(\"inventory\").mkdir(exist_ok=True)\n",
    "OUTPUT_INVENTORY = \"inventory/g5k_inventory.yaml\"\n",
    "\n",
    "print(\"Configuration initiale chargée.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95db030d",
   "metadata": {},
   "source": [
    "# Définition des Ressources pour le Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f89826ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Définition des ressources terminée.\n"
     ]
    }
   ],
   "source": [
    "# CELLULE 2\n",
    "# Définition de la configuration pour la connexion à Grid'5000\n",
    "# en.set_provider(\n",
    "#     en.G5k(\n",
    "#         username=G5K_USER,\n",
    "#         site=G5K_SITE,\n",
    "#         job_name=JOB_NAME,\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# Définition des ressources à réserver\n",
    "# 1 nœud master et 2 nœuds workers\n",
    "# Tous les nœuds seront déployés avec Ubuntu 22.04\n",
    "conf = (\n",
    "en.G5kConf.from_settings(\n",
    "    job_name=JOB_NAME,\n",
    "    job_type=[\"deploy\"],\n",
    "    walltime=\"03:30:00\", # Réservez pour 1 heure\n",
    "    env_name=\"ubuntu2204-min\"\n",
    ").add_machine(\n",
    "    roles=[\"master\"],\n",
    "    cluster=\"paradoxe\",\n",
    "    nodes=1\n",
    ").add_machine(\n",
    "    roles=[\"workers\"],\n",
    "    cluster=\"paradoxe\",\n",
    "    nodes=2\n",
    ")\n",
    ")\n",
    "\n",
    "print(\"Définition des ressources terminée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7476000e",
   "metadata": {},
   "source": [
    "# Exécution de la Réservation et du Déploiement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0123a647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:enoslib.log:[G5k] Submitting {'name': 'K8sEnoslibDeploy', 'types': ['deploy'], 'resources': \"{cluster='paradoxe'}/nodes=1+{cluster='paradoxe'}/nodes=2,walltime=03:30:00\", 'command': 'sleep 31536000', 'queue': 'default'} on rennes\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:50:41]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:50:41]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:50:41]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:50:41]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:50:41]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:50:41]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:50:41]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:50:41]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:50:41]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:50:41]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:50:41]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:50:41]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:51:08]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:51:08]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:51:08]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:51:08]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:51:08]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:51:08]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:51:08]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:51:08]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:51:08]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:51:08]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:51:08]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:51:08]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:51:08]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:51:08]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:51:08]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:51:08]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:51:08]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:51:08]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:51:08]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:51:08]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:02]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:02]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:02]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:02]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:02]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:02]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:02]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:02]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:52:24]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:53:42]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:53:42]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:53:42]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:53:42]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:53:42]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:53:42]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:53:42]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:53:42]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:53:42]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:53:42]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:53:42]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:53:42]\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:54:10]\n",
      "INFO:enoslib.log:[G5k] All jobs are Running !\n",
      "INFO:enoslib.log:[G5k] Waiting for 3293355 on rennes [2025-10-09 08:54:10]\n",
      "INFO:enoslib.log:[G5k] All jobs are Running !\n",
      "INFO:enoslib.log:[G5k] Deploy the public key contained in /home/romial/.ssh/id_rsa.pub to remote hosts.\n",
      "INFO:enoslib.log:[G5k] Deploying ['paradoxe-32.rennes.grid5000.fr', 'paradoxe-2.rennes.grid5000.fr', 'paradoxe-27.rennes.grid5000.fr'] with options {'environment': 'ubuntu2204-min', 'key': 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCspk0GLFN8ZdmvEinnrN7rLIOSMvilTypm+ZR5zTzdol5T/5g/vCT1U+jBOaP9y/SCw31+4KOoZoKNQewAdEh7l+5FnfJL2VD1XaLOCo+l6aoNj17nLFeiRvesNYPwPCll5vN6mfA1CDXIhBcEfuJC0wmIM9c6Qz/WFcqhpbdtpjVsz0h+bqX8+45M4Ek4JB55xQL0h1PUK+wrjhyeFPzgq2uEeeHrBAqf4EyQuv6qSkSHcT39HdUnDkJMrO4U5KMLxMbDB6iqPvRTOb7nOSxT0FF71wYRWNLKdqqtMBI0tF6IUiwc0xau0lgNDFUIXEdJCfIrljKRkWZ5mcEienAkq3/1BSW6qNb8NxzGkAkeyPDuHXlwic4guSC6NWt+xasT+Dqr7KlkealL3eKQbf3A3l7Luov4kCz9gWqVlcDnoMsQSg1mpVBkqng4+Udn+bTl4cuwwHjfd+32pjW/wfiVI/X8OXyaWNuUcVRt2EofA2wPmcIdc9PuLjKkB5Bl6lE= romial@PL-DAPI-NA-SALSA-004\\n'} [1/3]\n",
      "INFO:enoslib.log:[G5k] Deploy the public key contained in /home/romial/.ssh/id_rsa.pub to remote hosts.\n",
      "INFO:enoslib.log:[G5k] Deploying ['paradoxe-32.rennes.grid5000.fr', 'paradoxe-2.rennes.grid5000.fr', 'paradoxe-27.rennes.grid5000.fr'] with options {'environment': 'ubuntu2204-min', 'key': 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCspk0GLFN8ZdmvEinnrN7rLIOSMvilTypm+ZR5zTzdol5T/5g/vCT1U+jBOaP9y/SCw31+4KOoZoKNQewAdEh7l+5FnfJL2VD1XaLOCo+l6aoNj17nLFeiRvesNYPwPCll5vN6mfA1CDXIhBcEfuJC0wmIM9c6Qz/WFcqhpbdtpjVsz0h+bqX8+45M4Ek4JB55xQL0h1PUK+wrjhyeFPzgq2uEeeHrBAqf4EyQuv6qSkSHcT39HdUnDkJMrO4U5KMLxMbDB6iqPvRTOb7nOSxT0FF71wYRWNLKdqqtMBI0tF6IUiwc0xau0lgNDFUIXEdJCfIrljKRkWZ5mcEienAkq3/1BSW6qNb8NxzGkAkeyPDuHXlwic4guSC6NWt+xasT+Dqr7KlkealL3eKQbf3A3l7Luov4kCz9gWqVlcDnoMsQSg1mpVBkqng4+Udn+bTl4cuwwHjfd+32pjW/wfiVI/X8OXyaWNuUcVRt2EofA2wPmcIdc9PuLjKkB5Bl6lE= romial@PL-DAPI-NA-SALSA-004\\n'} [1/3]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n",
      "INFO:enoslib.log:[G5k] Waiting for the end of deployment [D-6d4031a1-3b95-42dd-a9ce-ff0ad10cbca2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47a06718be444d6be01ccbaa6cb8c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">Run dhcp on the nodes</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-27.rennes.grid5000.fr'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-32.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mRun dhcp on the nodes\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m, \n",
       "\u001b[32m'paradoxe-27.rennes.grid5000.fr'\u001b[0m, \u001b[32m'paradoxe-32.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Réservation et déploiement terminés ! ---\n",
      "Master: ['paradoxe-2.rennes.grid5000.fr']\n",
      "Workers: ['paradoxe-27.rennes.grid5000.fr', 'paradoxe-32.rennes.grid5000.fr']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "provider = en.G5k(conf)\n",
    "# Démarrage de la réservation et du déploiement\n",
    "# provider.init() bloque jusqu'à ce que les noeuds soient prêts\n",
    "\n",
    "roles, networks = provider.init()\n",
    "\n",
    "# Récupération des informations sur les rôles pour les cellules suivantes\n",
    "#roles = reservation.get_roles()\n",
    "master_node = roles[\"master\"]\n",
    "worker_nodes = roles[\"workers\"]\n",
    "\n",
    "print(\"--- Réservation et déploiement terminés ! ---\")\n",
    "print(f\"Master: {[node.address for node in master_node]}\")\n",
    "print(f\"Workers: {[node.address for node in worker_nodes]}\")\n",
    "#print(f\"Tous les nœuds: roles\" + str(roles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f16248",
   "metadata": {},
   "source": [
    "#  Préparation Commune de Tous les Nœuds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f110227d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3961079113634eeabca1b822747805db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement de la préparation commune...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-27.rennes.grid5000.fr'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-32.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m, \n",
       "\u001b[32m'paradoxe-27.rennes.grid5000.fr'\u001b[0m, \u001b[32m'paradoxe-32.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Préparation commune terminée.\n"
     ]
    }
   ],
   "source": [
    "# Script de configuration commun\n",
    "COMMON_SETUP_SCRIPT = \"\"\"\n",
    "#!/bin/bash -xe\n",
    "sudo apt-get update -y\n",
    "sudo apt-get install -y software-properties-common gpg curl apt-transport-https ca-certificates jq\n",
    "cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf\n",
    "overlay\n",
    "br_netfilter\n",
    "EOF\n",
    "sudo modprobe overlay\n",
    "sudo modprobe br_netfilter\n",
    "cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf\n",
    "net.bridge.bridge-nf-call-iptables  = 1\n",
    "net.bridge.bridge-nf-call-ip6tables = 1\n",
    "net.ipv4.ip_forward                 = 1\n",
    "EOF\n",
    "sudo sysctl --system\n",
    "sudo swapoff -a\n",
    "curl -fsSL https://pkgs.k8s.io/addons:/cri-o:/prerelease:/main/deb/Release.key | gpg --dearmor | sudo tee /etc/apt/keyrings/cri-o-apt-keyring.gpg >/dev/null\n",
    "echo \"deb [signed-by=/etc/apt/keyrings/cri-o-apt-keyring.gpg] https://pkgs.k8s.io/addons:/cri-o:/prerelease:/main/deb/ /\" | sudo tee /etc/apt/sources.list.d/cri-o.list\n",
    "sudo apt-get update -y\n",
    "sudo apt-get install -y cri-o\n",
    "sudo systemctl enable --now crio\n",
    "KUBERNETES_VERSION=\"1.30\"\n",
    "sudo mkdir -p /etc/apt/keyrings\n",
    "curl -fsSL https://pkgs.k8s.io/core:/stable:/v$KUBERNETES_VERSION/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\n",
    "echo \"deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v$KUBERNETES_VERSION/deb/ /\" | sudo tee /etc/apt/sources.list.d/kubernetes.list\n",
    "sudo apt-get update\n",
    "sudo apt-get install -y kubelet=1.30.0-1.1 kubectl=1.30.0-1.1 kubeadm=1.30.0-1.1\n",
    "sudo apt-mark hold kubelet kubeadm kubectl\n",
    "IFACE=$(ip route | grep default | awk '{print $5}')\n",
    "local_ip=$(ip --json addr show $IFACE | jq -r '.[0].addr_info[] | select(.family == \"inet\") | .local')\n",
    "echo \"KUBELET_EXTRA_ARGS=--node-ip=$local_ip\" | sudo tee /etc/default/kubelet\n",
    "\"\"\"\n",
    "\n",
    "# Exécution du script sur tous les nœuds\n",
    "print(\"Lancement de la préparation commune...\")\n",
    "with en.actions(roles=roles) as p:\n",
    "    p.shell(COMMON_SETUP_SCRIPT)\n",
    "print(\"Préparation commune terminée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f18b04e",
   "metadata": {},
   "source": [
    "##  Vérification de la Préparation des Nœuds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f78df3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7beb65574a64035b4f5e67c47c7cab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement de la vérification sur tous les nœuds...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-27.rennes.grid5000.fr'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-32.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m, \n",
       "\u001b[32m'paradoxe-27.rennes.grid5000.fr'\u001b[0m, \u001b[32m'paradoxe-32.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Vérification de l'état des nœuds ---\n",
      "[VÉRIF] Service CRI-O (runtime de conteneurs)...\n",
      "✅ OK: Le service CRI-O est actif.\n",
      "[VÉRIF] Binaires Kubernetes...\n",
      "Kubernetes v1.30.0\n",
      "kubeadm version: &version.Info{Major:\"1\", Minor:\"30\", GitVersion:\"v1.30.0\", GitCommit:\"7c48c2bd72b9bf5c44d21d7338cc7bea77d0ad2a\", GitTreeState:\"clean\", BuildDate:\"2024-04-17T17:34:08Z\", GoVersion:\"go1.22.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n",
      "✅ OK: Les binaires Kubelet et Kubeadm sont installés.\n",
      "[VÉRIF] Modules Kernel...\n",
      "✅ OK: Module 'br_netfilter' est chargé.\n",
      "✅ OK: Module 'overlay' est chargé.\n",
      "\n",
      "🎉 La préparation de ce nœud est validée.\n"
     ]
    }
   ],
   "source": [
    "# Script de vérification (inchangé)\n",
    "VERIFY_PREP_SCRIPT = \"\"\"\n",
    "#!/bin/bash -e\n",
    "echo \"--- Vérification de l'état des nœuds ---\"\n",
    "echo \"[VÉRIF] Service CRI-O (runtime de conteneurs)...\"\n",
    "sudo systemctl is-active --quiet crio\n",
    "echo \"✅ OK: Le service CRI-O est actif.\"\n",
    "echo \"[VÉRIF] Binaires Kubernetes...\"\n",
    "kubelet --version\n",
    "kubeadm version\n",
    "echo \"✅ OK: Les binaires Kubelet et Kubeadm sont installés.\"\n",
    "echo \"[VÉRIF] Modules Kernel...\"\n",
    "lsmod | grep -q br_netfilter && echo \"✅ OK: Module 'br_netfilter' est chargé.\"\n",
    "lsmod | grep -q overlay && echo \"✅ OK: Module 'overlay' est chargé.\"\n",
    "echo \"\\n🎉 La préparation de ce nœud est validée.\"\n",
    "\"\"\"\n",
    "\n",
    "# 1. On exécute les actions (comme avant)\n",
    "print(\"Lancement de la vérification sur tous les nœuds...\")\n",
    "with en.actions(roles=roles) as p:\n",
    "    p.shell(VERIFY_PREP_SCRIPT)\n",
    "\n",
    "results = p.results\n",
    "verify = results[0].stdout.strip()\n",
    "print(verify)\n",
    "# # 2. ✅ NOUVEAU : On récupère et on affiche les résultats APRÈS le bloc\n",
    "# print(\"\\n--- RÉSULTATS DE LA VÉRIFICATION ---\")\n",
    "# results = p.get_results()\n",
    "\n",
    "# # On boucle sur les résultats de chaque machine\n",
    "# for r in results:\n",
    "#     print(f\"\\n======== Nœud: {r.host} ========\")\n",
    "#     print(r.stdout) # Affiche la sortie standard de la commande\n",
    "    \n",
    "#     # Optionnel : Affiche les erreurs s'il y en a\n",
    "#     if r.stderr:\n",
    "#         print(f\"-------- Erreurs (stderr) pour {r.host} --------\")\n",
    "#         print(r.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3926281",
   "metadata": {},
   "source": [
    "#  Initialisation du Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ddc5e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b426259e104016bff2c84e411e412b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/tmp/ipykernel_2127663/3805460087.py:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  MASTER_INIT_SCRIPT = \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisation du master...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisation du master terminée.\n"
     ]
    }
   ],
   "source": [
    "# Script d'initialisation du master\n",
    "MASTER_INIT_SCRIPT = \"\"\"\n",
    "#!/bin/bash -xe\n",
    "IFACE=$(ip route | grep default | awk '{print $5}')\n",
    "IPADDR=$(ip -4 addr show $IFACE | grep -oP '(?<=inet\\s)\\d+(\\.\\d+){3}')\n",
    "NODENAME=$(hostname -s)\n",
    "sudo kubeadm init --pod-network-cidr=192.168.0.0/16 --apiserver-advertise-address=$IPADDR --node-name $NODENAME --cri-socket unix:///var/run/crio/crio.sock --ignore-preflight-errors=Swap\n",
    "mkdir -p $HOME/.kube\n",
    "sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n",
    "sudo chown $(id -u):$(id -g) $HOME/.kube/config\n",
    "kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml\n",
    "\"\"\"\n",
    "\n",
    "# Exécution du script sur le master\n",
    "print(\"Initialisation du master...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(MASTER_INIT_SCRIPT)\n",
    "print(\"Initialisation du master terminée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0079e4de",
   "metadata": {},
   "source": [
    "# Jonction des Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "278b9b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1fbfba3b43f4739b622eaa175fa7d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération de la commande de jonction depuis le master...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017ff80c0980478b981957b3062fd5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Commande de jonction récupérée: kubeadm join 172.16.101.2:6443 --token acfj01.04vq7vqnjiocq73p --discovery-token-ca-cert-hash sha256:4af7abcf28023e0e56ca90bc0fbbb9e6eb3a08b73893408fbb54dd87e0f49260\n",
      "Les workers rejoignent le cluster...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-27.rennes.grid5000.fr'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-32.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-27.rennes.grid5000.fr'\u001b[0m, \n",
       "\u001b[32m'paradoxe-32.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workers joints. Attente de 60s pour la stabilisation...\n"
     ]
    }
   ],
   "source": [
    "# 1. Récupérer la commande de jonction depuis le master\n",
    "print(\"Récupération de la commande de jonction depuis le master...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(\"sudo kubeadm token create --print-join-command\")\n",
    "\n",
    "# Récupération des résultats après le bloc\n",
    "results = p.results\n",
    "join_command = results[0].stdout.strip()\n",
    "print(f\"✅ Commande de jonction récupérée: {join_command}\")\n",
    "\n",
    "# 2. Exécuter la commande sur les workers\n",
    "print(\"Les workers rejoignent le cluster...\")\n",
    "with en.actions(roles=worker_nodes) as p:\n",
    "    p.shell(f\"sudo {join_command}\")\n",
    "\n",
    "print(\"Workers joints. Attente de 60s pour la stabilisation...\")\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a921f89",
   "metadata": {},
   "source": [
    "# Vérification du Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a7195aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226ef14894ab4114a47bc3e9bc29cd20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- État du cluster ---\n",
      "NAME          STATUS   ROLES           AGE   VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION       CONTAINER-RUNTIME\n",
      "paradoxe-2    Ready    control-plane   94s   v1.30.0   172.16.101.2    <none>        Ubuntu 22.04.5 LTS   5.15.0-144-generic   cri-o://1.33.0\n",
      "paradoxe-27   Ready    <none>          73s   v1.30.0   172.16.101.27   <none>        Ubuntu 22.04.5 LTS   5.15.0-144-generic   cri-o://1.33.0\n",
      "paradoxe-32   Ready    <none>          74s   v1.30.0   172.16.101.32   <none>        Ubuntu 22.04.5 LTS   5.15.0-144-generic   cri-o://1.33.0\n"
     ]
    }
   ],
   "source": [
    "# Exécution de kubectl get nodes sur le master pour vérifier\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(\"kubectl get nodes -o wide\")\n",
    "\n",
    "results = p.results\n",
    "nodes = results[0].stdout.strip()\n",
    "print(\"--- État du cluster ---\")\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4524c748",
   "metadata": {},
   "source": [
    " ## Installation des Add-ons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c717bd96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b063e33f0a3e41359a503ea481792ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installation des add-ons sur le nœud master...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Résultat de l'installation ---\n",
      "--- Installation du Metrics Server ---\n",
      "serviceaccount/metrics-server created\n",
      "clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created\n",
      "clusterrole.rbac.authorization.k8s.io/system:metrics-server created\n",
      "rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created\n",
      "service/metrics-server created\n",
      "deployment.apps/metrics-server created\n",
      "apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created\n",
      "\n",
      "--- Installation d'Ingress-NGINX ---\n",
      "namespace/ingress-nginx created\n",
      "serviceaccount/ingress-nginx created\n",
      "serviceaccount/ingress-nginx-admission created\n",
      "role.rbac.authorization.k8s.io/ingress-nginx created\n",
      "role.rbac.authorization.k8s.io/ingress-nginx-admission created\n",
      "clusterrole.rbac.authorization.k8s.io/ingress-nginx created\n",
      "clusterrole.rbac.authorization.k8s.io/ingress-nginx-admission created\n",
      "rolebinding.rbac.authorization.k8s.io/ingress-nginx created\n",
      "rolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created\n",
      "configmap/ingress-nginx-controller created\n",
      "service/ingress-nginx-controller created\n",
      "service/ingress-nginx-controller-admission created\n",
      "deployment.apps/ingress-nginx-controller created\n",
      "job.batch/ingress-nginx-admission-create created\n",
      "job.batch/ingress-nginx-admission-patch created\n",
      "ingressclass.networking.k8s.io/nginx created\n",
      "validatingwebhookconfiguration.admissionregistration.k8s.io/ingress-nginx-admission created\n",
      "\n",
      "Installation des add-ons terminée.\n"
     ]
    }
   ],
   "source": [
    "# Script pour installer les add-ons\n",
    "ADDONS_SCRIPT = \"\"\"\n",
    "#!/bin/bash -e\n",
    "\n",
    "echo \"--- Installation du Metrics Server ---\"\n",
    "kubectl apply -f https://raw.githubusercontent.com/techiescamp/kubeadm-scripts/main/manifests/metrics-server.yaml\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Installation d'Ingress-NGINX ---\"\n",
    "kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.13.0/deploy/static/provider/baremetal/deploy.yaml\n",
    "\n",
    "echo \"\"\n",
    "echo \"Installation des add-ons terminée.\"\n",
    "\"\"\"\n",
    "\n",
    "# Exécution du script sur le master\n",
    "print(\"Installation des add-ons sur le nœud master...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(ADDONS_SCRIPT)\n",
    "\n",
    "# Récupération de la sortie comme vous l'avez spécifié\n",
    "print(\"\\n--- Résultat de l'installation ---\")\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)\n",
    "else:\n",
    "    print(\"Aucun résultat à afficher. Vérifiez les erreurs potentielles.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6b258c",
   "metadata": {},
   "source": [
    "# Déploiement et Test d'une Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33ab194c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d93ee5785b4b8bae65b691ad0df1c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Déploiement de l'application de test...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Résultat du déploiement ---\n",
      "--- Création du Deployment et du Service pour l'application echoserver ---\n",
      "deployment.apps/echoserver created\n",
      "service/echoserver created\n",
      "\n",
      "--- Attente de 15 secondes pour le démarrage des pods ---\n",
      "\n",
      "--- Vérification du statut du déploiement ---\n",
      "NAME         READY   UP-TO-DATE   AVAILABLE   AGE\n",
      "echoserver   2/2     2            2           15s\n",
      "\n",
      "--- Vérification des pods (devrait en afficher 2) ---\n",
      "NAME                         READY   STATUS    RESTARTS   AGE\n",
      "echoserver-d75ff78c5-6lhlp   1/1     Running   0          15s\n",
      "echoserver-d75ff78c5-74rhx   1/1     Running   0          15s\n",
      "\n",
      "--- Vérification du service (notez le port après '80:') ---\n",
      "NAME         TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)        AGE\n",
      "echoserver   NodePort   10.106.4.94   <none>        80:31599/TCP   15s\n"
     ]
    }
   ],
   "source": [
    "# Script pour déployer l'application de test et son service\n",
    "APP_DEPLOY_SCRIPT = \"\"\"\n",
    "#!/bin/bash -e\n",
    "\n",
    "echo \"--- Création du Deployment et du Service pour l'application echoserver ---\"\n",
    "\n",
    "# On utilise un 'heredoc' pour passer le YAML directement à kubectl\n",
    "cat <<EOF | kubectl apply -f -\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: echoserver\n",
    "spec:\n",
    "  replicas: 2\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: echoserver\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: echoserver\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: echoserver\n",
    "        image: registry.k8s.io/echoserver:1.10\n",
    "        ports:\n",
    "        - containerPort: 8080\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: echoserver\n",
    "spec:\n",
    "  type: NodePort\n",
    "  selector:\n",
    "    app: echoserver\n",
    "  ports:\n",
    "  - port: 80\n",
    "    targetPort: 8080\n",
    "EOF\n",
    "\n",
    "echo \"\\n--- Attente de 15 secondes pour le démarrage des pods ---\"\n",
    "sleep 15\n",
    "\n",
    "echo \"\\n--- Vérification du statut du déploiement ---\"\n",
    "kubectl get deployment echoserver\n",
    "\n",
    "echo \"\\n--- Vérification des pods (devrait en afficher 2) ---\"\n",
    "kubectl get pods -l app=echoserver\n",
    "\n",
    "echo \"\\n--- Vérification du service (notez le port après '80:') ---\"\n",
    "kubectl get service echoserver\n",
    "\"\"\"\n",
    "\n",
    "# Exécution du script sur le master\n",
    "print(\"Déploiement de l'application de test...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(APP_DEPLOY_SCRIPT)\n",
    "\n",
    "# Affichage du résultat\n",
    "print(\"\\n--- Résultat du déploiement ---\")\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689c83c8",
   "metadata": {},
   "source": [
    "### Envoyez une Requête"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "558e8487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c1dfc6d1674cdbbafa5d6f53168049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Réponse du serveur ---\n",
      "\n",
      "\n",
      "Hostname: echoserver-d75ff78c5-6lhlp\n",
      "\n",
      "Pod Information:\n",
      "\t-no pod information available-\n",
      "\n",
      "Server values:\n",
      "\tserver_version=nginx: 1.13.3 - lua: 10008\n",
      "\n",
      "Request Information:\n",
      "\tclient_address=192.168.14.128\n",
      "\tmethod=GET\n",
      "\treal path=/\n",
      "\tquery=\n",
      "\trequest_version=1.1\n",
      "\trequest_scheme=http\n",
      "\trequest_uri=http://paradoxe-2.rennes.grid5000.fr:8080/\n",
      "\n",
      "Request Headers:\n",
      "\taccept=*/*\n",
      "\thost=paradoxe-2.rennes.grid5000.fr:31599\n",
      "\tuser-agent=curl/7.81.0\n",
      "\n",
      "Request Body:\n",
      "\t-no body in request-\n"
     ]
    }
   ],
   "source": [
    "# Récupère l'adresse IP du master\n",
    "master_ip = master_node[0].address \n",
    "\n",
    "# Remplacez 31192 par le port que vous avez obtenu à l'étape 1\n",
    "node_port = 31599 # ⚠️ CHANGEZ CE PORT\n",
    "\n",
    "# Test avec curl depuis le master\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(f\"curl http://{master_ip}:{node_port}\")\n",
    "\n",
    "if p.results:\n",
    "    print(\"--- Réponse du serveur ---\")\n",
    "    print(p.results[0].stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4fcd5b",
   "metadata": {},
   "source": [
    "# Installation de la Suite de Monitoring (Prometheus & Grafana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ad67271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee834eb79e7b4915b3fcabb19e619946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement de l'installation de la suite de monitoring...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Résultat de l'installation ---\n",
      "--- Installation de la suite Prometheus + Grafana via kube-prometheus ---\n",
      "Clonage du dépôt kube-prometheus...\n",
      "Étape 1/3 : Application des CRDs et de la configuration 'setup'...\n",
      "customresourcedefinition.apiextensions.k8s.io/alertmanagerconfigs.monitoring.coreos.com serverside-applied\n",
      "customresourcedefinition.apiextensions.k8s.io/alertmanagers.monitoring.coreos.com serverside-applied\n",
      "customresourcedefinition.apiextensions.k8s.io/podmonitors.monitoring.coreos.com serverside-applied\n",
      "customresourcedefinition.apiextensions.k8s.io/probes.monitoring.coreos.com serverside-applied\n",
      "customresourcedefinition.apiextensions.k8s.io/prometheuses.monitoring.coreos.com serverside-applied\n",
      "customresourcedefinition.apiextensions.k8s.io/prometheusagents.monitoring.coreos.com serverside-applied\n",
      "customresourcedefinition.apiextensions.k8s.io/prometheusrules.monitoring.coreos.com serverside-applied\n",
      "customresourcedefinition.apiextensions.k8s.io/scrapeconfigs.monitoring.coreos.com serverside-applied\n",
      "customresourcedefinition.apiextensions.k8s.io/servicemonitors.monitoring.coreos.com serverside-applied\n",
      "customresourcedefinition.apiextensions.k8s.io/thanosrulers.monitoring.coreos.com serverside-applied\n",
      "namespace/monitoring serverside-applied\n",
      "Attente de l'établissement des CRDs...\n",
      "customresourcedefinition.apiextensions.k8s.io/alertmanagerconfigs.monitoring.coreos.com condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/alertmanagers.monitoring.coreos.com condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/caliconodestatuses.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/ipreservations.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/kubecontrollersconfigurations.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/podmonitors.monitoring.coreos.com condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/probes.monitoring.coreos.com condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/prometheusagents.monitoring.coreos.com condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/prometheuses.monitoring.coreos.com condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/prometheusrules.monitoring.coreos.com condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/scrapeconfigs.monitoring.coreos.com condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/servicemonitors.monitoring.coreos.com condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/thanosrulers.monitoring.coreos.com condition met\n",
      "Étape 2/3 : Application des manifestes de la suite de monitoring...\n",
      "alertmanager.monitoring.coreos.com/main created\n",
      "networkpolicy.networking.k8s.io/alertmanager-main created\n",
      "poddisruptionbudget.policy/alertmanager-main created\n",
      "prometheusrule.monitoring.coreos.com/alertmanager-main-rules created\n",
      "secret/alertmanager-main created\n",
      "service/alertmanager-main created\n",
      "serviceaccount/alertmanager-main created\n",
      "servicemonitor.monitoring.coreos.com/alertmanager-main created\n",
      "clusterrole.rbac.authorization.k8s.io/blackbox-exporter created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/blackbox-exporter created\n",
      "configmap/blackbox-exporter-configuration created\n",
      "deployment.apps/blackbox-exporter created\n",
      "networkpolicy.networking.k8s.io/blackbox-exporter created\n",
      "service/blackbox-exporter created\n",
      "serviceaccount/blackbox-exporter created\n",
      "servicemonitor.monitoring.coreos.com/blackbox-exporter created\n",
      "secret/grafana-config created\n",
      "secret/grafana-datasources created\n",
      "configmap/grafana-dashboard-alertmanager-overview created\n",
      "configmap/grafana-dashboard-apiserver created\n",
      "configmap/grafana-dashboard-cluster-total created\n",
      "configmap/grafana-dashboard-controller-manager created\n",
      "configmap/grafana-dashboard-grafana-overview created\n",
      "configmap/grafana-dashboard-k8s-resources-cluster created\n",
      "configmap/grafana-dashboard-k8s-resources-multicluster created\n",
      "configmap/grafana-dashboard-k8s-resources-namespace created\n",
      "configmap/grafana-dashboard-k8s-resources-node created\n",
      "configmap/grafana-dashboard-k8s-resources-pod created\n",
      "configmap/grafana-dashboard-k8s-resources-windows-cluster created\n",
      "configmap/grafana-dashboard-k8s-resources-windows-namespace created\n",
      "configmap/grafana-dashboard-k8s-resources-windows-pod created\n",
      "configmap/grafana-dashboard-k8s-resources-workload created\n",
      "configmap/grafana-dashboard-k8s-resources-workloads-namespace created\n",
      "configmap/grafana-dashboard-k8s-windows-cluster-rsrc-use created\n",
      "configmap/grafana-dashboard-k8s-windows-node-rsrc-use created\n",
      "configmap/grafana-dashboard-kubelet created\n",
      "configmap/grafana-dashboard-namespace-by-pod created\n",
      "configmap/grafana-dashboard-namespace-by-workload created\n",
      "configmap/grafana-dashboard-node-cluster-rsrc-use created\n",
      "configmap/grafana-dashboard-node-rsrc-use created\n",
      "configmap/grafana-dashboard-nodes-aix created\n",
      "configmap/grafana-dashboard-nodes-darwin created\n",
      "configmap/grafana-dashboard-nodes created\n",
      "configmap/grafana-dashboard-persistentvolumesusage created\n",
      "configmap/grafana-dashboard-pod-total created\n",
      "configmap/grafana-dashboard-prometheus-remote-write created\n",
      "configmap/grafana-dashboard-prometheus created\n",
      "configmap/grafana-dashboard-proxy created\n",
      "configmap/grafana-dashboard-scheduler created\n",
      "configmap/grafana-dashboard-workload-total created\n",
      "configmap/grafana-dashboards created\n",
      "deployment.apps/grafana created\n",
      "networkpolicy.networking.k8s.io/grafana created\n",
      "prometheusrule.monitoring.coreos.com/grafana-rules created\n",
      "service/grafana created\n",
      "serviceaccount/grafana created\n",
      "servicemonitor.monitoring.coreos.com/grafana created\n",
      "prometheusrule.monitoring.coreos.com/kube-prometheus-rules created\n",
      "clusterrole.rbac.authorization.k8s.io/kube-state-metrics created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/kube-state-metrics created\n",
      "deployment.apps/kube-state-metrics created\n",
      "networkpolicy.networking.k8s.io/kube-state-metrics created\n",
      "prometheusrule.monitoring.coreos.com/kube-state-metrics-rules created\n",
      "service/kube-state-metrics created\n",
      "serviceaccount/kube-state-metrics created\n",
      "servicemonitor.monitoring.coreos.com/kube-state-metrics created\n",
      "prometheusrule.monitoring.coreos.com/kubernetes-monitoring-rules created\n",
      "servicemonitor.monitoring.coreos.com/kube-apiserver created\n",
      "servicemonitor.monitoring.coreos.com/coredns created\n",
      "servicemonitor.monitoring.coreos.com/kube-controller-manager created\n",
      "servicemonitor.monitoring.coreos.com/kube-scheduler created\n",
      "servicemonitor.monitoring.coreos.com/kubelet created\n",
      "clusterrole.rbac.authorization.k8s.io/node-exporter created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/node-exporter created\n",
      "daemonset.apps/node-exporter created\n",
      "networkpolicy.networking.k8s.io/node-exporter created\n",
      "prometheusrule.monitoring.coreos.com/node-exporter-rules created\n",
      "service/node-exporter created\n",
      "serviceaccount/node-exporter created\n",
      "servicemonitor.monitoring.coreos.com/node-exporter created\n",
      "clusterrole.rbac.authorization.k8s.io/prometheus-k8s created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/prometheus-k8s created\n",
      "networkpolicy.networking.k8s.io/prometheus-k8s created\n",
      "poddisruptionbudget.policy/prometheus-k8s created\n",
      "prometheus.monitoring.coreos.com/k8s created\n",
      "prometheusrule.monitoring.coreos.com/prometheus-k8s-prometheus-rules created\n",
      "rolebinding.rbac.authorization.k8s.io/prometheus-k8s-config created\n",
      "rolebinding.rbac.authorization.k8s.io/prometheus-k8s created\n",
      "rolebinding.rbac.authorization.k8s.io/prometheus-k8s created\n",
      "rolebinding.rbac.authorization.k8s.io/prometheus-k8s created\n",
      "role.rbac.authorization.k8s.io/prometheus-k8s-config created\n",
      "role.rbac.authorization.k8s.io/prometheus-k8s created\n",
      "role.rbac.authorization.k8s.io/prometheus-k8s created\n",
      "role.rbac.authorization.k8s.io/prometheus-k8s created\n",
      "service/prometheus-k8s created\n",
      "serviceaccount/prometheus-k8s created\n",
      "servicemonitor.monitoring.coreos.com/prometheus-k8s created\n",
      "apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io configured\n",
      "clusterrole.rbac.authorization.k8s.io/prometheus-adapter created\n",
      "clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader configured\n",
      "clusterrolebinding.rbac.authorization.k8s.io/prometheus-adapter created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/resource-metrics:system:auth-delegator created\n",
      "clusterrole.rbac.authorization.k8s.io/resource-metrics-server-resources created\n",
      "configmap/adapter-config created\n",
      "deployment.apps/prometheus-adapter created\n",
      "networkpolicy.networking.k8s.io/prometheus-adapter created\n",
      "poddisruptionbudget.policy/prometheus-adapter created\n",
      "rolebinding.rbac.authorization.k8s.io/resource-metrics-auth-reader created\n",
      "service/prometheus-adapter created\n",
      "serviceaccount/prometheus-adapter created\n",
      "servicemonitor.monitoring.coreos.com/prometheus-adapter created\n",
      "clusterrole.rbac.authorization.k8s.io/prometheus-operator created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/prometheus-operator created\n",
      "deployment.apps/prometheus-operator created\n",
      "networkpolicy.networking.k8s.io/prometheus-operator created\n",
      "prometheusrule.monitoring.coreos.com/prometheus-operator-rules created\n",
      "service/prometheus-operator created\n",
      "serviceaccount/prometheus-operator created\n",
      "servicemonitor.monitoring.coreos.com/prometheus-operator created\n",
      "Étape 3/3 : Attente du démarrage de Prometheus et Grafana (peut prendre quelques minutes)...\n",
      "deployment.apps/grafana condition met\n",
      "\n",
      "--- Vérification des pods dans le namespace 'monitoring' ---\n",
      "NAME                                   READY   STATUS            RESTARTS   AGE\n",
      "alertmanager-main-0                    2/2     Running           0          24s\n",
      "alertmanager-main-1                    0/2     PodInitializing   0          24s\n",
      "alertmanager-main-2                    0/2     PodInitializing   0          24s\n",
      "blackbox-exporter-77966b4779-4vcd8     3/3     Running           0          41s\n",
      "grafana-5997747455-tb8vf               1/1     Running           0          41s\n",
      "kube-state-metrics-756cd6cb9d-4qzx2    3/3     Running           0          40s\n",
      "node-exporter-72zzp                    2/2     Running           0          40s\n",
      "node-exporter-flvhj                    2/2     Running           0          40s\n",
      "node-exporter-jjprp                    2/2     Running           0          40s\n",
      "prometheus-adapter-5794d7d9f5-fmqbd    1/1     Running           0          40s\n",
      "prometheus-adapter-5794d7d9f5-kz5r4    1/1     Running           0          40s\n",
      "prometheus-k8s-0                       0/2     Init:0/1          0          24s\n",
      "prometheus-k8s-1                       0/2     PodInitializing   0          24s\n",
      "prometheus-operator-56fd964fb9-c7tj9   2/2     Running           0          40s\n",
      "\n",
      "🎉 Suite de monitoring Prometheus et Grafana installée avec succès !\n"
     ]
    }
   ],
   "source": [
    "# Script pour déployer la suite de monitoring\n",
    "MONITORING_SCRIPT = \"\"\"\n",
    "#!/bin/bash -e\n",
    "\n",
    "echo \"--- Installation de la suite Prometheus + Grafana via kube-prometheus ---\"\n",
    "\n",
    "# 1. Cloner le dépôt qui contient les manifestes\n",
    "if [ ! -d \"kube-prometheus\" ]; then\n",
    "    echo \"Clonage du dépôt kube-prometheus...\"\n",
    "    git clone https://github.com/prometheus-operator/kube-prometheus.git\n",
    "else\n",
    "    echo \"Dépôt kube-prometheus déjà présent.\"\n",
    "fi\n",
    "cd kube-prometheus\n",
    "\n",
    "# 2. Appliquer les définitions de ressources (CRDs) et la configuration de base\n",
    "echo \"Étape 1/3 : Application des CRDs et de la configuration 'setup'...\"\n",
    "kubectl apply --server-side -f manifests/setup\n",
    "\n",
    "# Attendre que les CRDs soient bien enregistrés dans le cluster avant de continuer\n",
    "echo \"Attente de l'établissement des CRDs...\"\n",
    "kubectl wait --for condition=Established --all CustomResourceDefinition --timeout=300s\n",
    "\n",
    "# 3. Appliquer le reste de la suite (Prometheus, Grafana, Alertmanager, etc.)\n",
    "echo \"Étape 2/3 : Application des manifestes de la suite de monitoring...\"\n",
    "kubectl apply -f manifests/\n",
    "\n",
    "# 4. Attendre que les déploiements clés soient prêts dans le namespace 'monitoring'\n",
    "echo \"Étape 3/3 : Attente du démarrage de Prometheus et Grafana (peut prendre quelques minutes)...\"\n",
    "kubectl wait --for=condition=available deployment/prometheus-k8s -n monitoring --timeout=300s\n",
    "kubectl wait --for=condition=available deployment/grafana -n monitoring --timeout=300s\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification des pods dans le namespace 'monitoring' ---\"\n",
    "kubectl get pods -n monitoring\n",
    "\n",
    "echo \"\\n🎉 Suite de monitoring Prometheus et Grafana installée avec succès !\"\n",
    "\"\"\"\n",
    "\n",
    "# Exécution du script sur le master\n",
    "print(\"Lancement de l'installation de la suite de monitoring...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(MONITORING_SCRIPT)\n",
    "\n",
    "# Affichage du résultat\n",
    "print(\"\\n--- Résultat de l'installation ---\")\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43e8a1d",
   "metadata": {},
   "source": [
    "## Vérification des Composants de Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5812a18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dffcaf5a61cf41869c1fa61b3e456582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération de l'état des composants de monitoring...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pods dans le namespace 'monitoring' ---\n",
      "NAME                                   READY   STATUS    RESTARTS   AGE   IP              NODE          NOMINATED NODE   READINESS GATES\n",
      "alertmanager-main-0                    2/2     Running   0          36s   192.168.25.71   paradoxe-32   <none>           <none>\n",
      "alertmanager-main-1                    2/2     Running   0          36s   192.168.152.7   paradoxe-27   <none>           <none>\n",
      "alertmanager-main-2                    2/2     Running   0          36s   192.168.152.6   paradoxe-27   <none>           <none>\n",
      "blackbox-exporter-77966b4779-4vcd8     3/3     Running   0          53s   192.168.152.2   paradoxe-27   <none>           <none>\n",
      "grafana-5997747455-tb8vf               1/1     Running   0          53s   192.168.25.69   paradoxe-32   <none>           <none>\n",
      "kube-state-metrics-756cd6cb9d-4qzx2    3/3     Running   0          52s   192.168.152.3   paradoxe-27   <none>           <none>\n",
      "node-exporter-72zzp                    2/2     Running   0          52s   172.16.101.27   paradoxe-27   <none>           <none>\n",
      "node-exporter-flvhj                    2/2     Running   0          52s   172.16.101.2    paradoxe-2    <none>           <none>\n",
      "node-exporter-jjprp                    2/2     Running   0          52s   172.16.101.32   paradoxe-32   <none>           <none>\n",
      "prometheus-adapter-5794d7d9f5-fmqbd    1/1     Running   0          52s   192.168.152.4   paradoxe-27   <none>           <none>\n",
      "prometheus-adapter-5794d7d9f5-kz5r4    1/1     Running   0          52s   192.168.25.70   paradoxe-32   <none>           <none>\n",
      "prometheus-k8s-0                       1/2     Running   0          36s   192.168.152.8   paradoxe-27   <none>           <none>\n",
      "prometheus-k8s-1                       2/2     Running   0          36s   192.168.25.72   paradoxe-32   <none>           <none>\n",
      "prometheus-operator-56fd964fb9-c7tj9   2/2     Running   0          52s   192.168.152.5   paradoxe-27   <none>           <none>\n",
      "\n",
      "--- Services dans le namespace 'monitoring' ---\n",
      "NAME                    TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE\n",
      "alertmanager-main       ClusterIP   10.96.163.14     <none>        9093/TCP,8080/TCP            54s\n",
      "alertmanager-operated   ClusterIP   None             <none>        9093/TCP,9094/TCP,9094/UDP   36s\n",
      "blackbox-exporter       ClusterIP   10.106.77.229    <none>        9115/TCP,19115/TCP           54s\n",
      "grafana                 ClusterIP   10.108.116.26    <none>        3000/TCP                     53s\n",
      "kube-state-metrics      ClusterIP   None             <none>        8443/TCP,9443/TCP            53s\n",
      "node-exporter           ClusterIP   None             <none>        9100/TCP                     52s\n",
      "prometheus-adapter      ClusterIP   10.102.173.102   <none>        443/TCP                      52s\n",
      "prometheus-k8s          ClusterIP   10.96.111.244    <none>        9090/TCP,8080/TCP            52s\n",
      "prometheus-operated     ClusterIP   None             <none>        9090/TCP                     36s\n",
      "prometheus-operator     ClusterIP   None             <none>        8443/TCP                     52s\n",
      "\n",
      "--- ServiceAccounts dans le namespace 'monitoring' ---\n",
      "NAME                  SECRETS   AGE\n",
      "alertmanager-main     0         54s\n",
      "blackbox-exporter     0         53s\n",
      "default               0         63s\n",
      "grafana               0         53s\n",
      "kube-state-metrics    0         53s\n",
      "node-exporter         0         52s\n",
      "prometheus-adapter    0         52s\n",
      "prometheus-k8s        0         52s\n",
      "prometheus-operator   0         52s\n"
     ]
    }
   ],
   "source": [
    "# Script pour lister les pods et services de monitoring\n",
    "VERIFY_MONITORING_SCRIPT = \"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "echo \"--- Pods dans le namespace 'monitoring' ---\"\n",
    "kubectl get pods -n monitoring -o wide\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Services dans le namespace 'monitoring' ---\"\n",
    "kubectl get services -n monitoring\n",
    "echo \"\"\n",
    "echo \"--- ServiceAccounts dans le namespace 'monitoring' ---\"\n",
    "kubectl get serviceaccounts -n monitoring\n",
    "\"\"\"\n",
    "\n",
    "# Exécution du script de vérification sur le master\n",
    "print(\"Récupération de l'état des composants de monitoring...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(VERIFY_MONITORING_SCRIPT)\n",
    "\n",
    "# Affichage du résultat\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab78fdd",
   "metadata": {},
   "source": [
    "## Mise à Jour des NetworkPolicies pour l'Accès Externe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34266c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba73732b5174d08a86c72c70176a9e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mise à jour des NetworkPolicies...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Mise à jour de la NetworkPolicy de Grafana ---\n",
      "networkpolicy.networking.k8s.io/grafana configured\n",
      "\n",
      "--- 2. Mise à jour de la NetworkPolicy de Prometheus ---\n",
      "networkpolicy.networking.k8s.io/prometheus-k8s configured\n",
      "\n",
      "NetworkPolicies mises à jour avec succès pour autoriser l'accès externe.\n"
     ]
    }
   ],
   "source": [
    "# Script pour mettre à jour les NetworkPolicies\n",
    "UPDATE_NP_SCRIPT = \"\"\"\n",
    "#!/bin/bash -e\n",
    "\n",
    "echo \"--- 1. Mise à jour de la NetworkPolicy de Grafana ---\"\n",
    "cat <<EOF | kubectl apply -f -\n",
    "apiVersion: networking.k8s.io/v1\n",
    "kind: NetworkPolicy\n",
    "metadata:\n",
    "  name: grafana\n",
    "  namespace: monitoring\n",
    "  labels:\n",
    "    app.kubernetes.io/component: grafana\n",
    "    app.kubernetes.io/name: grafana\n",
    "    app.kubernetes.io/part-of: kube-prometheus\n",
    "    app.kubernetes.io/version: 12.2.0\n",
    "spec:\n",
    "  podSelector:\n",
    "    matchLabels:\n",
    "      app.kubernetes.io/component: grafana\n",
    "      app.kubernetes.io/name: grafana\n",
    "      app.kubernetes.io/part-of: kube-prometheus\n",
    "  policyTypes:\n",
    "  - Ingress\n",
    "  - Egress\n",
    "  ingress:\n",
    "  - from:\n",
    "    # On autorise le trafic depuis n'importe quelle adresse IP (externe/interne)\n",
    "    - ipBlock:\n",
    "        cidr: 0.0.0.0/0\n",
    "    # On garde la règle existante qui autorise Prometheus\n",
    "    - podSelector:\n",
    "        matchLabels:\n",
    "          app.kubernetes.io/name: prometheus\n",
    "    ports:\n",
    "    - port: 3000\n",
    "      protocol: TCP\n",
    "  egress:\n",
    "  - {}\n",
    "EOF\n",
    "\n",
    "echo \"\\n--- 2. Mise à jour de la NetworkPolicy de Prometheus ---\"\n",
    "cat <<EOF | kubectl apply -f -\n",
    "apiVersion: networking.k8s.io/v1\n",
    "kind: NetworkPolicy\n",
    "metadata:\n",
    "  name: prometheus-k8s\n",
    "  namespace: monitoring\n",
    "  labels:\n",
    "    app.kubernetes.io/component: prometheus\n",
    "    app.kubernetes.io/instance: k8s\n",
    "    app.kubernetes.io/name: prometheus\n",
    "    app.kubernetes.io/part-of: kube-prometheus\n",
    "    app.kubernetes.io/version: 3.6.0\n",
    "spec:\n",
    "  podSelector:\n",
    "    matchLabels:\n",
    "      app.kubernetes.io/component: prometheus\n",
    "      app.kubernetes.io/instance: k8s\n",
    "      app.kubernetes.io/name: prometheus\n",
    "      app.kubernetes.io/part-of: kube-prometheus\n",
    "  policyTypes:\n",
    "  - Ingress\n",
    "  - Egress\n",
    "  ingress:\n",
    "  - from:\n",
    "    # On autorise le trafic depuis n'importe quelle adresse IP\n",
    "    - ipBlock:\n",
    "        cidr: 0.0.0.0/0\n",
    "    # On garde les règles existantes pour la communication interne\n",
    "    - namespaceSelector: {}\n",
    "    - podSelector:\n",
    "        matchLabels:\n",
    "          app.kubernetes.io/name: prometheus\n",
    "    - podSelector:\n",
    "        matchLabels:\n",
    "          app.kubernetes.io/name: prometheus-adapter\n",
    "    - podSelector:\n",
    "        matchLabels:\n",
    "          app.kubernetes.io/name: grafana\n",
    "    ports:\n",
    "    - port: 9090\n",
    "      protocol: TCP\n",
    "    - port: 8080\n",
    "      protocol: TCP\n",
    "  egress:\n",
    "  - {}\n",
    "EOF\n",
    "\n",
    "echo \"\\nNetworkPolicies mises à jour avec succès pour autoriser l'accès externe.\"\n",
    "\"\"\"\n",
    "\n",
    "# Exécution du script sur le master\n",
    "print(\"Mise à jour des NetworkPolicies...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(UPDATE_NP_SCRIPT)\n",
    "\n",
    "# Affichage du résultat\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0306d0cb",
   "metadata": {},
   "source": [
    "## Passage des Services en NodePort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d4963c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3786d7f41df451e846c570226d9a720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch des services Grafana et Prometheus en NodePort...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Résultat de la commande patch ---\n",
      "--- 1. Modification du service Grafana en type NodePort ---\n",
      "service/grafana patched\n",
      "\n",
      "--- 2. Modification du service Prometheus en type NodePort ---\n",
      "service/prometheus-k8s patched\n",
      "\n",
      "--- 3. Vérification du résultat ---\n",
      "NAME                    TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                         AGE\n",
      "alertmanager-main       ClusterIP   10.96.163.14     <none>        9093/TCP,8080/TCP               79s\n",
      "alertmanager-operated   ClusterIP   None             <none>        9093/TCP,9094/TCP,9094/UDP      61s\n",
      "blackbox-exporter       ClusterIP   10.106.77.229    <none>        9115/TCP,19115/TCP              79s\n",
      "grafana                 NodePort    10.108.116.26    <none>        3000:30574/TCP                  78s\n",
      "kube-state-metrics      ClusterIP   None             <none>        8443/TCP,9443/TCP               78s\n",
      "node-exporter           ClusterIP   None             <none>        9100/TCP                        77s\n",
      "prometheus-adapter      ClusterIP   10.102.173.102   <none>        443/TCP                         77s\n",
      "prometheus-k8s          NodePort    10.96.111.244    <none>        9090:31133/TCP,8080:30248/TCP   77s\n",
      "prometheus-operated     ClusterIP   None             <none>        9090/TCP                        61s\n",
      "prometheus-operator     ClusterIP   None             <none>        8443/TCP                        77s\n"
     ]
    }
   ],
   "source": [
    "# Script pour patcher les services en NodePort\n",
    "PATCH_SERVICES_SCRIPT = \"\"\"\n",
    "#!/bin/bash -e\n",
    "\n",
    "echo \"--- 1. Modification du service Grafana en type NodePort ---\"\n",
    "kubectl patch service grafana -n monitoring -p '{\"spec\": {\"type\": \"NodePort\"}}'\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 2. Modification du service Prometheus en type NodePort ---\"\n",
    "kubectl patch service prometheus-k8s -n monitoring -p '{\"spec\": {\"type\": \"NodePort\"}}'\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 3. Vérification du résultat ---\"\n",
    "# Petite pause pour s'assurer que l'API server a bien traité les changements\n",
    "sleep 2\n",
    "kubectl get services -n monitoring\n",
    "\"\"\"\n",
    "\n",
    "# Exécution du script sur le master\n",
    "print(\"Patch des services Grafana et Prometheus en NodePort...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(PATCH_SERVICES_SCRIPT)\n",
    "\n",
    "# Affichage du résultat\n",
    "print(\"\\n--- Résultat de la commande patch ---\")\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586d17f3",
   "metadata": {},
   "source": [
    "#  Installation de Kepler pour le Monitoring Énergétique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dadaf99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a85d2a1ff634c5da073f6528971ab4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le script d'installation final a été sauvegardé dans 'install_kepler.sh'.\n",
      "Lancement de la mise à jour de Kepler...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">script</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-7.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mscript\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-7.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helm non trouvé. Installation de Helm...\n",
      "Downloading https://get.helm.sh/helm-v3.19.0-linux-amd64.tar.gz\n",
      "Verifying checksum... Done.\n",
      "Preparing to install helm into /usr/local/bin\n",
      "helm installed into /usr/local/bin/helm\n",
      "\n",
      "--- Ajout et mise à jour du dépôt Helm de Kepler ---\n",
      "\"kepler\" has been added to your repositories\n",
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Successfully got an update from the \"kepler\" chart repository\n",
      "Update Complete. ⎈Happy Helming!⎈\n",
      "\n",
      "--- Déploiement/Mise à jour de Kepler dans le namespace 'kepler' ---\n",
      "Release \"kepler\" does not exist. Installing it now.\n",
      "NAME: kepler\n",
      "LAST DEPLOYED: Wed Oct  8 13:16:50 2025\n",
      "NAMESPACE: kepler\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "\n",
      "--- Attente des composants Kepler ---\n",
      "pod/kepler-6hnl6 condition met\n",
      "pod/kepler-j5w5h condition met\n",
      "pod/kepler-jzgl9 condition met\n",
      "\n",
      "--- Vérification des pods Kepler ---\n",
      "NAME           READY   STATUS    RESTARTS   AGE\n",
      "kepler-6hnl6   1/1     Running   0          21s\n",
      "kepler-j5w5h   1/1     Running   0          21s\n",
      "kepler-jzgl9   1/1     Running   0          21s\n",
      "\n",
      "--- Vérification que le ServiceMonitor a bien été créé ---\n",
      "NAME                         AGE\n",
      "kepler-prometheus-exporter   21s\n",
      "--- Vérification que le service est bien de type NodePort ---\n",
      "NAME     TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE\n",
      "kepler   NodePort   10.101.151.180   <none>        9102:32340/TCP   21s\n",
      "\n",
      "🎉 Kepler est maintenant correctement configuré avec un ServiceMonitor et un NodePort !\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Script mis à jour avec le bon paramètre pour le ServiceMonitor\n",
    "INSTALL_KEPLER_SCRIPT = \"\"\"\n",
    "#!/bin/bash -e\n",
    "\n",
    "# --- 1. Installation de Helm (si non présent) ---\n",
    "if ! command -v helm &> /dev/null\n",
    "then\n",
    "    echo \"Helm non trouvé. Installation de Helm...\"\n",
    "    curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3\n",
    "    chmod 700 get_helm.sh\n",
    "    ./get_helm.sh\n",
    "else\n",
    "    echo \"Helm est déjà installé.\"\n",
    "fi\n",
    "\n",
    "# --- 2. Ajout du dépôt Helm de Kepler ---\n",
    "echo \"\"\n",
    "echo \"--- Ajout et mise à jour du dépôt Helm de Kepler ---\"\n",
    "helm repo add kepler https://sustainable-computing-io.github.io/kepler-helm-chart\n",
    "helm repo update\n",
    "\n",
    "# --- 3. Installation ou Mise à Jour de Kepler ---\n",
    "echo \"\"\n",
    "echo \"--- Déploiement/Mise à jour de Kepler dans le namespace 'kepler' ---\"\n",
    "# CORRECTION : On utilise 'serviceMonitor.enabled=true'\n",
    "helm upgrade --install kepler kepler/kepler --namespace kepler --create-namespace \\\n",
    "    --set serviceMonitor.enabled=true \\\n",
    "    --set service.type=NodePort\n",
    "\n",
    "# --- 4. Vérification de l'installation ---\n",
    "echo \"\"\n",
    "echo \"--- Attente des composants Kepler ---\"\n",
    "kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=kepler -n kepler --timeout=300s\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification des pods Kepler ---\"\n",
    "kubectl get pods -n kepler\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification que le ServiceMonitor a bien été créé ---\"\n",
    "kubectl get servicemonitor -n kepler\n",
    "\n",
    "echo \"--- Vérification que le service est bien de type NodePort ---\"\n",
    "kubectl get service -n kepler\n",
    "\n",
    "echo \"\"\n",
    "echo \"🎉 Kepler est maintenant correctement configuré avec un ServiceMonitor et un NodePort !\"\n",
    "\"\"\"\n",
    "\n",
    "# --- Étape 1 : Enregistrer le script dans un fichier local ---\n",
    "script_path = \"install_kepler.sh\"\n",
    "with open(script_path, \"w\") as f:\n",
    "    f.write(INSTALL_KEPLER_SCRIPT)\n",
    "os.chmod(script_path, 0o755)\n",
    "print(f\"Le script d'installation final a été sauvegardé dans '{script_path}'.\")\n",
    "\n",
    "\n",
    "# --- Étape 2 : Exécuter le fichier script avec enoslib ---\n",
    "print(\"Lancement de la mise à jour de Kepler...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.script(script_path)\n",
    "\n",
    "# Affichage du résultat\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4e625f",
   "metadata": {},
   "source": [
    "## Vérification des ServiceMonitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "247cec4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be45561375ae44ce9da31e4cb54bff88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for ServiceMonitor resources across the cluster...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-7.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-7.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recherche des ServiceMonitors dans tous les namespaces (-A) ---\n",
      "NAMESPACE    NAME                         AGE\n",
      "kepler       kepler-prometheus-exporter   2m25s\n",
      "monitoring   alertmanager-main            11m\n",
      "monitoring   blackbox-exporter            11m\n",
      "monitoring   coredns                      11m\n",
      "monitoring   grafana                      11m\n",
      "monitoring   kube-apiserver               11m\n",
      "monitoring   kube-controller-manager      11m\n",
      "monitoring   kube-scheduler               11m\n",
      "monitoring   kube-state-metrics           11m\n",
      "monitoring   kubelet                      11m\n",
      "monitoring   node-exporter                11m\n",
      "monitoring   prometheus-adapter           11m\n",
      "monitoring   prometheus-k8s               11m\n",
      "monitoring   prometheus-operator          11m\n"
     ]
    }
   ],
   "source": [
    "# Script to list ServiceMonitors\n",
    "CHECK_SM_SCRIPT = \"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "echo \"--- Recherche des ServiceMonitors dans tous les namespaces (-A) ---\"\n",
    "kubectl get servicemonitor -A\n",
    "\"\"\"\n",
    "\n",
    "# Execute the verification script on the master node\n",
    "print(\"Checking for ServiceMonitor resources across the cluster...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(CHECK_SM_SCRIPT)\n",
    "\n",
    "# Display the result\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa1d2e5",
   "metadata": {},
   "source": [
    "## Suppression Complète de Kepler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8e17cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52b46ba139647188b8206c2002196a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement de la suppression complète de Kepler...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-7.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-7.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Désinstallation de la release Helm 'kepler' ---\n",
      "NAME: kepler\n",
      "LAST DEPLOYED: Wed Oct  8 13:16:50 2025\n",
      "NAMESPACE: kepler\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "release \"kepler\" uninstalled\n",
      "\n",
      "--- 2. Suppression du ServiceMonitor dans le namespace 'monitoring' ---\n",
      "\n",
      "--- 3. Suppression du namespace 'kepler' ---\n",
      "namespace \"kepler\" deleted\n",
      "\n",
      "--- 4. Suppression du dépôt Helm de la configuration locale ---\n",
      "\"kepler\" has been removed from your repositories\n",
      "\n",
      "🎉 Nettoyage de Kepler terminé.\n"
     ]
    }
   ],
   "source": [
    "# Script pour supprimer complètement Kepler\n",
    "UNINSTALL_KEPLER_SCRIPT = \"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "echo \"--- 1. Désinstallation de la release Helm 'kepler' ---\"\n",
    "# On vérifie si la release existe avant de tenter de la supprimer\n",
    "if helm status kepler -n kepler &> /dev/null; then\n",
    "    helm uninstall kepler -n kepler\n",
    "else\n",
    "    echo \"Release Helm 'kepler' non trouvée.\"\n",
    "fi\n",
    "\n",
    "echo \"\\n--- 2. Suppression du ServiceMonitor dans le namespace 'monitoring' ---\"\n",
    "# --ignore-not-found=true évite une erreur si la ressource a déjà été supprimée\n",
    "kubectl delete servicemonitor kepler-prometheus-exporter -n monitoring --ignore-not-found=true\n",
    "\n",
    "echo \"\\n--- 3. Suppression du namespace 'kepler' ---\"\n",
    "kubectl delete namespace kepler --ignore-not-found=true\n",
    "\n",
    "echo \"\\n--- 4. Suppression du dépôt Helm de la configuration locale ---\"\n",
    "if helm repo list | grep -q \"kepler\"; then\n",
    "    helm repo remove kepler\n",
    "else\n",
    "    echo \"Dépôt Helm 'kepler' non trouvé.\"\n",
    "fi\n",
    "\n",
    "echo \"\\n🎉 Nettoyage de Kepler terminé.\"\n",
    "\"\"\"\n",
    "\n",
    "# Exécution du script de suppression sur le master\n",
    "print(\"Lancement de la suppression complète de Kepler...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(UNINSTALL_KEPLER_SCRIPT)\n",
    "\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22ef0ab",
   "metadata": {},
   "source": [
    "# Installer Kepler depuis les Manifestes Locaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7236bc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed278fbec29741c4b4c7bbdcd21a9bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Copie du répertoire local 'kepler' vers '/tmp/kepler' sur le master... ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">copy</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mcopy\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a37ddbe7fcd4d40a8c69e760a021392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répertoire copié avec succès.\n",
      "\n",
      "--- Application des manifestes sur le cluster... ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Application de tous les manifestes depuis le répertoire /tmp/kepler ---\n",
      "configmap/kepler created\n",
      "daemonset.apps/kepler created\n",
      "namespace/kepler unchanged\n",
      "role.rbac.authorization.k8s.io/prom-kepler unchanged\n",
      "rolebinding.rbac.authorization.k8s.io/prom-kepler unchanged\n",
      "serviceaccount/kepler unchanged\n",
      "clusterrole.rbac.authorization.k8s.io/kepler unchanged\n",
      "clusterrolebinding.rbac.authorization.k8s.io/kepler unchanged\n",
      "service/kepler unchanged\n",
      "servicemonitor.monitoring.coreos.com/kepler unchanged\n",
      "\n",
      "--- Attente de 30 secondes pour le démarrage des pods ---\n",
      "\n",
      "--- Vérification du statut des pods dans le namespace 'kepler' ---\n",
      "NAME           READY   STATUS    RESTARTS   AGE\n",
      "kepler-gr7tq   1/1     Running   0          32s\n",
      "kepler-nv5qg   1/1     Running   0          32s\n",
      "kepler-rglvn   1/1     Running   0          32s\n",
      "--- Vérification que le Service a bien été créé ---\n",
      "NAME     TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)           AGE     SELECTOR\n",
      "kepler   NodePort   10.96.2.247   <none>        28282:32143/TCP   7m30s   app.kubernetes.io/name=kepler,app.kubernetes.io/part-of=kepler\n",
      "\n",
      "🎉 Kepler a été déployé à partir des manifestes locaux.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# --- Étape 1 : Copier le répertoire local 'kepler' vers le master ---\n",
    "\n",
    "source_dir = \"kepler\"\n",
    "dest_dir = \"/tmp/kepler\"\n",
    "\n",
    "if not os.path.isdir(source_dir):\n",
    "    raise FileNotFoundError(f\"Le répertoire local '{source_dir}' est introuvable.\")\n",
    "\n",
    "print(f\"--- Copie du répertoire local '{source_dir}' vers '{dest_dir}' sur le master... ---\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.copy(src=source_dir, dest=\"/tmp/\")\n",
    "\n",
    "if p.results and p.results[0].status == \"OK\":\n",
    "    print(\"Répertoire copié avec succès.\")\n",
    "else:\n",
    "    print(\"Erreur lors de la copie du répertoire.\")\n",
    "    if p.results:\n",
    "        print(p.results[0].stderr)\n",
    "\n",
    "\n",
    "# --- Étape 2 : Appliquer les manifestes et vérifier ---\n",
    "\n",
    "# Script simplifié : la création du namespace est gérée par les manifestes\n",
    "APPLY_KEPLER_MANIFESTS_SCRIPT = f\"\"\"\n",
    "#!/bin/bash -e\n",
    "\n",
    "echo \"--- Application de tous les manifestes depuis le répertoire {dest_dir} ---\"\n",
    "kubectl apply -f \"{dest_dir}\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Attente de 30 secondes pour le démarrage des pods ---\"\n",
    "sleep 30\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification du statut des pods dans le namespace 'kepler' ---\"\n",
    "kubectl get pods -n kepler\n",
    "\n",
    "echo \"--- Vérification que le Service a bien été créé ---\"\n",
    "kubectl get svc -n kepler -o wide\n",
    "\n",
    "echo \"\"\n",
    "echo \"🎉 Kepler a été déployé à partir des manifestes locaux.\"\n",
    "\"\"\"\n",
    "\n",
    "print(f\"\\n--- Application des manifestes sur le cluster... ---\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(APPLY_KEPLER_MANIFESTS_SCRIPT)\n",
    "\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b551dc",
   "metadata": {},
   "source": [
    "## Diagnostic - Pourquoi Prometheus ne Scrape pas Kepler ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9602aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2682d37a6824105a3904ba35290e60e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Lancement du diagnostic complet Prometheus ↔ Kepler...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">script</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mscript\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "🔍 DIAGNOSTIC COMPLET: Prometheus ↔ Kepler\n",
      "======================================================================\n",
      "\n",
      "--- 1. Vérification des Pods Kepler ---\n",
      "No resources found in kepler namespace.\n",
      "\n",
      "--- 2. Vérification du Service Kepler ---\n",
      "NAME     TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)           AGE    SELECTOR\n",
      "kepler   NodePort   10.96.2.247   <none>        28282:32143/TCP   5m4s   app.kubernetes.io/name=kepler,app.kubernetes.io/part-of=kepler\n",
      "\n",
      "--- 3. Vérification des Labels du Service Kepler ---\n",
      "Les labels sont CRITIQUES pour que le ServiceMonitor fonctionne!\n",
      "    labels:\n",
      "      app.kubernetes.io/name: kepler\n",
      "      app.kubernetes.io/part-of: kepler\n",
      "    name: kepler\n",
      "    namespace: kepler\n",
      "    resourceVersion: \"2536\"\n",
      "    uid: d0f9db1d-35ca-4039-9c73-d957e3163de6\n",
      "  spec:\n",
      "    clusterIP: 10.96.2.247\n",
      "    clusterIPs:\n",
      "    - 10.96.2.247\n",
      "\n",
      "--- 4. Vérification du ServiceMonitor Kepler ---\n",
      "NAME     AGE\n",
      "kepler   5m4s\n",
      "\n",
      "--- 5. Détails du ServiceMonitor (selector et labels) ---\n",
      "    selector:\n",
      "      matchLabels:\n",
      "        app.kubernetes.io/name: kepler\n",
      "        app.kubernetes.io/part-of: kepler\n",
      "kind: List\n",
      "metadata:\n",
      "  resourceVersion: \"\"\n",
      "\n",
      "--- 6. Vérification que Prometheus-Operator voit le ServiceMonitor ---\n",
      "Prometheus doit être dans le même namespace ou avec les bonnes règles RBAC\n",
      "NAMESPACE    NAME                      AGE\n",
      "kepler       kepler                    5m5s\n",
      "monitoring   alertmanager-main         7m23s\n",
      "monitoring   blackbox-exporter         7m22s\n",
      "monitoring   coredns                   7m21s\n",
      "monitoring   grafana                   7m22s\n",
      "monitoring   kube-apiserver            7m21s\n",
      "monitoring   kube-controller-manager   7m21s\n",
      "monitoring   kube-scheduler            7m21s\n",
      "monitoring   kube-state-metrics        7m22s\n",
      "monitoring   kubelet                   7m21s\n",
      "monitoring   node-exporter             7m21s\n",
      "monitoring   prometheus-adapter        7m21s\n",
      "monitoring   prometheus-k8s            7m21s\n",
      "monitoring   prometheus-operator       7m21s\n",
      "\n",
      "--- 7. Configuration de Prometheus pour ServiceMonitor ---\n",
      "Vérification des serviceMonitorSelector dans Prometheus:\n",
      "    serviceMonitorSelector: {}\n",
      "    version: 3.6.0\n",
      "  status:\n",
      "    availableReplicas: 2\n",
      "    conditions:\n",
      "    - lastTransitionTime: \"2025-10-09T07:14:01Z\"\n",
      "\n",
      "--- 8. Vérification des Endpoints Kepler ---\n",
      "Si pas d'endpoints, le service ne pointe vers rien!\n",
      "NAME     ENDPOINTS   AGE\n",
      "kepler   <none>      5m5s\n",
      "\n",
      "--- 9. Test direct du endpoint Kepler ---\n",
      "error: error executing jsonpath \"{.items[0].metadata.name}\": Error executing template: array index out of bounds: index 0, length 0. Printing more information for debugging the template:\n",
      "\ttemplate was:\n",
      "\t\t{.items[0].metadata.name}\n",
      "\tobject given to jsonpath engine was:\n",
      "\t\tmap[string]interface {}{\"apiVersion\":\"v1\", \"items\":[]interface {}{}, \"kind\":\"List\", \"metadata\":map[string]interface {}{\"resourceVersion\":\"\"}}\n",
      "\n",
      "\n",
      "❌ Aucun pod Kepler trouvé!\n",
      "\n",
      "--- 10. Vérification des Logs Prometheus ---\n",
      "Recherche d'erreurs liées à Kepler dans les logs Prometheus:\n",
      "time=2025-10-09T07:13:58.030Z level=INFO source=kubernetes.go:313 msg=\"Using pod service account via in-cluster config\" component=\"discovery manager scrape\" discovery=kubernetes config=serviceMonitor/kepler/kepler/0\n",
      "\n",
      "--- 11. Configuration Actuelle des Targets Prometheus ---\n",
      "Vérifiez si Kepler apparaît dans les targets de Prometheus\n",
      "💡 Accédez à l'UI Prometheus: Status → Targets\n",
      "💡 Ou utilisez l'API: curl http://prometheus-ip:port/api/v1/targets\n",
      "\n",
      "======================================================================\n",
      "🎯 CAUSES COMMUNES ET SOLUTIONS:\n",
      "======================================================================\n",
      "\n",
      "❌ PROBLÈME 1: Labels incompatibles\n",
      "   Le ServiceMonitor cherche des labels spécifiques sur le Service\n",
      "   Solution: Vérifiez que les labels du Service matchent le selector du ServiceMonitor\n",
      "\n",
      "❌ PROBLÈME 2: Namespace incorrect\n",
      "   Le ServiceMonitor doit être dans un namespace que Prometheus surveille\n",
      "   Solution: Soit mettre le ServiceMonitor dans 'monitoring', soit configurer Prometheus\n",
      "\n",
      "❌ PROBLÈME 3: serviceMonitorSelector vide\n",
      "   Prometheus n'est configuré pour surveiller AUCUN ServiceMonitor\n",
      "   Solution: Configurer prometheus.serviceMonitorSelector: {}\n",
      "\n",
      "❌ PROBLÈME 4: Port incorrect\n",
      "   Le ServiceMonitor pointe vers un port qui n'existe pas\n",
      "   Solution: Vérifier que le port dans ServiceMonitor = port du Service\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Script de diagnostic complet pour identifier pourquoi Prometheus ne scrape pas Kepler\n",
    "DIAGNOSTIC_KEPLER_PROMETHEUS = \"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "echo \"======================================================================\"\n",
    "echo \"🔍 DIAGNOSTIC COMPLET: Prometheus ↔ Kepler\"\n",
    "echo \"======================================================================\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 1. Vérification des Pods Kepler ---\"\n",
    "kubectl get pods -n kepler -o wide\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 2. Vérification du Service Kepler ---\"\n",
    "kubectl get svc -n kepler -o wide\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 3. Vérification des Labels du Service Kepler ---\"\n",
    "echo \"Les labels sont CRITIQUES pour que le ServiceMonitor fonctionne!\"\n",
    "kubectl get svc -n kepler -o yaml | grep -A 10 \"labels:\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 4. Vérification du ServiceMonitor Kepler ---\"\n",
    "kubectl get servicemonitor -n kepler -o wide\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 5. Détails du ServiceMonitor (selector et labels) ---\"\n",
    "kubectl get servicemonitor -n kepler -o yaml | grep -A 20 \"selector:\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 6. Vérification que Prometheus-Operator voit le ServiceMonitor ---\"\n",
    "echo \"Prometheus doit être dans le même namespace ou avec les bonnes règles RBAC\"\n",
    "kubectl get servicemonitor -A\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 7. Configuration de Prometheus pour ServiceMonitor ---\"\n",
    "echo \"Vérification des serviceMonitorSelector dans Prometheus:\"\n",
    "kubectl get prometheus -n monitoring -o yaml | grep -A 5 \"serviceMonitorSelector:\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 8. Vérification des Endpoints Kepler ---\"\n",
    "echo \"Si pas d'endpoints, le service ne pointe vers rien!\"\n",
    "kubectl get endpoints -n kepler\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 9. Test direct du endpoint Kepler ---\"\n",
    "KEPLER_POD=`kubectl get pods -n kepler -l app.kubernetes.io/name=kepler -o jsonpath='{.items[0].metadata.name}'`\n",
    "if [ -n \"$KEPLER_POD\" ]; then\n",
    "    echo \"Test de l'endpoint metrics sur le pod $KEPLER_POD:\"\n",
    "    kubectl exec -n kepler $KEPLER_POD -- curl -s localhost:9102/metrics | head -20\n",
    "else\n",
    "    echo \"❌ Aucun pod Kepler trouvé!\"\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 10. Vérification des Logs Prometheus ---\"\n",
    "echo \"Recherche d'erreurs liées à Kepler dans les logs Prometheus:\"\n",
    "PROM_POD=`kubectl get pods -n monitoring -l app.kubernetes.io/name=prometheus -o jsonpath='{.items[0].metadata.name}'`\n",
    "if [ -n \"$PROM_POD\" ]; then\n",
    "    kubectl logs -n monitoring $PROM_POD -c prometheus --tail=50 | grep -i kepler || echo \"Aucune mention de Kepler dans les logs récents\"\n",
    "else\n",
    "    echo \"❌ Pod Prometheus non trouvé!\"\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 11. Configuration Actuelle des Targets Prometheus ---\"\n",
    "echo \"Vérifiez si Kepler apparaît dans les targets de Prometheus\"\n",
    "echo \"💡 Accédez à l'UI Prometheus: Status → Targets\"\n",
    "echo \"💡 Ou utilisez l'API: curl http://prometheus-ip:port/api/v1/targets\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"======================================================================\"\n",
    "echo \"🎯 CAUSES COMMUNES ET SOLUTIONS:\"\n",
    "echo \"======================================================================\"\n",
    "echo \"\"\n",
    "echo \"❌ PROBLÈME 1: Labels incompatibles\"\n",
    "echo \"   Le ServiceMonitor cherche des labels spécifiques sur le Service\"\n",
    "echo \"   Solution: Vérifiez que les labels du Service matchent le selector du ServiceMonitor\"\n",
    "echo \"\"\n",
    "echo \"❌ PROBLÈME 2: Namespace incorrect\"\n",
    "echo \"   Le ServiceMonitor doit être dans un namespace que Prometheus surveille\"\n",
    "echo \"   Solution: Soit mettre le ServiceMonitor dans 'monitoring', soit configurer Prometheus\"\n",
    "echo \"\"\n",
    "echo \"❌ PROBLÈME 3: serviceMonitorSelector vide\"\n",
    "echo \"   Prometheus n'est configuré pour surveiller AUCUN ServiceMonitor\"\n",
    "echo \"   Solution: Configurer prometheus.serviceMonitorSelector: {}\"\n",
    "echo \"\"\n",
    "echo \"❌ PROBLÈME 4: Port incorrect\"\n",
    "echo \"   Le ServiceMonitor pointe vers un port qui n'existe pas\"\n",
    "echo \"   Solution: Vérifier que le port dans ServiceMonitor = port du Service\"\n",
    "echo \"\"\n",
    "echo \"======================================================================\"\n",
    "\"\"\"\n",
    "\n",
    "# --- Enregistrer le script dans un fichier local ---\n",
    "script_path = \"diagnostic_kepler.sh\"\n",
    "with open(script_path, \"w\") as f:\n",
    "    f.write(DIAGNOSTIC_KEPLER_PROMETHEUS)\n",
    "os.chmod(script_path, 0o755)\n",
    "\n",
    "print(\"🔍 Lancement du diagnostic complet Prometheus ↔ Kepler...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.script(script_path)\n",
    "\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474c1d10",
   "metadata": {},
   "source": [
    "## 🔧 Solution : Donner les Permissions RBAC à Prometheus pour Kepler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d3187c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd125d1b54a43f28c576241906719ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Application de la correction RBAC...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "🔧 Correction des Permissions RBAC pour Prometheus → Kepler\n",
      "========================================================================\n",
      "\n",
      "--- Création d'un ClusterRole avec les permissions nécessaires ---\n",
      "clusterrole.rbac.authorization.k8s.io/prometheus-kepler-access unchanged\n",
      "\n",
      "--- Liaison du ClusterRole au ServiceAccount prometheus-k8s ---\n",
      "clusterrolebinding.rbac.authorization.k8s.io/prometheus-kepler-access unchanged\n",
      "\n",
      "--- Vérification des permissions créées ---\n",
      "NAME                       CREATED AT\n",
      "prometheus-kepler-access   2025-10-09T07:11:18Z\n",
      "NAME                       ROLE                                   AGE\n",
      "prometheus-kepler-access   ClusterRole/prometheus-kepler-access   2m7s\n",
      "\n",
      "--- Redémarrage des pods Prometheus pour appliquer les changements ---\n",
      "statefulset.apps/prometheus-k8s restarted\n",
      "\n",
      "--- Attente du redémarrage de Prometheus (30 secondes) ---\n",
      "\n",
      "--- Vérification que Prometheus est prêt ---\n",
      "pod/prometheus-k8s-0 condition met\n",
      "pod/prometheus-k8s-1 condition met\n",
      "\n",
      "========================================================================\n",
      "✅ Permissions RBAC configurées avec succès !\n",
      "========================================================================\n",
      "\n",
      "Prometheus peut maintenant accéder aux EndpointSlices du namespace kepler.\n",
      "Attendez 1-2 minutes puis vérifiez les targets dans l'UI Prometheus.\n"
     ]
    }
   ],
   "source": [
    "# Script pour corriger les permissions RBAC de Prometheus\n",
    "FIX_PROMETHEUS_RBAC = \"\"\"\n",
    "#!/bin/bash -e\n",
    "\n",
    "echo \"========================================================================\"\n",
    "echo \"🔧 Correction des Permissions RBAC pour Prometheus → Kepler\"\n",
    "echo \"========================================================================\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Création d'un ClusterRole avec les permissions nécessaires ---\"\n",
    "cat <<EOF | kubectl apply -f -\n",
    "apiVersion: rbac.authorization.k8s.io/v1\n",
    "kind: ClusterRole\n",
    "metadata:\n",
    "  name: prometheus-kepler-access\n",
    "rules:\n",
    "- apiGroups: [\"\"]\n",
    "  resources:\n",
    "  - services\n",
    "  - endpoints\n",
    "  - pods\n",
    "  verbs: [\"get\", \"list\", \"watch\"]\n",
    "- apiGroups: [\"discovery.k8s.io\"]\n",
    "  resources:\n",
    "  - endpointslices\n",
    "  verbs: [\"get\", \"list\", \"watch\"]\n",
    "EOF\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Liaison du ClusterRole au ServiceAccount prometheus-k8s ---\"\n",
    "cat <<EOF | kubectl apply -f -\n",
    "apiVersion: rbac.authorization.k8s.io/v1\n",
    "kind: ClusterRoleBinding\n",
    "metadata:\n",
    "  name: prometheus-kepler-access\n",
    "roleRef:\n",
    "  apiGroup: rbac.authorization.k8s.io\n",
    "  kind: ClusterRole\n",
    "  name: prometheus-kepler-access\n",
    "subjects:\n",
    "- kind: ServiceAccount\n",
    "  name: prometheus-k8s\n",
    "  namespace: monitoring\n",
    "EOF\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification des permissions créées ---\"\n",
    "kubectl get clusterrole prometheus-kepler-access\n",
    "kubectl get clusterrolebinding prometheus-kepler-access\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Redémarrage des pods Prometheus pour appliquer les changements ---\"\n",
    "kubectl rollout restart statefulset prometheus-k8s -n monitoring\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Attente du redémarrage de Prometheus (30 secondes) ---\"\n",
    "sleep 30\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification que Prometheus est prêt ---\"\n",
    "kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=prometheus -n monitoring --timeout=120s\n",
    "\n",
    "echo \"\"\n",
    "echo \"========================================================================\"\n",
    "echo \"✅ Permissions RBAC configurées avec succès !\"\n",
    "echo \"========================================================================\"\n",
    "echo \"\"\n",
    "echo \"Prometheus peut maintenant accéder aux EndpointSlices du namespace kepler.\"\n",
    "echo \"Attendez 1-2 minutes puis vérifiez les targets dans l'UI Prometheus.\"\n",
    "\"\"\"\n",
    "\n",
    "print(\"🔧 Application de la correction RBAC...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(FIX_PROMETHEUS_RBAC)\n",
    "\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6c02f4",
   "metadata": {},
   "source": [
    "# Déploiement des Ressources PowerCap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6c5d05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f97c8c3c4c41dcb1dd34c4168699ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Copie du répertoire 'powercap' vers '/tmp/powercap' sur le master... ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">copy</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mcopy\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f2052fa0fc4408a67e45f963754764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Répertoire copié avec succès.\n",
      "\n",
      "--- Déploiement des ressources PowerCap... ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "🚀 Déploiement des Ressources PowerCap dans le namespace 'default'\n",
      "========================================================================\n",
      "\n",
      "--- Application de tous les manifestes depuis /tmp/powercap ---\n",
      "configmap/powercap-config created\n",
      "daemonset.apps/powercap-manager created\n",
      "serviceaccount/powercap-manager created\n",
      "clusterrole.rbac.authorization.k8s.io/powercap-manager created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/powercap-manager created\n",
      "\n",
      "--- Vérification du DaemonSet powercap-manager ---\n",
      "NAME               DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE   CONTAINERS         IMAGES                                SELECTOR\n",
      "powercap-manager   2         2         0       2            0           <none>          0s    powercap-manager   ghcr.io/menraromial/powercap:latest   app=powercap-manager\n",
      "\n",
      "--- Vérification des pods powercap-manager ---\n",
      "NAME                     READY   STATUS              RESTARTS   AGE   IP              NODE          NOMINATED NODE   READINESS GATES\n",
      "powercap-manager-8qh7b   0/1     ContainerCreating   0          0s    172.16.101.27   paradoxe-27   <none>           <none>\n",
      "powercap-manager-mjk5f   0/1     ContainerCreating   0          0s    172.16.101.32   paradoxe-32   <none>           <none>\n",
      "\n",
      "--- Statut du DaemonSet (nombre de pods prêts) ---\n",
      "Waiting for daemon set \"powercap-manager\" rollout to finish: 0 of 2 updated pods are available...\n",
      "Waiting for daemon set \"powercap-manager\" rollout to finish: 1 of 2 updated pods are available...\n",
      "daemon set \"powercap-manager\" successfully rolled out\n",
      "\n",
      "--- Vérification du ServiceAccount ---\n",
      "NAME               SECRETS   AGE\n",
      "powercap-manager   0         31s\n",
      "\n",
      "--- Vérification de la ConfigMap ---\n",
      "NAME              DATA   AGE\n",
      "powercap-config   10     31s\n",
      "\n",
      "--- Vérification des services (si présents) ---\n",
      "\n",
      "========================================================================\n",
      "✅ Déploiement PowerCap terminé !\n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# --- Script pour déployer tous les manifestes PowerCap ---\n",
    "\n",
    "source_dir = \"powercap\"\n",
    "dest_dir = \"/tmp/powercap\"\n",
    "\n",
    "# Vérifier que le répertoire local existe\n",
    "if not os.path.isdir(source_dir):\n",
    "    print(f\"⚠️  Le répertoire local '{source_dir}' n'existe pas.\")\n",
    "    print(f\"📁 Veuillez créer le dossier '{source_dir}' avec les fichiers suivants:\")\n",
    "    print(\"   - daemonset.yaml\")\n",
    "    print(\"   - rbac.yaml\")\n",
    "    print(\"   - configmap.yaml\")\n",
    "    print(\"\\n💡 Ou uploadez le dossier complet dans le répertoire de travail.\")\n",
    "    raise FileNotFoundError(f\"Le répertoire local '{source_dir}' est introuvable. Créez-le d'abord avec les manifestes nécessaires.\")\n",
    "\n",
    "# --- Étape 1 : Copier le répertoire local vers le master ---\n",
    "print(f\"--- Copie du répertoire '{source_dir}' vers '{dest_dir}' sur le master... ---\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.copy(src=source_dir, dest=\"/tmp/\")\n",
    "\n",
    "if p.results and p.results[0].status == \"OK\":\n",
    "    print(\"✅ Répertoire copié avec succès.\")\n",
    "else:\n",
    "    print(\"❌ Erreur lors de la copie du répertoire.\")\n",
    "    if p.results:\n",
    "        print(p.results[0].stderr)\n",
    "\n",
    "# --- Étape 2 : Appliquer tous les manifestes ---\n",
    "DEPLOY_POWERCAP_SCRIPT = f\"\"\"\n",
    "#!/bin/bash -e\n",
    "\n",
    "echo \"========================================================================\"\n",
    "echo \"🚀 Déploiement des Ressources PowerCap dans le namespace 'default'\"\n",
    "echo \"========================================================================\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Application de tous les manifestes depuis {dest_dir} ---\"\n",
    "kubectl apply -f \"{dest_dir}\"\n",
    "\n",
    "# echo \"\"\n",
    "# echo \"--- Attente de 30 secondes pour la création des ressources ---\"\n",
    "# sleep 30\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification du DaemonSet powercap-manager ---\"\n",
    "kubectl get daemonset powercap-manager -n default -o wide\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification des pods powercap-manager ---\"\n",
    "kubectl get pods -n default -l app=powercap-manager -o wide\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Statut du DaemonSet (nombre de pods prêts) ---\"\n",
    "kubectl rollout status daemonset/powercap-manager -n default --timeout=60s\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification du ServiceAccount ---\"\n",
    "kubectl get serviceaccount powercap-manager -n default\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification de la ConfigMap ---\"\n",
    "kubectl get configmap powercap-config -n default\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification des services (si présents) ---\"\n",
    "kubectl get services -n default -l app=powercap-manager || echo \"Aucun service trouvé\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"========================================================================\"\n",
    "echo \"✅ Déploiement PowerCap terminé !\"\n",
    "echo \"========================================================================\"\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- Déploiement des ressources PowerCap... ---\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(DEPLOY_POWERCAP_SCRIPT)\n",
    "\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772d700f",
   "metadata": {},
   "source": [
    "## Vérification de l'État et des Logs PowerCap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19d50d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94f3934b5f2403097268b15f4d1c4b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Lancement de la vérification détaillée de l'état et des logs PowerCap...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "📊 VÉRIFICATION DÉTAILLÉE - État et Logs PowerCap Manager\n",
      "========================================================================\n",
      "\n",
      "--- 1. État du DaemonSet powercap-manager ---\n",
      "NAME               DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE   CONTAINERS         IMAGES                                SELECTOR\n",
      "powercap-manager   2         2         2       2            2           <none>          50s   powercap-manager   ghcr.io/menraromial/powercap:latest   app=powercap-manager\n",
      "\n",
      "--- 2. Détails du DaemonSet ---\n",
      "Name:           powercap-manager\n",
      "Selector:       app=powercap-manager\n",
      "Node-Selector:  <none>\n",
      "Labels:         app=powercap-manager\n",
      "                app.kubernetes.io/component=power-management\n",
      "                app.kubernetes.io/name=powercap-manager\n",
      "                app.kubernetes.io/version=v1.0.0\n",
      "Annotations:    deprecated.daemonset.template.generation: 1\n",
      "Desired Number of Nodes Scheduled: 2\n",
      "Current Number of Nodes Scheduled: 2\n",
      "Number of Nodes Scheduled with Up-to-date Pods: 2\n",
      "Number of Nodes Scheduled with Available Pods: 2\n",
      "Number of Nodes Misscheduled: 0\n",
      "Pods Status:  2 Running / 0 Waiting / 0 Succeeded / 0 Failed\n",
      "Pod Template:\n",
      "  Labels:           app=powercap-manager\n",
      "                    app.kubernetes.io/component=power-management\n",
      "                    app.kubernetes.io/name=powercap-manager\n",
      "                    app.kubernetes.io/version=v1.0.0\n",
      "  Service Account:  powercap-manager\n",
      "  Containers:\n",
      "   powercap-manager:\n",
      "    Image:      ghcr.io/menraromial/powercap:latest\n",
      "    Port:       <none>\n",
      "    Host Port:  <none>\n",
      "    Limits:\n",
      "      cpu:     200m\n",
      "      memory:  128Mi\n",
      "    Requests:\n",
      "      cpu:      50m\n",
      "      memory:   64Mi\n",
      "    Liveness:   exec [pgrep -f powercap] delay=30s timeout=10s period=60s #success=1 #failure=3\n",
      "    Readiness:  exec [sh -c test -d /sys/devices/virtual/powercap/intel-rapl && pgrep -f powercap] delay=15s timeout=10s period=30s #success=1 #failure=3\n",
      "    Environment Variables from:\n",
      "      powercap-config  ConfigMap  Optional: false\n",
      "    Environment:\n",
      "      NODE_NAME:   (v1:spec.nodeName)\n",
      "    Mounts:\n",
      "      /app/data from data-storage (rw)\n",
      "      /sys/devices/virtual/powercap from rapl (rw)\n",
      "  Volumes:\n",
      "   rapl:\n",
      "    Type:          HostPath (bare host directory volume)\n",
      "    Path:          /sys/devices/virtual/powercap\n",
      "    HostPathType:  Directory\n",
      "   data-storage:\n",
      "    Type:          HostPath (bare host directory volume)\n",
      "    Path:          /var/lib/powercap\n",
      "    HostPathType:  DirectoryOrCreate\n",
      "  Node-Selectors:  <none>\n",
      "\n",
      "--- 3. Liste des pods powercap-manager sur tous les nœuds ---\n",
      "NAME                     READY   STATUS    RESTARTS   AGE   IP              NODE          NOMINATED NODE   READINESS GATES\n",
      "powercap-manager-8qh7b   1/1     Running   0          50s   172.16.101.27   paradoxe-27   <none>           <none>\n",
      "powercap-manager-mjk5f   1/1     Running   0          50s   172.16.101.32   paradoxe-32   <none>           <none>\n",
      "\n",
      "--- 4. Nombre de pods actifs par rapport au nombre attendu ---\n",
      "Pods désirés: 2\n",
      "Pods prêts: 2\n",
      "Pods disponibles: 2\n",
      "\n",
      "--- 5. Description détaillée de chaque pod ---\n",
      "\n",
      "==========================================\n",
      "Pod: powercap-manager-8qh7b\n",
      "==========================================\n",
      "\n",
      "--- État général ---\n",
      "NAME                     READY   STATUS    RESTARTS   AGE   IP              NODE          NOMINATED NODE   READINESS GATES\n",
      "powercap-manager-8qh7b   1/1     Running   0          50s   172.16.101.27   paradoxe-27   <none>           <none>\n",
      "\n",
      "--- Nœud d'exécution ---\n",
      "Nœud: paradoxe-27\n",
      "\n",
      "--- Statut du conteneur ---\n",
      "Conteneur: powercap-manager\n",
      "Ready: true\n",
      "Restarts: 0\n",
      "Image: ghcr.io/menraromial/powercap:latest\n",
      "\n",
      "--- Conditions du pod ---\n",
      "PodReadyToStartContainers: True ()\n",
      "Initialized: True ()\n",
      "Ready: True ()\n",
      "ContainersReady: True ()\n",
      "PodScheduled: True ()\n",
      "\n",
      "==========================================\n",
      "Pod: powercap-manager-mjk5f\n",
      "==========================================\n",
      "\n",
      "--- État général ---\n",
      "NAME                     READY   STATUS    RESTARTS   AGE   IP              NODE          NOMINATED NODE   READINESS GATES\n",
      "powercap-manager-mjk5f   1/1     Running   0          51s   172.16.101.32   paradoxe-32   <none>           <none>\n",
      "\n",
      "--- Nœud d'exécution ---\n",
      "Nœud: paradoxe-32\n",
      "\n",
      "--- Statut du conteneur ---\n",
      "Conteneur: powercap-manager\n",
      "Ready: true\n",
      "Restarts: 0\n",
      "Image: ghcr.io/menraromial/powercap:latest\n",
      "\n",
      "--- Conditions du pod ---\n",
      "PodReadyToStartContainers: True ()\n",
      "Initialized: True ()\n",
      "Ready: True ()\n",
      "ContainersReady: True ()\n",
      "PodScheduled: True ()\n",
      "\n",
      "--- 6. Logs de tous les pods powercap-manager ---\n",
      "\n",
      "==========================================\n",
      "📝 LOGS du pod: powercap-manager-8qh7b\n",
      "==========================================\n",
      "[PowerManager] 2025/10/09 10:21:09.665156 Starting professional power management system...\n",
      "[PowerManager] 2025/10/09 10:21:09.665416 🌍 Timezone set to: Europe/Paris (current time: 10:21:09 CEST)\n",
      "[PowerManager] 2025/10/09 10:21:09.665433 🚀 Initializing PowerCap Manager...\n",
      "[PowerManager] 2025/10/09 10:21:09.665455 ✅ Configuration loaded successfully\n",
      "[PowerManager] 2025/10/09 10:21:09.665459    - Node Name: paradoxe-27\n",
      "[PowerManager] 2025/10/09 10:21:09.665463    - Data Provider: epex\n",
      "[PowerManager] 2025/10/09 10:21:09.665466    - Provider URL: https://www.epexspot.com/en/market-results\n",
      "[PowerManager] 2025/10/09 10:21:09.665470    - Stabilisation Time: 5m0s\n",
      "[PowerManager] 2025/10/09 10:21:09.665492    - RAPL Min Power: 20000000 µW (20.0 W)\n",
      "[PowerManager] 2025/10/09 10:21:09.665502 🔌 Creating Kubernetes client...\n",
      "[PowerManager] 2025/10/09 10:21:09.666148 ✅ Kubernetes client created successfully\n",
      "[PowerManager] 2025/10/09 10:21:09.666154 ⚡ Discovering RAPL domains...\n",
      "[PowerManager] 2025/10/09 10:21:09.666157 🔍 Discovering RAPL domains in /sys/devices/virtual/powercap/intel-rapl...\n",
      "[PowerManager] 2025/10/09 10:21:09.666201 📁 Found 6 entries in RAPL directory\n",
      "[PowerManager] 2025/10/09 10:21:09.666205    ⏭️  Skipping non-RAPL entry: enabled\n",
      "[PowerManager] 2025/10/09 10:21:09.666207 ⚡ Processing RAPL domain: intel-rapl:0\n",
      "[PowerManager] 2025/10/09 10:21:09.666802    ✅ Added domain intel-rapl:0 with 2 constraints and 2 max constraints\n",
      "[PowerManager] 2025/10/09 10:21:09.666813 ⚡ Processing RAPL domain: intel-rapl:1\n",
      "[PowerManager] 2025/10/09 10:21:09.667299    ✅ Added domain intel-rapl:1 with 2 constraints and 2 max constraints\n",
      "[PowerManager] 2025/10/09 10:21:09.667302    ⏭️  Skipping non-RAPL entry: power\n",
      "[PowerManager] 2025/10/09 10:21:09.667304    ⏭️  Skipping non-RAPL entry: subsystem\n",
      "[PowerManager] 2025/10/09 10:21:09.667305    ⏭️  Skipping non-RAPL entry: uevent\n",
      "[PowerManager] 2025/10/09 10:21:09.667307 ✅ Domain discovery completed: found 2 valid RAPL domains\n",
      "[PowerManager] 2025/10/09 10:21:09.667308    📊 Domain intel-rapl:0: 2 power constraints, 2 max constraints\n",
      "[PowerManager] 2025/10/09 10:21:09.667310    📊 Domain intel-rapl:1: 2 power constraints, 2 max constraints\n",
      "[PowerManager] 2025/10/09 10:21:09.667311 ✅ Discovered 2 RAPL domains\n",
      "[PowerManager] 2025/10/09 10:21:09.667313 📊 Initializing data store and calculator...\n",
      "[PowerManager] 2025/10/09 10:21:09.667315 🏭 Setting up market data provider...\n",
      "[PowerManager] 2025/10/09 10:21:09.667319 ✅ Configured data provider: EPEX\n",
      "[PowerManager] 2025/10/09 10:21:09.667320 ✅ PowerCap Manager initialized successfully with 2 RAPL domains\n",
      "[PowerManager] 2025/10/09 10:21:09.667324 📥 Loading market data for 2025-10-09...\n",
      "[PowerManager] 2025/10/09 10:21:09.667345 Data file epex_data_2025-10-09.csv not found, attempting to generate...\n",
      "[PowerManager] 2025/10/09 10:21:09.667347 🔄 Refreshing market data for 2025-10-09 using provider 'EPEX'...\n",
      "[PowerManager] 2025/10/09 10:21:10.201354 ✅ Successfully fetched 96 data points from 'EPEX' in 534.004097ms\n",
      "[PowerManager] 2025/10/09 10:21:10.201379    📊 Sample fetched data:\n",
      "[PowerManager] 2025/10/09 10:21:10.201382       00:00-00:15: 68.2 MWh @ 95.69 €/MWh\n",
      "[PowerManager] 2025/10/09 10:21:10.201387       00:15-00:30: 62.8 MWh @ 95.02 €/MWh\n",
      "[PowerManager] 2025/10/09 10:21:10.201390       00:30-00:45: 61.9 MWh @ 88.00 €/MWh\n",
      "[PowerManager] 2025/10/09 10:21:10.201392       ... and 93 more data points\n",
      "[PowerManager] 2025/10/09 10:21:10.201393 💾 Saving fetched data to CSV...\n",
      "[PowerManager] 2025/10/09 10:21:10.201670 📊 Calculating maximum volume from 96 data points...\n",
      "[PowerManager] 2025/10/09 10:21:10.201675 ✅ Maximum volume calculated: 120.6 MWh at period 17:15-17:30\n",
      "[PowerManager] 2025/10/09 10:21:10.201678 📊 Calculating maximum volume from 96 data points...\n",
      "[PowerManager] 2025/10/09 10:21:10.201679 ✅ Maximum volume calculated: 120.6 MWh at period 17:15-17:30\n",
      "[PowerManager] 2025/10/09 10:21:10.201682 ✅ Successfully refreshed data for 2025-10-09\n",
      "[PowerManager] 2025/10/09 10:21:10.201746 📊 Calculating maximum volume from 96 data points...\n",
      "[PowerManager] 2025/10/09 10:21:10.201748 ✅ Maximum volume calculated: 120.6 MWh at period 17:15-17:30\n",
      "[PowerManager] 2025/10/09 10:21:10.201751 ✅ Successfully loaded 96 market data points for 2025-10-09\n",
      "[PowerManager] 2025/10/09 10:21:10.201753    📊 Sample data points:\n",
      "[PowerManager] 2025/10/09 10:21:10.201755       00:00-00:15: 68.2 MWh @ 95.69 €/MWh\n",
      "[PowerManager] 2025/10/09 10:21:10.201757       00:15-00:30: 62.8 MWh @ 95.02 €/MWh\n",
      "[PowerManager] 2025/10/09 10:21:10.201760       00:30-00:45: 61.9 MWh @ 88.00 €/MWh\n",
      "[PowerManager] 2025/10/09 10:21:10.201763       ... and 93 more data points\n",
      "[PowerManager] 2025/10/09 10:21:10.201765 🔧 Initializing Kubernetes node 'paradoxe-27'...\n",
      "[PowerManager] 2025/10/09 10:21:10.262892 ✅ Successfully retrieved node 'paradoxe-27'\n",
      "[PowerManager] 2025/10/09 10:21:10.262927 🚀 Node 'paradoxe-27' not initialized, proceeding with initialization...\n",
      "[PowerManager] 2025/10/09 10:21:10.262934 ⚡ Finding maximum power value from RAPL domains...\n",
      "[PowerManager] 2025/10/09 10:21:10.262938 🔍 Searching for maximum power value across 2 RAPL domains...\n",
      "[PowerManager] 2025/10/09 10:21:10.262944    📊 Checking domain intel-rapl:0...\n",
      "[PowerManager] 2025/10/09 10:21:10.262950       🔋 Found higher power constraint: 194000000 µW (194.0 W) from /sys/devices/virtual/powercap/intel-rapl/intel-rapl:0/constraint_0_power_limit_uw\n",
      "[PowerManager] 2025/10/09 10:21:10.262961       🔋 Found higher max constraint: 652000000 µW (652.0 W) from /sys/devices/virtual/powercap/intel-rapl/intel-rapl:0/constraint_1_max_power_uw\n",
      "[PowerManager] 2025/10/09 10:21:10.262968    📊 Checking domain intel-rapl:1...\n",
      "[PowerManager] 2025/10/09 10:21:10.262973 ✅ Maximum power value determined: 652000000 µW (652.0 W) from /sys/devices/virtual/powercap/intel-rapl/intel-rapl:0/constraint_1_max_power_uw\n",
      "[PowerManager] 2025/10/09 10:21:10.262978 ✅ Found maximum power value: 652000000 µW (652.0 W)\n",
      "[PowerManager] 2025/10/09 10:21:10.262983 📝 Setting node annotations...\n",
      "[PowerManager] 2025/10/09 10:21:10.262988    - rapl/max_power_uw: 652000000\n",
      "[PowerManager] 2025/10/09 10:21:10.262992    - rapl/pmax: 652000000\n",
      "[PowerManager] 2025/10/09 10:21:10.262996    - rapl/provider: epex\n",
      "[PowerManager] 2025/10/09 10:21:10.263000 🏷️  Marking node as initialized...\n",
      "[PowerManager] 2025/10/09 10:21:10.276654 ✅ Node 'paradoxe-27' initialized successfully with max power: 652000000 µW (652.0 W)\n",
      "[PowerManager] 2025/10/09 10:21:10.276676 Power management system ready - starting main cycle\n",
      "[PowerManager] 2025/10/09 10:21:10.276684 Starting power management cycle...\n",
      "[PowerManager] 2025/10/09 10:21:10.276698 Next data refresh scheduled in 13h38m49.72330783s (at 2025-10-10 00:00:00)\n",
      "[PowerManager] 2025/10/09 10:21:10.276716 🔄 Starting power cap adjustment cycle...\n",
      "[PowerManager] 2025/10/09 10:21:10.281924 ⏰ Current time: 10:21:10 (period: 10:15-10:30)\n",
      "[PowerManager] 2025/10/09 10:21:10.281946 📊 Market data: 96 points available, max volume: 120.6 MWh\n",
      "[PowerManager] 2025/10/09 10:21:10.281958 ⚡ Retrieving RAPL max power...\n",
      "[PowerManager] 2025/10/09 10:21:10.281963 ✅ RAPL max power: 652000000 µW (652.0 W)\n",
      "[PowerManager] 2025/10/09 10:21:10.281970 🧮 Calculating source power using market data...\n",
      "[PowerManager] 2025/10/09 10:21:10.281978 ✅ Calculated source power: 327621891 µW (327.6 W)\n",
      "[PowerManager] 2025/10/09 10:21:10.281983 🎯 Determining final power limit to apply...\n",
      "[PowerManager] 2025/10/09 10:21:10.281987    Starting with minimum: 20000000 µW (20.0 W)\n",
      "[PowerManager] 2025/10/09 10:21:10.281992    ✅ Using calculated source power: 327621891 µW (327.6 W)\n",
      "[PowerManager] 2025/10/09 10:21:10.281998 📋 Power calculation summary:\n",
      "[PowerManager] 2025/10/09 10:21:10.282002    - Period: 10:15-10:30\n",
      "[PowerManager] 2025/10/09 10:21:10.282006    - Source Power: 327621891 µW (327.6 W)\n",
      "[PowerManager] 2025/10/09 10:21:10.282011    - Max Hardware: 652000000 µW (652.0 W)\n",
      "[PowerManager] 2025/10/09 10:21:10.282015    - Min Threshold: 20000000 µW (20.0 W)\n",
      "[PowerManager] 2025/10/09 10:21:10.282020    - Applied Limit: 327621891 µW (327.6 W)\n",
      "[PowerManager] 2025/10/09 10:21:10.282024 ⚡ Applying power limits to RAPL domains...\n",
      "\n",
      "==========================================\n",
      "📝 LOGS du pod: powercap-manager-mjk5f\n",
      "==========================================\n",
      "[PowerManager] 2025/10/09 10:21:10.017836 Starting professional power management system...\n",
      "[PowerManager] 2025/10/09 10:21:10.017982 🌍 Timezone set to: Europe/Paris (current time: 10:21:10 CEST)\n",
      "[PowerManager] 2025/10/09 10:21:10.017991 🚀 Initializing PowerCap Manager...\n",
      "[PowerManager] 2025/10/09 10:21:10.018000 ✅ Configuration loaded successfully\n",
      "[PowerManager] 2025/10/09 10:21:10.018002    - Node Name: paradoxe-32\n",
      "[PowerManager] 2025/10/09 10:21:10.018003    - Data Provider: epex\n",
      "[PowerManager] 2025/10/09 10:21:10.018005    - Provider URL: https://www.epexspot.com/en/market-results\n",
      "[PowerManager] 2025/10/09 10:21:10.018007    - Stabilisation Time: 5m0s\n",
      "[PowerManager] 2025/10/09 10:21:10.018018    - RAPL Min Power: 20000000 µW (20.0 W)\n",
      "[PowerManager] 2025/10/09 10:21:10.018025 🔌 Creating Kubernetes client...\n",
      "[PowerManager] 2025/10/09 10:21:10.018436 ✅ Kubernetes client created successfully\n",
      "[PowerManager] 2025/10/09 10:21:10.018441 ⚡ Discovering RAPL domains...\n",
      "[PowerManager] 2025/10/09 10:21:10.018443 🔍 Discovering RAPL domains in /sys/devices/virtual/powercap/intel-rapl...\n",
      "[PowerManager] 2025/10/09 10:21:10.018482 📁 Found 6 entries in RAPL directory\n",
      "[PowerManager] 2025/10/09 10:21:10.018485    ⏭️  Skipping non-RAPL entry: enabled\n",
      "[PowerManager] 2025/10/09 10:21:10.018487 ⚡ Processing RAPL domain: intel-rapl:0\n",
      "[PowerManager] 2025/10/09 10:21:10.109720    ✅ Added domain intel-rapl:0 with 2 constraints and 2 max constraints\n",
      "[PowerManager] 2025/10/09 10:21:10.109743 ⚡ Processing RAPL domain: intel-rapl:1\n",
      "[PowerManager] 2025/10/09 10:21:10.110109    ✅ Added domain intel-rapl:1 with 2 constraints and 2 max constraints\n",
      "[PowerManager] 2025/10/09 10:21:10.110118    ⏭️  Skipping non-RAPL entry: power\n",
      "[PowerManager] 2025/10/09 10:21:10.110122    ⏭️  Skipping non-RAPL entry: subsystem\n",
      "[PowerManager] 2025/10/09 10:21:10.110125    ⏭️  Skipping non-RAPL entry: uevent\n",
      "[PowerManager] 2025/10/09 10:21:10.110128 ✅ Domain discovery completed: found 2 valid RAPL domains\n",
      "[PowerManager] 2025/10/09 10:21:10.110133    📊 Domain intel-rapl:0: 2 power constraints, 2 max constraints\n",
      "[PowerManager] 2025/10/09 10:21:10.110137    📊 Domain intel-rapl:1: 2 power constraints, 2 max constraints\n",
      "[PowerManager] 2025/10/09 10:21:10.110141 ✅ Discovered 2 RAPL domains\n",
      "[PowerManager] 2025/10/09 10:21:10.110144 📊 Initializing data store and calculator...\n",
      "[PowerManager] 2025/10/09 10:21:10.110149 🏭 Setting up market data provider...\n",
      "[PowerManager] 2025/10/09 10:21:10.110157 ✅ Configured data provider: EPEX\n",
      "[PowerManager] 2025/10/09 10:21:10.110161 ✅ PowerCap Manager initialized successfully with 2 RAPL domains\n",
      "[PowerManager] 2025/10/09 10:21:10.110169 📥 Loading market data for 2025-10-09...\n",
      "[PowerManager] 2025/10/09 10:21:10.110204 Data file epex_data_2025-10-09.csv not found, attempting to generate...\n",
      "[PowerManager] 2025/10/09 10:21:10.110210 🔄 Refreshing market data for 2025-10-09 using provider 'EPEX'...\n",
      "[PowerManager] 2025/10/09 10:21:10.614120 ✅ Successfully fetched 96 data points from 'EPEX' in 503.903692ms\n",
      "[PowerManager] 2025/10/09 10:21:10.614167    📊 Sample fetched data:\n",
      "[PowerManager] 2025/10/09 10:21:10.614174       00:00-00:15: 68.2 MWh @ 95.69 €/MWh\n",
      "[PowerManager] 2025/10/09 10:21:10.614187       00:15-00:30: 62.8 MWh @ 95.02 €/MWh\n",
      "[PowerManager] 2025/10/09 10:21:10.614193       00:30-00:45: 61.9 MWh @ 88.00 €/MWh\n",
      "[PowerManager] 2025/10/09 10:21:10.614198       ... and 93 more data points\n",
      "[PowerManager] 2025/10/09 10:21:10.614202 💾 Saving fetched data to CSV...\n",
      "[PowerManager] 2025/10/09 10:21:10.614568 📊 Calculating maximum volume from 96 data points...\n",
      "[PowerManager] 2025/10/09 10:21:10.614573 ✅ Maximum volume calculated: 120.6 MWh at period 17:15-17:30\n",
      "[PowerManager] 2025/10/09 10:21:10.614576 📊 Calculating maximum volume from 96 data points...\n",
      "[PowerManager] 2025/10/09 10:21:10.614578 ✅ Maximum volume calculated: 120.6 MWh at period 17:15-17:30\n",
      "[PowerManager] 2025/10/09 10:21:10.614580 ✅ Successfully refreshed data for 2025-10-09\n",
      "[PowerManager] 2025/10/09 10:21:10.614646 📊 Calculating maximum volume from 96 data points...\n",
      "[PowerManager] 2025/10/09 10:21:10.614648 ✅ Maximum volume calculated: 120.6 MWh at period 17:15-17:30\n",
      "[PowerManager] 2025/10/09 10:21:10.614651 ✅ Successfully loaded 96 market data points for 2025-10-09\n",
      "[PowerManager] 2025/10/09 10:21:10.614652    📊 Sample data points:\n",
      "[PowerManager] 2025/10/09 10:21:10.614655       00:00-00:15: 68.2 MWh @ 95.69 €/MWh\n",
      "[PowerManager] 2025/10/09 10:21:10.614658       00:15-00:30: 62.8 MWh @ 95.02 €/MWh\n",
      "[PowerManager] 2025/10/09 10:21:10.614661       00:30-00:45: 61.9 MWh @ 88.00 €/MWh\n",
      "[PowerManager] 2025/10/09 10:21:10.614663       ... and 93 more data points\n",
      "[PowerManager] 2025/10/09 10:21:10.614665 🔧 Initializing Kubernetes node 'paradoxe-32'...\n",
      "[PowerManager] 2025/10/09 10:21:10.629718 ✅ Successfully retrieved node 'paradoxe-32'\n",
      "[PowerManager] 2025/10/09 10:21:10.629740 🚀 Node 'paradoxe-32' not initialized, proceeding with initialization...\n",
      "[PowerManager] 2025/10/09 10:21:10.629747 ⚡ Finding maximum power value from RAPL domains...\n",
      "[PowerManager] 2025/10/09 10:21:10.629751 🔍 Searching for maximum power value across 2 RAPL domains...\n",
      "[PowerManager] 2025/10/09 10:21:10.629755    📊 Checking domain intel-rapl:0...\n",
      "[PowerManager] 2025/10/09 10:21:10.629761       🔋 Found higher power constraint: 194000000 µW (194.0 W) from /sys/devices/virtual/powercap/intel-rapl/intel-rapl:0/constraint_0_power_limit_uw\n",
      "[PowerManager] 2025/10/09 10:21:10.629770       🔋 Found higher max constraint: 652000000 µW (652.0 W) from /sys/devices/virtual/powercap/intel-rapl/intel-rapl:0/constraint_1_max_power_uw\n",
      "[PowerManager] 2025/10/09 10:21:10.629776    📊 Checking domain intel-rapl:1...\n",
      "[PowerManager] 2025/10/09 10:21:10.629780 ✅ Maximum power value determined: 652000000 µW (652.0 W) from /sys/devices/virtual/powercap/intel-rapl/intel-rapl:0/constraint_1_max_power_uw\n",
      "[PowerManager] 2025/10/09 10:21:10.629784 ✅ Found maximum power value: 652000000 µW (652.0 W)\n",
      "[PowerManager] 2025/10/09 10:21:10.629789 📝 Setting node annotations...\n",
      "[PowerManager] 2025/10/09 10:21:10.629794    - rapl/max_power_uw: 652000000\n",
      "[PowerManager] 2025/10/09 10:21:10.629797    - rapl/pmax: 652000000\n",
      "[PowerManager] 2025/10/09 10:21:10.629801    - rapl/provider: epex\n",
      "[PowerManager] 2025/10/09 10:21:10.629804 🏷️  Marking node as initialized...\n",
      "[PowerManager] 2025/10/09 10:21:10.642539 ✅ Node 'paradoxe-32' initialized successfully with max power: 652000000 µW (652.0 W)\n",
      "[PowerManager] 2025/10/09 10:21:10.642570 Power management system ready - starting main cycle\n",
      "[PowerManager] 2025/10/09 10:21:10.642578 Starting power management cycle...\n",
      "[PowerManager] 2025/10/09 10:21:10.642597 Next data refresh scheduled in 13h38m49.357410451s (at 2025-10-10 00:00:00)\n",
      "[PowerManager] 2025/10/09 10:21:10.642615 🔄 Starting power cap adjustment cycle...\n",
      "[PowerManager] 2025/10/09 10:21:10.647161 ⏰ Current time: 10:21:10 (period: 10:15-10:30)\n",
      "[PowerManager] 2025/10/09 10:21:10.647176 📊 Market data: 96 points available, max volume: 120.6 MWh\n",
      "[PowerManager] 2025/10/09 10:21:10.647188 ⚡ Retrieving RAPL max power...\n",
      "[PowerManager] 2025/10/09 10:21:10.647195 ✅ RAPL max power: 652000000 µW (652.0 W)\n",
      "[PowerManager] 2025/10/09 10:21:10.647202 🧮 Calculating source power using market data...\n",
      "[PowerManager] 2025/10/09 10:21:10.647209 ✅ Calculated source power: 327621891 µW (327.6 W)\n",
      "[PowerManager] 2025/10/09 10:21:10.647215 🎯 Determining final power limit to apply...\n",
      "[PowerManager] 2025/10/09 10:21:10.647219    Starting with minimum: 20000000 µW (20.0 W)\n",
      "[PowerManager] 2025/10/09 10:21:10.647225    ✅ Using calculated source power: 327621891 µW (327.6 W)\n",
      "[PowerManager] 2025/10/09 10:21:10.647231 📋 Power calculation summary:\n",
      "[PowerManager] 2025/10/09 10:21:10.647235    - Period: 10:15-10:30\n",
      "[PowerManager] 2025/10/09 10:21:10.647239    - Source Power: 327621891 µW (327.6 W)\n",
      "[PowerManager] 2025/10/09 10:21:10.647244    - Max Hardware: 652000000 µW (652.0 W)\n",
      "[PowerManager] 2025/10/09 10:21:10.647249    - Min Threshold: 20000000 µW (20.0 W)\n",
      "[PowerManager] 2025/10/09 10:21:10.647254    - Applied Limit: 327621891 µW (327.6 W)\n",
      "[PowerManager] 2025/10/09 10:21:10.647259 ⚡ Applying power limits to RAPL domains...\n",
      "\n",
      "--- 7. Événements récents liés à powercap-manager ---\n",
      "60m         Normal   Scheduled          pod/powercap-manager-t4lvv   Successfully assigned default/powercap-manager-t4lvv to paradoxe-27\n",
      "60m         Normal   SuccessfulCreate   daemonset/powercap-manager   Created pod: powercap-manager-t4lvv\n",
      "60m         Normal   SuccessfulCreate   daemonset/powercap-manager   Created pod: powercap-manager-vxgq4\n",
      "60m         Normal   Pulling            pod/powercap-manager-vxgq4   Pulling image \"ghcr.io/menraromial/powercap:latest\"\n",
      "60m         Normal   Scheduled          pod/powercap-manager-vxgq4   Successfully assigned default/powercap-manager-vxgq4 to paradoxe-32\n",
      "60m         Normal   Pulling            pod/powercap-manager-t4lvv   Pulling image \"ghcr.io/menraromial/powercap:latest\"\n",
      "60m         Normal   Pulled             pod/powercap-manager-vxgq4   Successfully pulled image \"ghcr.io/menraromial/powercap:latest\" in 2.47s (2.47s including waiting). Image size: 44675895 bytes.\n",
      "60m         Normal   Pulled             pod/powercap-manager-t4lvv   Successfully pulled image \"ghcr.io/menraromial/powercap:latest\" in 2.435s (2.435s including waiting). Image size: 44675895 bytes.\n",
      "60m         Normal   Started            pod/powercap-manager-vxgq4   Started container powercap-manager\n",
      "60m         Normal   Created            pod/powercap-manager-vxgq4   Created container powercap-manager\n",
      "60m         Normal   Started            pod/powercap-manager-t4lvv   Started container powercap-manager\n",
      "60m         Normal   Created            pod/powercap-manager-t4lvv   Created container powercap-manager\n",
      "2m20s       Normal   Killing            pod/powercap-manager-t4lvv   Stopping container powercap-manager\n",
      "2m20s       Normal   Killing            pod/powercap-manager-vxgq4   Stopping container powercap-manager\n",
      "51s         Normal   SuccessfulCreate   daemonset/powercap-manager   Created pod: powercap-manager-8qh7b\n",
      "51s         Normal   SuccessfulCreate   daemonset/powercap-manager   Created pod: powercap-manager-mjk5f\n",
      "51s         Normal   Scheduled          pod/powercap-manager-8qh7b   Successfully assigned default/powercap-manager-8qh7b to paradoxe-27\n",
      "51s         Normal   Scheduled          pod/powercap-manager-mjk5f   Successfully assigned default/powercap-manager-mjk5f to paradoxe-32\n",
      "50s         Normal   Pulling            pod/powercap-manager-mjk5f   Pulling image \"ghcr.io/menraromial/powercap:latest\"\n",
      "50s         Normal   Pulling            pod/powercap-manager-8qh7b   Pulling image \"ghcr.io/menraromial/powercap:latest\"\n",
      "47s         Normal   Started            pod/powercap-manager-mjk5f   Started container powercap-manager\n",
      "47s         Normal   Created            pod/powercap-manager-mjk5f   Created container powercap-manager\n",
      "47s         Normal   Pulled             pod/powercap-manager-8qh7b   Successfully pulled image \"ghcr.io/menraromial/powercap:latest\" in 3.342s (3.342s including waiting). Image size: 44676213 bytes.\n",
      "47s         Normal   Created            pod/powercap-manager-8qh7b   Created container powercap-manager\n",
      "47s         Normal   Started            pod/powercap-manager-8qh7b   Started container powercap-manager\n",
      "47s         Normal   Pulled             pod/powercap-manager-mjk5f   Successfully pulled image \"ghcr.io/menraromial/powercap:latest\" in 3.742s (3.742s including waiting). Image size: 44676213 bytes.\n",
      "\n",
      "--- 8. Vérification de l'accès aux ressources système ---\n",
      "Test d'accès RAPL sur le pod: powercap-manager-8qh7b\n",
      "total 0\n",
      "drwxr-xr-x    4 root     root             0 Oct  9 08:56 .\n",
      "drwxr-xr-x   19 root     root             0 Oct  9 08:56 ..\n",
      "drwxr-xr-x    3 root     root             0 Oct  9 08:56 dtpm\n",
      "drwxr-xr-x    5 root     root             0 Oct  9 08:56 intel-rapl\n",
      "\n",
      "--- 9. Vérification de la ConfigMap ---\n",
      "apiVersion: v1\n",
      "data:\n",
      "  ALPHA: \"4\"\n",
      "  DATA_PROVIDER: epex\n",
      "  DATA_REFRESH_CRON: 0 0 * * *\n",
      "  MAX_SOURCE: \"100000000\"\n",
      "  PROVIDER_PARAMS: |\n",
      "    {\n",
      "      \"market_area\": \"FR\",\n",
      "      \"auction\": \"IDA1\",\n",
      "      \"modality\": \"Auction\",\n",
      "      \"sub_modality\": \"Intraday\",\n",
      "      \"data_mode\": \"table\"\n",
      "    }\n",
      "  PROVIDER_URL: https://www.epexspot.com/en/market-results\n",
      "  RAPL_MIN_POWER: \"20000000\"\n",
      "  STABILISATION_TIME: \"300\"\n",
      "  TIMEZONE: Europe/Paris\n",
      "  TZ: Europe/Paris\n",
      "kind: ConfigMap\n",
      "metadata:\n",
      "  annotations:\n",
      "    kubectl.kubernetes.io/last-applied-configuration: |\n",
      "      {\"apiVersion\":\"v1\",\"data\":{\"ALPHA\":\"4\",\"DATA_PROVIDER\":\"epex\",\"DATA_REFRESH_CRON\":\"0 0 * * *\",\"MAX_SOURCE\":\"100000000\",\"PROVIDER_PARAMS\":\"{\\n  \\\"market_area\\\": \\\"FR\\\",\\n  \\\"auction\\\": \\\"IDA1\\\",\\n  \\\"modality\\\": \\\"Auction\\\",\\n  \\\"sub_modality\\\": \\\"Intraday\\\",\\n  \\\"data_mode\\\": \\\"table\\\"\\n}\\n\",\"PROVIDER_URL\":\"https://www.epexspot.com/en/market-results\",\"RAPL_MIN_POWER\":\"20000000\",\"STABILISATION_TIME\":\"300\",\"TIMEZONE\":\"Europe/Paris\",\"TZ\":\"Europe/Paris\"},\"kind\":\"ConfigMap\",\"metadata\":{\"annotations\":{},\"labels\":{\"app.kubernetes.io/component\":\"power-management\",\"app.kubernetes.io/name\":\"powercap-manager\",\"app.kubernetes.io/version\":\"v1.0.0\"},\"name\":\"powercap-config\",\"namespace\":\"default\"}}\n",
      "  creationTimestamp: \"2025-10-09T08:21:05Z\"\n",
      "  labels:\n",
      "    app.kubernetes.io/component: power-management\n",
      "    app.kubernetes.io/name: powercap-manager\n",
      "    app.kubernetes.io/version: v1.0.0\n",
      "  name: powercap-config\n",
      "  namespace: default\n",
      "  resourceVersion: \"9879\"\n",
      "  uid: cf64b908-6770-4e95-820c-8f415faf2568\n",
      "\n",
      "--- 10. Vérification des erreurs critiques ---\n",
      "\n",
      "========================================================================\n",
      "✅ Vérification terminée\n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "# Script pour vérifier l'état détaillé et afficher les logs\n",
    "CHECK_POWERCAP_STATUS_LOGS = \"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "echo \"========================================================================\"\n",
    "echo \"📊 VÉRIFICATION DÉTAILLÉE - État et Logs PowerCap Manager\"\n",
    "echo \"========================================================================\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 1. État du DaemonSet powercap-manager ---\"\n",
    "kubectl get daemonset powercap-manager -n default -o wide\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 2. Détails du DaemonSet ---\"\n",
    "kubectl describe daemonset powercap-manager -n default | head -50\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 3. Liste des pods powercap-manager sur tous les nœuds ---\"\n",
    "kubectl get pods -n default -l app=powercap-manager -o wide\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 4. Nombre de pods actifs par rapport au nombre attendu ---\"\n",
    "DESIRED=$(kubectl get daemonset powercap-manager -n default -o jsonpath='{.status.desiredNumberScheduled}')\n",
    "READY=$(kubectl get daemonset powercap-manager -n default -o jsonpath='{.status.numberReady}')\n",
    "AVAILABLE=$(kubectl get daemonset powercap-manager -n default -o jsonpath='{.status.numberAvailable}')\n",
    "echo \"Pods désirés: $DESIRED\"\n",
    "echo \"Pods prêts: $READY\"\n",
    "echo \"Pods disponibles: $AVAILABLE\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 5. Description détaillée de chaque pod ---\"\n",
    "POWERCAP_PODS=$(kubectl get pods -n default -l app=powercap-manager -o jsonpath='{.items[*].metadata.name}')\n",
    "\n",
    "if [ -n \"$POWERCAP_PODS\" ]; then\n",
    "    for pod in $POWERCAP_PODS; do\n",
    "        echo \"\"\n",
    "        echo \"==========================================\"\n",
    "        echo \"Pod: $pod\"\n",
    "        echo \"==========================================\"\n",
    "        \n",
    "        echo \"\"\n",
    "        echo \"--- État général ---\"\n",
    "        kubectl get pod $pod -n default -o wide\n",
    "        \n",
    "        echo \"\"\n",
    "        echo \"--- Nœud d'exécution ---\"\n",
    "        NODE=$(kubectl get pod $pod -n default -o jsonpath='{.spec.nodeName}')\n",
    "        echo \"Nœud: $NODE\"\n",
    "        \n",
    "        echo \"\"\n",
    "        echo \"--- Statut du conteneur ---\"\n",
    "        kubectl get pod $pod -n default -o jsonpath='{range .status.containerStatuses[*]}Conteneur: {.name}\n",
    "Ready: {.ready}\n",
    "Restarts: {.restartCount}\n",
    "Image: {.image}\n",
    "{end}'\n",
    "        \n",
    "        echo \"\"\n",
    "        echo \"--- Conditions du pod ---\"\n",
    "        kubectl get pod $pod -n default -o jsonpath='{range .status.conditions[*]}{.type}: {.status} ({.reason})\n",
    "{end}'\n",
    "    done\n",
    "else\n",
    "    echo \"❌ Aucun pod powercap-manager trouvé dans le namespace default\"\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 6. Logs de tous les pods powercap-manager ---\"\n",
    "if [ -n \"$POWERCAP_PODS\" ]; then\n",
    "    for pod in $POWERCAP_PODS; do\n",
    "        echo \"\"\n",
    "        echo \"==========================================\"\n",
    "        echo \"📝 LOGS du pod: $pod\"\n",
    "        echo \"==========================================\"\n",
    "        kubectl logs $pod -n default --tail=100 2>&1 || echo \"Impossible de récupérer les logs\"\n",
    "    done\n",
    "else\n",
    "    echo \"❌ Aucun log à afficher\"\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 7. Événements récents liés à powercap-manager ---\"\n",
    "kubectl get events -n default --sort-by='.lastTimestamp' | grep powercap | tail -30 || echo \"Aucun événement récent\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 8. Vérification de l'accès aux ressources système ---\"\n",
    "if [ -n \"$POWERCAP_PODS\" ]; then\n",
    "    # Test sur le premier pod\n",
    "    FIRST_POD=$(echo $POWERCAP_PODS | awk '{print $1}')\n",
    "    echo \"Test d'accès RAPL sur le pod: $FIRST_POD\"\n",
    "    kubectl exec $FIRST_POD -n default -- ls -la /sys/devices/virtual/powercap/ 2>&1 || echo \"❌ Impossible d'accéder au répertoire RAPL\"\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 9. Vérification de la ConfigMap ---\"\n",
    "kubectl get configmap powercap-config -n default -o yaml\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 10. Vérification des erreurs critiques ---\"\n",
    "if [ -n \"$POWERCAP_PODS\" ]; then\n",
    "    for pod in $POWERCAP_PODS; do\n",
    "        STATUS=$(kubectl get pod $pod -n default -o jsonpath='{.status.phase}')\n",
    "        if [ \"$STATUS\" != \"Running\" ]; then\n",
    "            echo \"\"\n",
    "            echo \"⚠️  ATTENTION: Pod $pod est en état: $STATUS\"\n",
    "            echo \"Raison:\"\n",
    "            kubectl get pod $pod -n default -o jsonpath='{.status.conditions[?(@.type==\"Ready\")].message}'\n",
    "            echo \"\"\n",
    "            echo \"Logs d'erreur:\"\n",
    "            kubectl logs $pod -n default --tail=20 2>&1\n",
    "        fi\n",
    "    done\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"========================================================================\"\n",
    "echo \"✅ Vérification terminée\"\n",
    "echo \"========================================================================\"\n",
    "\"\"\"\n",
    "\n",
    "print(\"🔍 Lancement de la vérification détaillée de l'état et des logs PowerCap...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(CHECK_POWERCAP_STATUS_LOGS)\n",
    "\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9074831",
   "metadata": {},
   "source": [
    "## Vérification des Annotations des Nœuds par PowerCap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68b89add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77ddd78e9e14c1cab043796c18159da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\.'\n",
      "/tmp/ipykernel_2127663/1530325844.py:2: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  CHECK_NODE_ANNOTATIONS_SCRIPT = \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏷️  Vérification des annotations des nœuds...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "🏷️  VÉRIFICATION DES ANNOTATIONS DES NŒUDS\n",
      "========================================================================\n",
      "\n",
      "--- Liste de tous les nœuds du cluster ---\n",
      "NAME          STATUS   ROLES           AGE   VERSION\n",
      "paradoxe-2    Ready    control-plane   23m   v1.30.0\n",
      "paradoxe-27   Ready    <none>          23m   v1.30.0\n",
      "paradoxe-32   Ready    <none>          23m   v1.30.0\n",
      "\n",
      "--- Annotations complètes de tous les nœuds ---\n",
      "\n",
      "==========================================\n",
      "📍 Nœud: paradoxe-2\n",
      "==========================================\n",
      "\n",
      "--- Type de nœud ---\n",
      "Type: Master/Control-Plane\n",
      "\n",
      "--- Toutes les annotations ---\n",
      "{\n",
      "  \"kubeadm.alpha.kubernetes.io/cri-socket\": \"unix:///var/run/crio/crio.sock\",\n",
      "  \"node.alpha.kubernetes.io/ttl\": \"0\",\n",
      "  \"projectcalico.org/IPv4Address\": \"172.16.101.2/20\",\n",
      "  \"projectcalico.org/IPv4IPIPTunnelAddr\": \"192.168.14.128\",\n",
      "  \"volumes.kubernetes.io/controller-managed-attach-detach\": \"true\"\n",
      "}\n",
      "\n",
      "--- Annotations spécifiques à PowerCap (filtrées) ---\n",
      "\n",
      "==========================================\n",
      "📍 Nœud: paradoxe-27\n",
      "==========================================\n",
      "\n",
      "--- Type de nœud ---\n",
      "Type: Master/Control-Plane\n",
      "\n",
      "--- Toutes les annotations ---\n",
      "{\n",
      "  \"kubeadm.alpha.kubernetes.io/cri-socket\": \"unix:///var/run/crio/crio.sock\",\n",
      "  \"node.alpha.kubernetes.io/ttl\": \"0\",\n",
      "  \"power-manager/initialized\": \"kcas-power-manager\",\n",
      "  \"projectcalico.org/IPv4Address\": \"172.16.101.27/20\",\n",
      "  \"projectcalico.org/IPv4IPIPTunnelAddr\": \"192.168.152.0\",\n",
      "  \"rapl/last-update\": \"2025-10-09T07:21:20Z\",\n",
      "  \"rapl/market-period\": \"07:15-07:30\",\n",
      "  \"rapl/market-price\": \"94.91\",\n",
      "  \"rapl/market-volume\": \"43.6\",\n",
      "  \"rapl/max_power_uw\": \"652000000\",\n",
      "  \"rapl/pmax\": \"235714760\",\n",
      "  \"rapl/provider\": \"epex\",\n",
      "  \"volumes.kubernetes.io/controller-managed-attach-detach\": \"true\"\n",
      "}\n",
      "\n",
      "--- Annotations spécifiques à PowerCap (filtrées) ---\n",
      "power-manager/initialized: kcas-power-manager\n",
      "rapl/last-update: 2025-10-09T07:21:20Z\n",
      "rapl/market-period: 07:15-07:30\n",
      "rapl/market-price: 94.91\n",
      "rapl/market-volume: 43.6\n",
      "rapl/max_power_uw: 652000000\n",
      "rapl/pmax: 235714760\n",
      "rapl/provider: epex\n",
      "\n",
      "==========================================\n",
      "📍 Nœud: paradoxe-32\n",
      "==========================================\n",
      "\n",
      "--- Type de nœud ---\n",
      "Type: Master/Control-Plane\n",
      "\n",
      "--- Toutes les annotations ---\n",
      "{\n",
      "  \"kubeadm.alpha.kubernetes.io/cri-socket\": \"unix:///var/run/crio/crio.sock\",\n",
      "  \"node.alpha.kubernetes.io/ttl\": \"0\",\n",
      "  \"power-manager/initialized\": \"kcas-power-manager\",\n",
      "  \"projectcalico.org/IPv4Address\": \"172.16.101.32/20\",\n",
      "  \"projectcalico.org/IPv4IPIPTunnelAddr\": \"192.168.25.64\",\n",
      "  \"rapl/last-update\": \"2025-10-09T07:21:20Z\",\n",
      "  \"rapl/market-period\": \"07:15-07:30\",\n",
      "  \"rapl/market-price\": \"94.91\",\n",
      "  \"rapl/market-volume\": \"43.6\",\n",
      "  \"rapl/max_power_uw\": \"652000000\",\n",
      "  \"rapl/pmax\": \"235714760\",\n",
      "  \"rapl/provider\": \"epex\",\n",
      "  \"volumes.kubernetes.io/controller-managed-attach-detach\": \"true\"\n",
      "}\n",
      "\n",
      "--- Annotations spécifiques à PowerCap (filtrées) ---\n",
      "power-manager/initialized: kcas-power-manager\n",
      "rapl/last-update: 2025-10-09T07:21:20Z\n",
      "rapl/market-period: 07:15-07:30\n",
      "rapl/market-price: 94.91\n",
      "rapl/market-volume: 43.6\n",
      "rapl/max_power_uw: 652000000\n",
      "rapl/pmax: 235714760\n",
      "rapl/provider: epex\n",
      "\n",
      "--- Récapitulatif : Annotations PowerCap par nœud ---\n",
      "NAME          ANNOTATIONS\n",
      "paradoxe-2    map[kubeadm.alpha.kubernetes.io/cri-socket:unix:///var/run/crio/crio.sock node.alpha.kubernetes.io/ttl:0 projectcalico.org/IPv4Address:172.16.101.2/20 projectcalico.org/IPv4IPIPTunnelAddr:192.168.14.128 volumes.kubernetes.io/controller-managed-attach-detach:true]\n",
      "paradoxe-27   map[kubeadm.alpha.kubernetes.io/cri-socket:unix:///var/run/crio/crio.sock node.alpha.kubernetes.io/ttl:0 power-manager/initialized:kcas-power-manager projectcalico.org/IPv4Address:172.16.101.27/20 projectcalico.org/IPv4IPIPTunnelAddr:192.168.152.0 rapl/last-update:2025-10-09T07:21:20Z rapl/market-period:07:15-07:30 rapl/market-price:94.91 rapl/market-volume:43.6 rapl/max_power_uw:652000000 rapl/pmax:235714760 rapl/provider:epex volumes.kubernetes.io/controller-managed-attach-detach:true]\n",
      "paradoxe-32   map[kubeadm.alpha.kubernetes.io/cri-socket:unix:///var/run/crio/crio.sock node.alpha.kubernetes.io/ttl:0 power-manager/initialized:kcas-power-manager projectcalico.org/IPv4Address:172.16.101.32/20 projectcalico.org/IPv4IPIPTunnelAddr:192.168.25.64 rapl/last-update:2025-10-09T07:21:20Z rapl/market-period:07:15-07:30 rapl/market-price:94.91 rapl/market-volume:43.6 rapl/max_power_uw:652000000 rapl/pmax:235714760 rapl/provider:epex volumes.kubernetes.io/controller-managed-attach-detach:true]\n",
      "\n",
      "========================================================================\n",
      "✅ Vérification des annotations terminée\n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "# Script pour vérifier les annotations ajoutées par PowerCap sur les nœuds\n",
    "CHECK_NODE_ANNOTATIONS_SCRIPT = \"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "echo \"========================================================================\"\n",
    "echo \"🏷️  VÉRIFICATION DES ANNOTATIONS DES NŒUDS\"\n",
    "echo \"========================================================================\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Liste de tous les nœuds du cluster ---\"\n",
    "kubectl get nodes\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Annotations complètes de tous les nœuds ---\"\n",
    "for node in $(kubectl get nodes -o jsonpath='{.items[*].metadata.name}'); do\n",
    "    echo \"\"\n",
    "    echo \"==========================================\"\n",
    "    echo \"📍 Nœud: $node\"\n",
    "    echo \"==========================================\"\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"--- Type de nœud ---\"\n",
    "    kubectl get node $node -o jsonpath='{.metadata.labels.node-role\\.kubernetes\\.io/control-plane}' > /dev/null 2>&1 && echo \"Type: Master/Control-Plane\" || echo \"Type: Worker\"\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"--- Toutes les annotations ---\"\n",
    "    kubectl get node $node -o jsonpath='{.metadata.annotations}' | jq '.' 2>/dev/null || kubectl get node $node -o jsonpath='{.metadata.annotations}'\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"--- Annotations spécifiques à PowerCap (filtrées) ---\"\n",
    "    kubectl get node $node -o json | jq -r '.metadata.annotations | to_entries[] | select(.key | contains(\"power\") or contains(\"rapl\") or contains(\"energy\") or contains(\"cap\")) | \"\\(.key): \\(.value)\"' 2>/dev/null || echo \"Aucune annotation PowerCap trouvée ou jq non disponible\"\n",
    "done\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Récapitulatif : Annotations PowerCap par nœud ---\"\n",
    "kubectl get nodes -o custom-columns=NAME:.metadata.name,ANNOTATIONS:.metadata.annotations 2>/dev/null || echo \"Format custom-columns non supporté\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"========================================================================\"\n",
    "echo \"✅ Vérification des annotations terminée\"\n",
    "echo \"========================================================================\"\n",
    "\"\"\"\n",
    "\n",
    "print(\"🏷️  Vérification des annotations des nœuds...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(CHECK_NODE_ANNOTATIONS_SCRIPT)\n",
    "\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644ef55d",
   "metadata": {},
   "source": [
    "## Suppression du DaemonSet PowerCap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a85425d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e31188320645c1b07ee96aa6a6f999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Vérification/copie du répertoire 'powercap' vers le master...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">copy</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mcopy\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e0e605933740fdbaf17c7f26730cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Répertoire copié/mis à jour sur le master.\n",
      "🗑️  Lancement de la suppression de PowerCap...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ed309790be4762aa59103e849c333f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "🗑️  SUPPRESSION des Ressources PowerCap\n",
      "========================================================================\n",
      "\n",
      "--- Suppression de toutes les ressources via les manifestes ---\n",
      "configmap \"powercap-config\" deleted\n",
      "daemonset.apps \"powercap-manager\" deleted\n",
      "serviceaccount \"powercap-manager\" deleted\n",
      "clusterrole.rbac.authorization.k8s.io \"powercap-manager\" deleted\n",
      "clusterrolebinding.rbac.authorization.k8s.io \"powercap-manager\" deleted\n",
      "\n",
      "--- Attente de la suppression des pods (10 secondes) ---\n",
      "\n",
      "--- Suppression des annotations PowerCap sur les nœuds ---\n",
      "Nettoyage des annotations sur le nœud: paradoxe-2\n",
      "node/paradoxe-2 annotated\n",
      "node/paradoxe-2 annotated\n",
      "node/paradoxe-2 annotated\n",
      "node/paradoxe-2 annotated\n",
      "node/paradoxe-2 annotated\n",
      "node/paradoxe-2 annotated\n",
      "node/paradoxe-2 annotated\n",
      "node/paradoxe-2 annotated\n",
      "Nettoyage des annotations sur le nœud: paradoxe-27\n",
      "node/paradoxe-27 annotated\n",
      "node/paradoxe-27 annotated\n",
      "node/paradoxe-27 annotated\n",
      "node/paradoxe-27 annotated\n",
      "node/paradoxe-27 annotated\n",
      "node/paradoxe-27 annotated\n",
      "node/paradoxe-27 annotated\n",
      "node/paradoxe-27 annotated\n",
      "Nettoyage des annotations sur le nœud: paradoxe-32\n",
      "node/paradoxe-32 annotated\n",
      "node/paradoxe-32 annotated\n",
      "node/paradoxe-32 annotated\n",
      "node/paradoxe-32 annotated\n",
      "node/paradoxe-32 annotated\n",
      "node/paradoxe-32 annotated\n",
      "node/paradoxe-32 annotated\n",
      "node/paradoxe-32 annotated\n",
      "✅ Annotations PowerCap supprimées de tous les nœuds\n",
      "\n",
      "--- Vérification finale ---\n",
      "\n",
      "DaemonSets restants avec 'powercap' :\n",
      "✅ Aucun DaemonSet trouvé\n",
      "\n",
      "Pods restants avec 'powercap' :\n",
      "\n",
      "ConfigMaps restantes avec 'powercap' :\n",
      "✅ Aucune ConfigMap trouvée\n",
      "\n",
      "ServiceAccounts restants avec 'powercap' :\n",
      "✅ Aucun ServiceAccount trouvé\n",
      "\n",
      "ClusterRoles restants avec 'powercap' :\n",
      "✅ Aucun ClusterRole trouvé\n",
      "\n",
      "ClusterRoleBindings restants avec 'powercap' :\n",
      "✅ Aucun ClusterRoleBinding trouvé\n",
      "\n",
      "--- Vérification des annotations restantes ---\n",
      "Annotations PowerCap/RAPL restantes sur les nœuds:\n",
      "\n",
      "Nœud: paradoxe-2\n",
      "\n",
      "Nœud: paradoxe-27\n",
      "\n",
      "Nœud: paradoxe-32\n",
      "\n",
      "========================================================================\n",
      "✅ Suppression de PowerCap terminée !\n",
      "========================================================================\n",
      "\n",
      "--- Nettoyage des données sur les nœuds workers ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-27.rennes.grid5000.fr'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-32.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-27.rennes.grid5000.fr'\u001b[0m, \n",
       "\u001b[32m'paradoxe-32.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Toutes les ressources PowerCap ont été supprimées du cluster !\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Vérifier si le dossier local existe, sinon afficher une erreur\n",
    "source_dir = \"powercap\"\n",
    "dest_dir = \"/tmp/powercap\"\n",
    "\n",
    "if not os.path.isdir(source_dir):\n",
    "    print(f\"❌ Le répertoire local '{source_dir}' n'existe pas.\")\n",
    "    print(\"💡 Créez le dossier avec les manifestes avant de supprimer les ressources.\")\n",
    "    raise FileNotFoundError(f\"Le répertoire '{source_dir}' est introuvable.\")\n",
    "\n",
    "# --- Copier le répertoire vers le master (au cas où il n'existe plus sur le master) ---\n",
    "print(f\"📁 Vérification/copie du répertoire '{source_dir}' vers le master...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.copy(src=source_dir, dest=\"/tmp/\")\n",
    "\n",
    "if p.results and p.results[0].status == \"OK\":\n",
    "    print(\"✅ Répertoire copié/mis à jour sur le master.\")\n",
    "\n",
    "# Script pour supprimer complètement le DaemonSet PowerCap en utilisant les manifestes\n",
    "DELETE_POWERCAP_SCRIPT = f\"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "echo \"========================================================================\"\n",
    "echo \"🗑️  SUPPRESSION des Ressources PowerCap\"\n",
    "echo \"========================================================================\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Suppression de toutes les ressources via les manifestes ---\"\n",
    "kubectl delete -f {dest_dir}/ --ignore-not-found=true\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Attente de la suppression des pods (10 secondes) ---\"\n",
    "sleep 10\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Suppression des annotations PowerCap sur les nœuds ---\"\n",
    "for node in $(kubectl get nodes -o jsonpath='{{.items[*].metadata.name}}'); do\n",
    "    echo \"Nettoyage des annotations sur le nœud: $node\"\n",
    "    \n",
    "    # Suppression de chaque annotation PowerCap (avec 2>&1 pour voir les erreurs)\n",
    "    kubectl annotate node $node power-manager/initialized- 2>&1 || true\n",
    "    kubectl annotate node $node rapl/last-update- 2>&1 || true\n",
    "    kubectl annotate node $node rapl/market-period- 2>&1 || true\n",
    "    kubectl annotate node $node rapl/market-price- 2>&1 || true\n",
    "    kubectl annotate node $node rapl/market-volume- 2>&1 || true\n",
    "    kubectl annotate node $node rapl/max_power_uw- 2>&1 || true\n",
    "    kubectl annotate node $node rapl/pmax- 2>&1 || true\n",
    "    kubectl annotate node $node rapl/provider- 2>&1 || true\n",
    "done\n",
    "echo \"✅ Annotations PowerCap supprimées de tous les nœuds\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification finale ---\"\n",
    "echo \"\"\n",
    "echo \"DaemonSets restants avec 'powercap' :\"\n",
    "kubectl get daemonsets -n default | grep powercap || echo \"✅ Aucun DaemonSet trouvé\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"Pods restants avec 'powercap' :\"\n",
    "kubectl get pods -n default -l app=powercap-manager || echo \"✅ Aucun pod trouvé\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"ConfigMaps restantes avec 'powercap' :\"\n",
    "kubectl get configmap -n default | grep powercap || echo \"✅ Aucune ConfigMap trouvée\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"ServiceAccounts restants avec 'powercap' :\"\n",
    "kubectl get serviceaccount -n default | grep powercap || echo \"✅ Aucun ServiceAccount trouvé\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"ClusterRoles restants avec 'powercap' :\"\n",
    "kubectl get clusterrole | grep powercap || echo \"✅ Aucun ClusterRole trouvé\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"ClusterRoleBindings restants avec 'powercap' :\"\n",
    "kubectl get clusterrolebinding | grep powercap || echo \"✅ Aucun ClusterRoleBinding trouvé\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification des annotations restantes ---\"\n",
    "echo \"Annotations PowerCap/RAPL restantes sur les nœuds:\"\n",
    "for node in $(kubectl get nodes -o jsonpath='{{.items[*].metadata.name}}'); do\n",
    "    echo \"\"\n",
    "    echo \"Nœud: $node\"\n",
    "    kubectl get node $node -o json | jq -r '.metadata.annotations | to_entries[] | select(.key | contains(\"power\") or contains(\"rapl\")) | \"  \\\\(.key): \\\\(.value)\"' 2>/dev/null || echo \"  Aucune annotation PowerCap/RAPL trouvée\"\n",
    "done\n",
    "\n",
    "echo \"\"\n",
    "echo \"========================================================================\"\n",
    "echo \"✅ Suppression de PowerCap terminée !\"\n",
    "echo \"========================================================================\"\n",
    "\"\"\"\n",
    "\n",
    "print(\"🗑️  Lancement de la suppression de PowerCap...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(DELETE_POWERCAP_SCRIPT)\n",
    "\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)\n",
    "\n",
    "# --- Nettoyage des données sur les workers ---\n",
    "print(\"\\n--- Nettoyage des données sur les nœuds workers ---\")\n",
    "CLEANUP_WORKERS_SCRIPT = \"\"\"\n",
    "#!/bin/bash\n",
    "echo \"Suppression des données PowerCap dans /var/lib/powercap...\"\n",
    "sudo rm -rf /var/lib/powercap/*.csv 2>/dev/null || true\n",
    "echo \"✅ Nettoyage terminé sur ce nœud\"\n",
    "\"\"\"\n",
    "\n",
    "with en.actions(roles=worker_nodes) as p:\n",
    "    p.shell(CLEANUP_WORKERS_SCRIPT)\n",
    "\n",
    "print(\"✅ Toutes les ressources PowerCap ont été supprimées du cluster !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce3c3d9",
   "metadata": {},
   "source": [
    "# Déploiement de Volta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27f8e683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9b2d945aa0434b9307fb5b36148f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fichiers Volta trouvés:\n",
      "   - Configuration: volta/volta-config.yaml\n",
      "   - Manifest: volta/volta.yaml\n",
      "\n",
      "--- Copie du fichier de configuration vers /etc/kubernetes/ sur le master... ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">copy</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mcopy\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cdb42dcff5749e5ac8fafd8adcecf48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fichier de configuration copié avec succès.\n",
      "\n",
      "--- Copie du manifest Volta vers le master... ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">copy</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mcopy\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86dab66479e9471ab5b620afbf49addd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Manifest Volta copié avec succès.\n",
      "\n",
      "--- Déploiement de Volta... ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "⚡ Déploiement de Volta Scheduler\n",
      "========================================================================\n",
      "\n",
      "--- Vérification du fichier de configuration ---\n",
      "✅ Fichier de configuration trouvé: /etc/kubernetes/volta-config.yaml\n",
      "-rw-r--r-- 1 root root 848 Oct  9 11:01 /etc/kubernetes/volta-config.yaml\n",
      "\n",
      "Contenu du fichier de configuration:\n",
      "apiVersion: kubescheduler.config.k8s.io/v1\n",
      "kind: KubeSchedulerConfiguration\n",
      "leaderElection:\n",
      "  # (Optional) Change true to false if you are not running a HA control-plane.\n",
      "  leaderElect: false\n",
      "clientConnection:\n",
      "  kubeconfig: /etc/kubernetes/scheduler.conf\n",
      "profiles:\n",
      "- schedulerName: volta-scheduler\n",
      "  plugins:\n",
      "    queueSort:\n",
      "      enabled:\n",
      "      - name: PrioritySort\n",
      "    preFilter:\n",
      "      disabled:\n",
      "      - name: \"*\"\n",
      "      enabled:\n",
      "      - name: Volta\n",
      "    filter:\n",
      "      disabled:\n",
      "\n",
      "--- Application du manifest Volta ---\n",
      "deployment.apps/volta-scheduler created\n",
      "\n",
      "--- Attente de 30 secondes pour le démarrage ---\n",
      "\n",
      "--- Vérification du déploiement volta-scheduler ---\n",
      "NAME              READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS        IMAGES                                       SELECTOR\n",
      "volta-scheduler   1/1     1            1           30s   volta-scheduler   ghcr.io/menraromial/volta-scheduler:v0.0.3   component=scheduler,tier=control-plane\n",
      "\n",
      "--- Vérification des pods Volta (component=scheduler) ---\n",
      "NAME                               READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATES\n",
      "volta-scheduler-57dd4b6f48-tdm9w   1/1     Running   0          30s   192.168.14.134   paradoxe-2   <none>           <none>\n",
      "\n",
      "--- Statut du déploiement Volta ---\n",
      "deployment \"volta-scheduler\" successfully rolled out\n",
      "\n",
      "--- Vérification de toutes les ressources liées à Volta ---\n",
      "pod/volta-scheduler-57dd4b6f48-tdm9w           1/1     Running   0          31s\n",
      "deployment.apps/volta-scheduler           1/1     1            1           31s\n",
      "replicaset.apps/volta-scheduler-57dd4b6f48           1         1         1       31s\n",
      "\n",
      "--- Événements récents liés à volta-scheduler ---\n",
      "14m         Normal    ScalingReplicaSet   deployment/volta-scheduler              Scaled up replica set volta-scheduler-57dd4b6f48 to 1\n",
      "14m         Normal    SuccessfulCreate    replicaset/volta-scheduler-57dd4b6f48   Created pod: volta-scheduler-57dd4b6f48-tzh2m\n",
      "14m         Normal    Scheduled           pod/volta-scheduler-57dd4b6f48-tzh2m    Successfully assigned kube-system/volta-scheduler-57dd4b6f48-tzh2m to paradoxe-2\n",
      "14m         Normal    Pulled              pod/volta-scheduler-57dd4b6f48-tzh2m    Successfully pulled image \"ghcr.io/menraromial/volta-scheduler:v0.0.3\" in 3.431s (3.431s including waiting). Image size: 76908634 bytes.\n",
      "14m         Normal    Pulled              pod/volta-scheduler-57dd4b6f48-tzh2m    Successfully pulled image \"ghcr.io/menraromial/volta-scheduler:v0.0.3\" in 1.34s (1.34s including waiting). Image size: 76908634 bytes.\n",
      "14m         Normal    Pulled              pod/volta-scheduler-57dd4b6f48-tzh2m    Successfully pulled image \"ghcr.io/menraromial/volta-scheduler:v0.0.3\" in 1.148s (1.148s including waiting). Image size: 76908634 bytes.\n",
      "13m         Normal    Pulled              pod/volta-scheduler-57dd4b6f48-tzh2m    Successfully pulled image \"ghcr.io/menraromial/volta-scheduler:v0.0.3\" in 1.242s (1.242s including waiting). Image size: 76908634 bytes.\n",
      "13m         Normal    Created             pod/volta-scheduler-57dd4b6f48-tzh2m    Created container volta-scheduler\n",
      "13m         Normal    Started             pod/volta-scheduler-57dd4b6f48-tzh2m    Started container volta-scheduler\n",
      "13m         Normal    Pulling             pod/volta-scheduler-57dd4b6f48-tzh2m    Pulling image \"ghcr.io/menraromial/volta-scheduler:v0.0.3\"\n",
      "13m         Normal    Pulled              pod/volta-scheduler-57dd4b6f48-tzh2m    Successfully pulled image \"ghcr.io/menraromial/volta-scheduler:v0.0.3\" in 1.493s (1.493s including waiting). Image size: 76908634 bytes.\n",
      "4m41s       Warning   BackOff             pod/volta-scheduler-57dd4b6f48-tzh2m    Back-off restarting failed container volta-scheduler in pod volta-scheduler-57dd4b6f48-tzh2m_kube-system(2e81275f-0e75-406a-a7b7-e39ffd098c9b)\n",
      "31s         Normal    Scheduled           pod/volta-scheduler-57dd4b6f48-tdm9w    Successfully assigned kube-system/volta-scheduler-57dd4b6f48-tdm9w to paradoxe-2\n",
      "31s         Normal    SuccessfulCreate    replicaset/volta-scheduler-57dd4b6f48   Created pod: volta-scheduler-57dd4b6f48-tdm9w\n",
      "31s         Normal    ScalingReplicaSet   deployment/volta-scheduler              Scaled up replica set volta-scheduler-57dd4b6f48 to 1\n",
      "30s         Normal    Pulling             pod/volta-scheduler-57dd4b6f48-tdm9w    Pulling image \"ghcr.io/menraromial/volta-scheduler:v0.0.3\"\n",
      "21s         Normal    Started             pod/volta-scheduler-57dd4b6f48-tdm9w    Started container volta-scheduler\n",
      "21s         Normal    Created             pod/volta-scheduler-57dd4b6f48-tdm9w    Created container volta-scheduler\n",
      "21s         Normal    Pulled              pod/volta-scheduler-57dd4b6f48-tdm9w    Successfully pulled image \"ghcr.io/menraromial/volta-scheduler:v0.0.3\" in 9.128s (9.128s including waiting). Image size: 76908634 bytes.\n",
      "\n",
      "--- Logs des pods volta-scheduler ---\n",
      "I1009 09:03:11.891129       1 eventhandlers.go:202] \"Add event for scheduled pod\" pod=\"monitoring/grafana-5997747455-tb8vf\"\n",
      "I1009 09:03:11.891150       1 eventhandlers.go:202] \"Add event for scheduled pod\" pod=\"monitoring/kube-state-metrics-756cd6cb9d-4qzx2\"\n",
      "I1009 09:03:11.891285       1 eventhandlers.go:202] \"Add event for scheduled pod\" pod=\"monitoring/node-exporter-72zzp\"\n",
      "I1009 09:03:11.891351       1 eventhandlers.go:202] \"Add event for scheduled pod\" pod=\"monitoring/node-exporter-flvhj\"\n",
      "I1009 09:03:11.891381       1 eventhandlers.go:202] \"Add event for scheduled pod\" pod=\"monitoring/node-exporter-jjprp\"\n",
      "I1009 09:03:11.891420       1 eventhandlers.go:202] \"Add event for scheduled pod\" pod=\"monitoring/prometheus-adapter-5794d7d9f5-fmqbd\"\n",
      "I1009 09:03:11.891463       1 eventhandlers.go:202] \"Add event for scheduled pod\" pod=\"monitoring/prometheus-adapter-5794d7d9f5-kz5r4\"\n",
      "I1009 09:03:11.891510       1 eventhandlers.go:202] \"Add event for scheduled pod\" pod=\"monitoring/prometheus-k8s-0\"\n",
      "I1009 09:03:11.891541       1 eventhandlers.go:202] \"Add event for scheduled pod\" pod=\"monitoring/prometheus-k8s-1\"\n",
      "I1009 09:03:11.891559       1 eventhandlers.go:202] \"Add event for scheduled pod\" pod=\"monitoring/prometheus-operator-56fd964fb9-c7tj9\"\n",
      "I1009 09:03:11.891613       1 round_trippers.go:553] GET https://172.16.101.2:6443/api/v1/pods?allowWatchBookmarks=true&fieldSelector=status.phase%21%3DSucceeded%2Cstatus.phase%21%3DFailed&resourceVersion=14181&timeout=5m51s&timeoutSeconds=351&watch=true 200 OK in 1 milliseconds\n",
      "I1009 09:03:11.891667       1 round_trippers.go:570] HTTP Statistics: GetConnection 0 ms ServerProcessing 1 ms Duration 1 ms\n",
      "I1009 09:03:11.891690       1 round_trippers.go:577] Response Headers:\n",
      "I1009 09:03:11.891711       1 round_trippers.go:580]     X-Kubernetes-Pf-Flowschema-Uid: b723cf8c-813c-45ba-87f0-c54cc0587670\n",
      "I1009 09:03:11.891726       1 round_trippers.go:580]     X-Kubernetes-Pf-Prioritylevel-Uid: 4fdc911b-004a-40fb-9ade-2aab205f2556\n",
      "I1009 09:03:11.891747       1 round_trippers.go:580]     Date: Thu, 09 Oct 2025 09:03:11 GMT\n",
      "I1009 09:03:11.891760       1 round_trippers.go:580]     Audit-Id: 1d2bc61a-1b96-4229-91cc-ac43087f7c78\n",
      "I1009 09:03:11.891772       1 round_trippers.go:580]     Cache-Control: no-cache, private\n",
      "I1009 09:03:11.891785       1 round_trippers.go:580]     Content-Type: application/vnd.kubernetes.protobuf;stream=watch\n",
      "I1009 09:03:11.943782       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file\n",
      "I1009 09:03:11.943903       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file\n",
      "I1009 09:03:11.944004       1 shared_informer.go:320] Caches are synced for RequestHeaderAuthRequestController\n",
      "I1009 09:03:11.944109       1 server.go:217] \"Handlers synced\"\n",
      "I1009 09:03:11.944161       1 tlsconfig.go:178] \"Loaded client CA\" index=0 certName=\"client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file\" certDetail=\"\\\"kubernetes\\\" [] validServingFor=[kubernetes] issuer=\\\"<self>\\\" (2025-10-09 06:55:31 +0000 UTC to 2035-10-07 07:00:31 +0000 UTC (now=2025-10-09 09:03:11.944126538 +0000 UTC))\"\n",
      "I1009 09:03:11.944611       1 tlsconfig.go:200] \"Loaded serving cert\" certName=\"Generated self signed cert\" certDetail=\"\\\"localhost@1760000591\\\" [serving] validServingFor=[127.0.0.1,localhost,localhost] issuer=\\\"localhost-ca@1760000591\\\" (2025-10-09 08:03:10 +0000 UTC to 2026-10-09 08:03:10 +0000 UTC (now=2025-10-09 09:03:11.944585281 +0000 UTC))\"\n",
      "I1009 09:03:11.944931       1 named_certificates.go:53] \"Loaded SNI cert\" index=0 certName=\"self-signed loopback\" certDetail=\"\\\"apiserver-loopback-client@1760000591\\\" [serving] validServingFor=[apiserver-loopback-client] issuer=\\\"apiserver-loopback-client-ca@1760000591\\\" (2025-10-09 08:03:11 +0000 UTC to 2026-10-09 08:03:11 +0000 UTC (now=2025-10-09 09:03:11.944909289 +0000 UTC))\"\n",
      "I1009 09:03:11.945063       1 tlsconfig.go:178] \"Loaded client CA\" index=0 certName=\"client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file\" certDetail=\"\\\"kubernetes\\\" [] validServingFor=[kubernetes] issuer=\\\"<self>\\\" (2025-10-09 06:55:31 +0000 UTC to 2035-10-07 07:00:31 +0000 UTC (now=2025-10-09 09:03:11.945045224 +0000 UTC))\"\n",
      "I1009 09:03:11.945107       1 tlsconfig.go:178] \"Loaded client CA\" index=1 certName=\"client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file\" certDetail=\"\\\"front-proxy-ca\\\" [] validServingFor=[front-proxy-ca] issuer=\\\"<self>\\\" (2025-10-09 06:55:31 +0000 UTC to 2035-10-07 07:00:31 +0000 UTC (now=2025-10-09 09:03:11.945090745 +0000 UTC))\"\n",
      "I1009 09:03:11.945456       1 tlsconfig.go:200] \"Loaded serving cert\" certName=\"Generated self signed cert\" certDetail=\"\\\"localhost@1760000591\\\" [serving] validServingFor=[127.0.0.1,localhost,localhost] issuer=\\\"localhost-ca@1760000591\\\" (2025-10-09 08:03:10 +0000 UTC to 2026-10-09 08:03:10 +0000 UTC (now=2025-10-09 09:03:11.94543606 +0000 UTC))\"\n",
      "I1009 09:03:11.945763       1 named_certificates.go:53] \"Loaded SNI cert\" index=0 certName=\"self-signed loopback\" certDetail=\"\\\"apiserver-loopback-client@1760000591\\\" [serving] validServingFor=[apiserver-loopback-client] issuer=\\\"apiserver-loopback-client-ca@1760000591\\\" (2025-10-09 08:03:11 +0000 UTC to 2026-10-09 08:03:11 +0000 UTC (now=2025-10-09 09:03:11.945744538 +0000 UTC))\"\n",
      "\n",
      "========================================================================\n",
      "✅ Déploiement de Volta Scheduler terminé !\n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# --- Script pour déployer Volta ---\n",
    "\n",
    "source_dir = \"volta\"\n",
    "config_file = \"volta-config.yaml\"\n",
    "manifest_file = \"volta.yaml\"\n",
    "\n",
    "# Vérifier que le répertoire local existe\n",
    "if not os.path.isdir(source_dir):\n",
    "    print(f\"❌ Le répertoire local '{source_dir}' n'existe pas.\")\n",
    "    print(f\"📁 Veuillez créer le dossier '{source_dir}' avec les fichiers suivants:\")\n",
    "    print(f\"   - {config_file}\")\n",
    "    print(f\"   - {manifest_file}\")\n",
    "    print(\"\\n💡 Ou uploadez le dossier complet dans le répertoire de travail.\")\n",
    "    raise FileNotFoundError(f\"Le répertoire local '{source_dir}' est introuvable. Créez-le d'abord avec les manifestes nécessaires.\")\n",
    "\n",
    "# Vérifier que les fichiers nécessaires existent\n",
    "config_path = os.path.join(source_dir, config_file)\n",
    "manifest_path = os.path.join(source_dir, manifest_file)\n",
    "\n",
    "if not os.path.isfile(config_path):\n",
    "    raise FileNotFoundError(f\"Le fichier de configuration '{config_path}' est introuvable.\")\n",
    "\n",
    "if not os.path.isfile(manifest_path):\n",
    "    raise FileNotFoundError(f\"Le fichier manifest '{manifest_path}' est introuvable.\")\n",
    "\n",
    "print(f\"✅ Fichiers Volta trouvés:\")\n",
    "print(f\"   - Configuration: {config_path}\")\n",
    "print(f\"   - Manifest: {manifest_path}\")\n",
    "\n",
    "# --- Étape 1 : Copier le fichier de configuration vers /etc/kubernetes/ sur le master ---\n",
    "print(f\"\\n--- Copie du fichier de configuration vers /etc/kubernetes/ sur le master... ---\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.copy(src=config_path, dest=\"/etc/kubernetes/volta-config.yaml\")\n",
    "\n",
    "if p.results and p.results[0].status == \"OK\":\n",
    "    print(\"✅ Fichier de configuration copié avec succès.\")\n",
    "else:\n",
    "    print(\"❌ Erreur lors de la copie du fichier de configuration.\")\n",
    "    if p.results:\n",
    "        print(p.results[0].stderr)\n",
    "\n",
    "# --- Étape 2 : Copier le manifest vers le master ---\n",
    "print(f\"\\n--- Copie du manifest Volta vers le master... ---\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.copy(src=manifest_path, dest=\"/tmp/volta.yaml\")\n",
    "\n",
    "if p.results and p.results[0].status == \"OK\":\n",
    "    print(\"✅ Manifest Volta copié avec succès.\")\n",
    "else:\n",
    "    print(\"❌ Erreur lors de la copie du manifest.\")\n",
    "    if p.results:\n",
    "        print(p.results[0].stderr)\n",
    "\n",
    "# --- Étape 3 : Déployer Volta ---\n",
    "DEPLOY_VOLTA_SCRIPT = \"\"\"\n",
    "#!/bin/bash -e\n",
    "\n",
    "echo \"========================================================================\"\n",
    "echo \"⚡ Déploiement de Volta Scheduler\"\n",
    "echo \"========================================================================\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification du fichier de configuration ---\"\n",
    "if [ -f \"/etc/kubernetes/volta-config.yaml\" ]; then\n",
    "    echo \"✅ Fichier de configuration trouvé: /etc/kubernetes/volta-config.yaml\"\n",
    "    ls -la /etc/kubernetes/volta-config.yaml\n",
    "    echo \"\"\n",
    "    echo \"Contenu du fichier de configuration:\"\n",
    "    head -20 /etc/kubernetes/volta-config.yaml\n",
    "else\n",
    "    echo \"❌ Fichier de configuration non trouvé!\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Application du manifest Volta ---\"\n",
    "kubectl apply -f /tmp/volta.yaml\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Attente de 30 secondes pour le démarrage ---\"\n",
    "sleep 30\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification du déploiement volta-scheduler ---\"\n",
    "kubectl get deployment volta-scheduler -n kube-system -o wide\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification des pods Volta (component=scheduler) ---\"\n",
    "kubectl get pods -n kube-system -l component=scheduler,tier=control-plane -o wide\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Statut du déploiement Volta ---\"\n",
    "kubectl rollout status deployment/volta-scheduler -n kube-system --timeout=120s\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification de toutes les ressources liées à Volta ---\"\n",
    "kubectl get all -n kube-system | grep volta || echo \"Aucune ressource Volta trouvée\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Événements récents liés à volta-scheduler ---\"\n",
    "kubectl get events -n kube-system --sort-by='.lastTimestamp' | grep volta | tail -20 || echo \"Aucun événement Volta récent\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Logs des pods volta-scheduler ---\"\n",
    "kubectl logs -l component=scheduler,tier=control-plane -n kube-system --tail=30 2>&1 || echo \"Aucun log disponible\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"========================================================================\"\n",
    "echo \"✅ Déploiement de Volta Scheduler terminé !\"\n",
    "echo \"========================================================================\"\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- Déploiement de Volta... ---\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(DEPLOY_VOLTA_SCRIPT)\n",
    "\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995c0847",
   "metadata": {},
   "source": [
    "## Récupération de Tous les Logs Volta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8355e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script pour récupérer tous les logs de Volta Scheduler\n",
    "GET_ALL_VOLTA_LOGS_SCRIPT = \"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "echo \"========================================================================\"\n",
    "echo \"📋 RÉCUPÉRATION COMPLÈTE DES LOGS VOLTA SCHEDULER\"\n",
    "echo \"========================================================================\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 1. Recherche de tous les pods volta-scheduler ---\"\n",
    "VOLTA_PODS=$(kubectl get pods -n kube-system -l component=scheduler,tier=control-plane -o jsonpath='{.items[*].metadata.name}' | grep volta)\n",
    "\n",
    "if [ -z \"$VOLTA_PODS\" ]; then\n",
    "    echo \"❌ Aucun pod volta-scheduler trouvé\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "echo \"Pods Volta trouvés: $VOLTA_PODS\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 2. Informations détaillées sur les pods Volta ---\"\n",
    "for pod in $VOLTA_PODS; do\n",
    "    echo \"\"\n",
    "    echo \"==========================================\"\n",
    "    echo \"Pod: $pod\"\n",
    "    echo \"==========================================\"\n",
    "    \n",
    "    echo \"--- État du pod ---\"\n",
    "    kubectl get pod $pod -n kube-system -o wide\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"--- Nœud d'exécution ---\"\n",
    "    kubectl get pod $pod -n kube-system -o jsonpath='{.spec.nodeName}'\n",
    "    echo \"\"\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"--- Statut des conteneurs ---\"\n",
    "    kubectl get pod $pod -n kube-system -o jsonpath='{range .status.containerStatuses[*]}Conteneur: {.name}, Ready: {.ready}, Restarts: {.restartCount}{\"\\n\"}{end}'\n",
    "done\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 3. LOGS COMPLETS DE TOUS LES PODS VOLTA ---\"\n",
    "for pod in $VOLTA_PODS; do\n",
    "    echo \"\"\n",
    "    echo \"==========================================\"\n",
    "    echo \"📝 LOGS COMPLETS du pod: $pod\"\n",
    "    echo \"==========================================\"\n",
    "    \n",
    "    # Logs depuis le début (pas de --tail)\n",
    "    kubectl logs $pod -n kube-system --timestamps 2>&1 || echo \"❌ Impossible de récupérer les logs\"\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"--- Logs du conteneur précédent (si redémarrage) ---\"\n",
    "    kubectl logs $pod -n kube-system --previous --timestamps 2>/dev/null || echo \"Aucun log de conteneur précédent\"\n",
    "done\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 4. LOGS EN TEMPS RÉEL (suivre les logs) ---\"\n",
    "echo \"💡 Pour suivre les logs en temps réel, utilisez:\"\n",
    "echo \"kubectl logs -f -l component=scheduler,tier=control-plane -n kube-system | grep volta\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 5. ÉVÉNEMENTS LIÉS À VOLTA ---\"\n",
    "kubectl get events -n kube-system --sort-by='.lastTimestamp' | grep -i volta | tail -50 || echo \"Aucun événement Volta trouvé\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 6. DESCRIPTION DÉTAILLÉE DES PODS VOLTA ---\"\n",
    "for pod in $VOLTA_PODS; do\n",
    "    echo \"\"\n",
    "    echo \"==========================================\"\n",
    "    echo \"📋 DESCRIPTION du pod: $pod\"\n",
    "    echo \"==========================================\"\n",
    "    kubectl describe pod $pod -n kube-system\n",
    "done\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 7. CONFIGURATION DU DÉPLOIEMENT VOLTA ---\"\n",
    "kubectl get deployment volta-scheduler -n kube-system -o yaml 2>&1 || echo \"Déploiement Volta non trouvé\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 8. LOGS DE DÉBOGAGE - DÉCISIONS DE SCHEDULING ---\"\n",
    "echo \"Recherche des logs de scheduling dans tous les pods volta:\"\n",
    "for pod in $VOLTA_PODS; do\n",
    "    echo \"\"\n",
    "    echo \"--- Décisions de scheduling dans $pod ---\"\n",
    "    kubectl logs $pod -n kube-system | grep -i \"schedule\\|bind\\|filter\\|score\" | tail -20 || echo \"Aucun log de scheduling trouvé\"\n",
    "done\n",
    "\n",
    "echo \"\"\n",
    "echo \"========================================================================\"\n",
    "echo \"✅ Récupération complète des logs Volta terminée\"\n",
    "echo \"========================================================================\"\n",
    "\"\"\"\n",
    "\n",
    "print(\"📋 Récupération de tous les logs Volta...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(GET_ALL_VOLTA_LOGS_SCRIPT)\n",
    "\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46effed1",
   "metadata": {},
   "source": [
    "## Déploiement d'Application Demo avec Volta Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "615d94d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2486471853cf4a91bfa5eb3e5f7bb92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:34: SyntaxWarning: invalid escape sequence '\\|'\n",
      "<>:34: SyntaxWarning: invalid escape sequence '\\|'\n",
      "/tmp/ipykernel_2127663/3533626614.py:34: SyntaxWarning: invalid escape sequence '\\|'\n",
      "  DEPLOY_DEMO_WITH_VOLTA_SCRIPT = \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fichier demo trouvé: demo/rancher-demo.yaml\n",
      "\n",
      "--- Copie du fichier demo vers le master... ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">copy</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mcopy\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa0c868208e45808affd1608e3f978d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fichier demo copié avec succès.\n",
      "\n",
      "--- Déploiement de l'application demo avec Volta Scheduler... ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-2.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-2.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "🚀 Déploiement de l'Application Demo avec Volta Scheduler\n",
      "========================================================================\n",
      "\n",
      "--- Application du manifest rancher-demo.yaml ---\n",
      "deployment.apps/hello-world created\n",
      "\n",
      "--- Attente de 30 secondes pour le démarrage ---\n",
      "\n",
      "--- Vérification du déploiement hello-world ---\n",
      "NAME          READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS    IMAGES                          SELECTOR\n",
      "hello-world   0/3     3            0           30s   hello-world   bashofmann/rancher-demo:1.0.0   app=hello-world\n",
      "\n",
      "--- Vérification des pods hello-world ---\n",
      "NAME                           READY   STATUS    RESTARTS   AGE   IP       NODE     NOMINATED NODE   READINESS GATES\n",
      "hello-world-778df56cb6-4jtzc   0/1     Pending   0          30s   <none>   <none>   <none>           <none>\n",
      "hello-world-778df56cb6-w97hl   0/1     Pending   0          30s   <none>   <none>   <none>           <none>\n",
      "hello-world-778df56cb6-x9h92   0/1     Pending   0          30s   <none>   <none>   <none>           <none>\n",
      "\n",
      "--- Vérification du scheduler utilisé ---\n",
      "\n",
      "--- Statut du déploiement ---\n",
      "Waiting for deployment \"hello-world\" rollout to finish: 0 of 3 updated replicas are available...\n",
      "\n",
      "--- Événements récents liés à hello-world ---\n",
      "2m30s       Warning   FailedScheduling    pod/hello-world-778df56cb6-4jtzc    0/3 nodes are available: 3 node(s) didn't meet power requirements for the requested pod. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.\n",
      "0s          Warning   FailedScheduling    pod/hello-world-778df56cb6-4jtzc    0/3 nodes are available: 3 node(s) didn't meet power requirements for the requested pod. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.\n",
      "2m30s       Warning   FailedScheduling    pod/hello-world-778df56cb6-w97hl    0/3 nodes are available: 3 node(s) didn't meet power requirements for the requested pod. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.\n",
      "0s          Warning   FailedScheduling    pod/hello-world-778df56cb6-w97hl    0/3 nodes are available: 3 node(s) didn't meet power requirements for the requested pod. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.\n",
      "2m30s       Warning   FailedScheduling    pod/hello-world-778df56cb6-x9h92    0/3 nodes are available: 3 node(s) didn't meet power requirements for the requested pod. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.\n",
      "0s          Warning   FailedScheduling    pod/hello-world-778df56cb6-x9h92    0/3 nodes are available: 3 node(s) didn't meet power requirements for the requested pod. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.\n",
      "2m30s       Normal    SuccessfulCreate    replicaset/hello-world-778df56cb6   Created pod: hello-world-778df56cb6-w97hl\n",
      "2m30s       Normal    SuccessfulCreate    replicaset/hello-world-778df56cb6   Created pod: hello-world-778df56cb6-x9h92\n",
      "2m30s       Normal    ScalingReplicaSet   deployment/hello-world              Scaled up replica set hello-world-778df56cb6 to 3\n",
      "2m30s       Normal    SuccessfulCreate    replicaset/hello-world-778df56cb6   Created pod: hello-world-778df56cb6-4jtzc\n",
      "\n",
      "--- Logs du scheduler Volta (pour voir les décisions de placement) ---\n",
      "Aucun log de scheduling trouvé\n",
      "\n",
      "========================================================================\n",
      "✅ Déploiement de l'application demo avec Volta terminé !\n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# --- Script pour déployer l'application demo avec Volta Scheduler ---\n",
    "\n",
    "demo_dir = \"demo\"\n",
    "demo_file = \"rancher-demo.yaml\"\n",
    "\n",
    "# Vérifier que le répertoire et le fichier existent\n",
    "if not os.path.isdir(demo_dir):\n",
    "    print(f\"❌ Le répertoire local '{demo_dir}' n'existe pas.\")\n",
    "    raise FileNotFoundError(f\"Le répertoire '{demo_dir}' est introuvable.\")\n",
    "\n",
    "demo_path = os.path.join(demo_dir, demo_file)\n",
    "if not os.path.isfile(demo_path):\n",
    "    print(f\"❌ Le fichier '{demo_path}' n'existe pas.\")\n",
    "    raise FileNotFoundError(f\"Le fichier '{demo_path}' est introuvable.\")\n",
    "\n",
    "print(f\"✅ Fichier demo trouvé: {demo_path}\")\n",
    "\n",
    "\n",
    "# --- Copier le fichier demo vers le master ---\n",
    "print(f\"\\n--- Copie du fichier demo vers le master... ---\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.copy(src=demo_path, dest=\"/tmp/rancher-demo.yaml\")\n",
    "\n",
    "if p.results and p.results[0].status == \"OK\":\n",
    "    print(\"✅ Fichier demo copié avec succès.\")\n",
    "else:\n",
    "    print(\"❌ Erreur lors de la copie du fichier demo.\")\n",
    "    if p.results:\n",
    "        print(p.results[0].stderr)\n",
    "\n",
    "# --- Appliquer le manifest demo avec Volta Scheduler ---\n",
    "DEPLOY_DEMO_WITH_VOLTA_SCRIPT = \"\"\"\n",
    "#!/bin/bash -e\n",
    "\n",
    "echo \"========================================================================\"\n",
    "echo \"🚀 Déploiement de l'Application Demo avec Volta Scheduler\"\n",
    "echo \"========================================================================\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Application du manifest rancher-demo.yaml ---\"\n",
    "kubectl apply -f /tmp/rancher-demo.yaml\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Attente de 30 secondes pour le démarrage ---\"\n",
    "sleep 30\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification du déploiement hello-world ---\"\n",
    "kubectl get deployment hello-world -o wide\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification des pods hello-world ---\"\n",
    "kubectl get pods -l app=hello-world -o wide\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification du scheduler utilisé ---\"\n",
    "kubectl get pods -l app=hello-world -o jsonpath='{range .items[*]}{.metadata.name}{\"\\t\"}{.spec.schedulerName}{\"\\t\"}{.spec.nodeName}{\"\\n\"}{end}' | column -t\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Statut du déploiement ---\"\n",
    "kubectl rollout status deployment/hello-world --timeout=120s\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Événements récents liés à hello-world ---\"\n",
    "kubectl get events --sort-by='.lastTimestamp' | grep hello-world | tail -10 || echo \"Aucun événement récent\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Logs du scheduler Volta (pour voir les décisions de placement) ---\"\n",
    "kubectl logs -l component=scheduler,tier=control-plane -n kube-system --tail=20 | grep -i \"hello-world\\|volta\\|schedule\" || echo \"Aucun log de scheduling trouvé\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"========================================================================\"\n",
    "echo \"✅ Déploiement de l'application demo avec Volta terminé !\"\n",
    "echo \"========================================================================\"\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- Déploiement de l'application demo avec Volta Scheduler... ---\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(DEPLOY_DEMO_WITH_VOLTA_SCRIPT)\n",
    "\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d694a3",
   "metadata": {},
   "source": [
    "## Suppression de l'Application Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f4eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script pour supprimer l'application demo\n",
    "DELETE_DEMO_SCRIPT = \"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "echo \"========================================================================\"\n",
    "echo \"🗑️  SUPPRESSION de l'Application Demo\"\n",
    "echo \"========================================================================\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Suppression du déploiement hello-world ---\"\n",
    "kubectl delete deployment hello-world --ignore-not-found=true\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Attente de la suppression des pods (10 secondes) ---\"\n",
    "sleep 10\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Suppression des fichiers temporaires ---\"\n",
    "rm -f /tmp/rancher-demo.yaml /tmp/rancher-demo-volta.yaml 2>&1 || echo \"Fichiers temporaires déjà supprimés\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification finale ---\"\n",
    "echo \"\"\n",
    "echo \"Déploiements restants avec 'hello-world' :\"\n",
    "kubectl get deployments | grep hello-world || echo \"✅ Aucun déploiement trouvé\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"Pods restants avec 'hello-world' :\"\n",
    "kubectl get pods -l app=hello-world || echo \"✅ Aucun pod trouvé\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"========================================================================\"\n",
    "echo \"✅ Suppression de l'application demo terminée !\"\n",
    "echo \"========================================================================\"\n",
    "\"\"\"\n",
    "\n",
    "print(\"🗑️  Lancement de la suppression de l'application demo...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(DELETE_DEMO_SCRIPT)\n",
    "\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)\n",
    "\n",
    "print(\"✅ L'application demo a été complètement supprimée du cluster !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1eab8d",
   "metadata": {},
   "source": [
    "## Suppression de Volta Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd17f623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script pour supprimer complètement Volta Scheduler\n",
    "DELETE_VOLTA_SCRIPT = \"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "echo \"========================================================================\"\n",
    "echo \"🗑️  SUPPRESSION de Volta Scheduler\"\n",
    "echo \"========================================================================\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Suppression du déploiement volta-scheduler ---\"\n",
    "kubectl delete deployment volta-scheduler -n kube-system --ignore-not-found=true\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Attente de la suppression des pods (10 secondes) ---\"\n",
    "sleep 10\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Suppression du fichier de configuration ---\"\n",
    "sudo rm -f /etc/kubernetes/volta-config.yaml 2>&1 || echo \"Fichier de configuration déjà supprimé\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Suppression du manifest temporaire ---\"\n",
    "rm -f /tmp/volta.yaml 2>&1 || echo \"Manifest temporaire déjà supprimé\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification finale ---\"\n",
    "echo \"\"\n",
    "echo \"Déploiements restants avec 'volta' :\"\n",
    "kubectl get deployments -n kube-system | grep volta || echo \"✅ Aucun déploiement trouvé\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"Pods restants avec 'volta' :\"\n",
    "kubectl get pods -n kube-system | grep volta || echo \"✅ Aucun pod trouvé\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"Services restants avec 'volta' :\"\n",
    "kubectl get services -n kube-system | grep volta || echo \"✅ Aucun service trouvé\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification des fichiers de configuration ---\"\n",
    "ls -la /etc/kubernetes/volta-config.yaml 2>/dev/null || echo \"✅ Fichier de configuration supprimé\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"========================================================================\"\n",
    "echo \"✅ Suppression de Volta Scheduler terminée !\"\n",
    "echo \"========================================================================\"\n",
    "\"\"\"\n",
    "\n",
    "print(\"🗑️  Lancement de la suppression de Volta Scheduler...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(DELETE_VOLTA_SCRIPT)\n",
    "\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)\n",
    "\n",
    "print(\"✅ Volta Scheduler a été complètement supprimé du cluster !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2797649d",
   "metadata": {},
   "source": [
    "# Libération des Ressources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf720446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libération des ressources sur Grid'5000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:enoslib.log:[G5k] Reloading 3292757 from rennes\n",
      "INFO:enoslib.log:[G5k] Killing the job (rennes, 3292757)\n",
      "INFO:enoslib.log:[G5k] Killing the job (rennes, 3292757)\n",
      "INFO:enoslib.log:[G5k] Job killed (rennes, 3292757)\n",
      "INFO:enoslib.log:[G5k] Job killed (rennes, 3292757)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ressources libérées. ✅\n"
     ]
    }
   ],
   "source": [
    "# Destruction de la réservation\n",
    "print(\"Libération des ressources sur Grid'5000...\")\n",
    "provider.destroy()\n",
    "print(\"Ressources libérées. ✅\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
