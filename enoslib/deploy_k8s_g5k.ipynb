{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a6f19e1",
   "metadata": {},
   "source": [
    "# Importations et Configuration Initiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60918c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING]: failed to patch stdout/stderr for fork-safety: 'OutStream' object\n",
      "has no attribute 'buffer'\n",
      "[WARNING]: failed to reconfigure stdout/stderr with custom encoding error\n",
      "handler: 'OutStream' object has no attribute 'reconfigure'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration initiale chargée.\n"
     ]
    }
   ],
   "source": [
    "import enoslib as en\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# --- Configuration de l'expérience ---\n",
    "\n",
    "# Configurez le logging pour avoir un retour clair sur les étapes\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# MODIFIEZ CETTE LIGNE AVEC VOTRE NOM D'UTILISATEUR GRID'5000\n",
    "G5K_USER = \"wemenra\"\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "G5K_SITE = \"rennes\"  # Site Grid'5000 à utiliser\n",
    "\n",
    "# Nom du job pour la réservation sur Grid'5000\n",
    "JOB_NAME = \"K8sEnoslibDeploy\"\n",
    "\n",
    "# Clé SSH, par défaut enoslib cherche ~/.ssh/id_rsa\n",
    "# Si vous en utilisez une autre, décommentez et modifiez la ligne suivante :\n",
    "# en.set_config(ssh_key=\"~/.ssh/ma_cle_ssh\")\n",
    "\n",
    "# Création du chemin pour les sorties (par exemple, inventaire)\n",
    "Path(\"inventory\").mkdir(exist_ok=True)\n",
    "OUTPUT_INVENTORY = \"inventory/g5k_inventory.yaml\"\n",
    "\n",
    "print(\"Configuration initiale chargée.\")\n",
    "if G5K_USER == \"VOTRE_LOGIN_G5K\":\n",
    "    print(\"\\n⚠️  ATTENTION: N'oubliez pas de remplacer 'VOTRE_LOGIN_G5K' par votre nom d'utilisateur Grid'5000.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95db030d",
   "metadata": {},
   "source": [
    "# Définition des Ressources pour le Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89826ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Définition des ressources terminée.\n"
     ]
    }
   ],
   "source": [
    "# CELLULE 2\n",
    "# Définition de la configuration pour la connexion à Grid'5000\n",
    "# en.set_provider(\n",
    "#     en.G5k(\n",
    "#         username=G5K_USER,\n",
    "#         site=G5K_SITE,\n",
    "#         job_name=JOB_NAME,\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# Définition des ressources à réserver\n",
    "# 1 nœud master et 2 nœuds workers\n",
    "# Tous les nœuds seront déployés avec Ubuntu 22.04\n",
    "conf = (\n",
    "en.G5kConf.from_settings(\n",
    "    job_name=JOB_NAME,\n",
    "    job_type=[\"deploy\"],\n",
    "    walltime=\"03:30:00\", # Réservez pour 1 heure\n",
    "    env_name=\"ubuntu2204-min\"\n",
    ").add_machine(\n",
    "    roles=[\"master\"],\n",
    "    cluster=\"paradoxe\",\n",
    "    nodes=1\n",
    ").add_machine(\n",
    "    roles=[\"workers\"],\n",
    "    cluster=\"paradoxe\",\n",
    "    nodes=2\n",
    ")\n",
    ")\n",
    "\n",
    "print(\"Définition des ressources terminée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7476000e",
   "metadata": {},
   "source": [
    "# Exécution de la Réservation et du Déploiement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0123a647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:enoslib.log:[G5k] Reloading 3292534 from rennes\n",
      "INFO:enoslib.log:[G5k] Waiting for 3292534 on rennes [2025-10-08 08:59:17]\n",
      "INFO:enoslib.log:[G5k] All jobs are Running !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a770d73fb9474893a11b33778ec85b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">Run dhcp on the nodes</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-13.rennes.grid5000.fr'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-26.rennes.grid5000.fr'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-19.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mRun dhcp on the nodes\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-13.rennes.grid5000.fr'\u001b[0m, \n",
       "\u001b[32m'paradoxe-26.rennes.grid5000.fr'\u001b[0m, \u001b[32m'paradoxe-19.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Réservation et déploiement terminés ! ---\n",
      "Master: ['paradoxe-13.rennes.grid5000.fr']\n",
      "Workers: ['paradoxe-19.rennes.grid5000.fr', 'paradoxe-26.rennes.grid5000.fr']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "provider = en.G5k(conf)\n",
    "# Démarrage de la réservation et du déploiement\n",
    "# provider.init() bloque jusqu'à ce que les noeuds soient prêts\n",
    "\n",
    "roles, networks = provider.init()\n",
    "\n",
    "# Récupération des informations sur les rôles pour les cellules suivantes\n",
    "#roles = reservation.get_roles()\n",
    "master_node = roles[\"master\"]\n",
    "worker_nodes = roles[\"workers\"]\n",
    "\n",
    "print(\"--- Réservation et déploiement terminés ! ---\")\n",
    "print(f\"Master: {[node.address for node in master_node]}\")\n",
    "print(f\"Workers: {[node.address for node in worker_nodes]}\")\n",
    "#print(f\"Tous les nœuds: roles\" + str(roles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f16248",
   "metadata": {},
   "source": [
    "#  Préparation Commune de Tous les Nœuds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f110227d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bfc3de31c7346c2919ab490c91eac27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement de la préparation commune...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-26.rennes.grid5000.fr'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-19.rennes.grid5000.fr'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-13.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-26.rennes.grid5000.fr'\u001b[0m, \n",
       "\u001b[32m'paradoxe-19.rennes.grid5000.fr'\u001b[0m, \u001b[32m'paradoxe-13.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Préparation commune terminée.\n"
     ]
    }
   ],
   "source": [
    "# Script de configuration commun\n",
    "COMMON_SETUP_SCRIPT = \"\"\"\n",
    "#!/bin/bash -xe\n",
    "sudo apt-get update -y\n",
    "sudo apt-get install -y software-properties-common gpg curl apt-transport-https ca-certificates jq\n",
    "cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf\n",
    "overlay\n",
    "br_netfilter\n",
    "EOF\n",
    "sudo modprobe overlay\n",
    "sudo modprobe br_netfilter\n",
    "cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf\n",
    "net.bridge.bridge-nf-call-iptables  = 1\n",
    "net.bridge.bridge-nf-call-ip6tables = 1\n",
    "net.ipv4.ip_forward                 = 1\n",
    "EOF\n",
    "sudo sysctl --system\n",
    "sudo swapoff -a\n",
    "curl -fsSL https://pkgs.k8s.io/addons:/cri-o:/prerelease:/main/deb/Release.key | gpg --dearmor | sudo tee /etc/apt/keyrings/cri-o-apt-keyring.gpg >/dev/null\n",
    "echo \"deb [signed-by=/etc/apt/keyrings/cri-o-apt-keyring.gpg] https://pkgs.k8s.io/addons:/cri-o:/prerelease:/main/deb/ /\" | sudo tee /etc/apt/sources.list.d/cri-o.list\n",
    "sudo apt-get update -y\n",
    "sudo apt-get install -y cri-o\n",
    "sudo systemctl enable --now crio\n",
    "KUBERNETES_VERSION=\"1.30\"\n",
    "sudo mkdir -p /etc/apt/keyrings\n",
    "curl -fsSL https://pkgs.k8s.io/core:/stable:/v$KUBERNETES_VERSION/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\n",
    "echo \"deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v$KUBERNETES_VERSION/deb/ /\" | sudo tee /etc/apt/sources.list.d/kubernetes.list\n",
    "sudo apt-get update\n",
    "sudo apt-get install -y kubelet=1.30.0-1.1 kubectl=1.30.0-1.1 kubeadm=1.30.0-1.1\n",
    "sudo apt-mark hold kubelet kubeadm kubectl\n",
    "IFACE=$(ip route | grep default | awk '{print $5}')\n",
    "local_ip=$(ip --json addr show $IFACE | jq -r '.[0].addr_info[] | select(.family == \"inet\") | .local')\n",
    "echo \"KUBELET_EXTRA_ARGS=--node-ip=$local_ip\" | sudo tee /etc/default/kubelet\n",
    "\"\"\"\n",
    "\n",
    "# Exécution du script sur tous les nœuds\n",
    "print(\"Lancement de la préparation commune...\")\n",
    "with en.actions(roles=roles) as p:\n",
    "    p.shell(COMMON_SETUP_SCRIPT)\n",
    "print(\"Préparation commune terminée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f18b04e",
   "metadata": {},
   "source": [
    "##  Vérification de la Préparation des Nœuds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f78df3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace8e5d2b3c64680bc6b289403fed292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement de la vérification sur tous les nœuds...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-26.rennes.grid5000.fr'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-19.rennes.grid5000.fr'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-13.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-26.rennes.grid5000.fr'\u001b[0m, \n",
       "\u001b[32m'paradoxe-19.rennes.grid5000.fr'\u001b[0m, \u001b[32m'paradoxe-13.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Vérification de l'état des nœuds ---\n",
      "[VÉRIF] Service CRI-O (runtime de conteneurs)...\n",
      "✅ OK: Le service CRI-O est actif.\n",
      "[VÉRIF] Binaires Kubernetes...\n",
      "Kubernetes v1.30.0\n",
      "kubeadm version: &version.Info{Major:\"1\", Minor:\"30\", GitVersion:\"v1.30.0\", GitCommit:\"7c48c2bd72b9bf5c44d21d7338cc7bea77d0ad2a\", GitTreeState:\"clean\", BuildDate:\"2024-04-17T17:34:08Z\", GoVersion:\"go1.22.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n",
      "✅ OK: Les binaires Kubelet et Kubeadm sont installés.\n",
      "[VÉRIF] Modules Kernel...\n",
      "✅ OK: Module 'br_netfilter' est chargé.\n",
      "✅ OK: Module 'overlay' est chargé.\n",
      "\n",
      "🎉 La préparation de ce nœud est validée.\n"
     ]
    }
   ],
   "source": [
    "# Script de vérification (inchangé)\n",
    "VERIFY_PREP_SCRIPT = \"\"\"\n",
    "#!/bin/bash -e\n",
    "echo \"--- Vérification de l'état des nœuds ---\"\n",
    "echo \"[VÉRIF] Service CRI-O (runtime de conteneurs)...\"\n",
    "sudo systemctl is-active --quiet crio\n",
    "echo \"✅ OK: Le service CRI-O est actif.\"\n",
    "echo \"[VÉRIF] Binaires Kubernetes...\"\n",
    "kubelet --version\n",
    "kubeadm version\n",
    "echo \"✅ OK: Les binaires Kubelet et Kubeadm sont installés.\"\n",
    "echo \"[VÉRIF] Modules Kernel...\"\n",
    "lsmod | grep -q br_netfilter && echo \"✅ OK: Module 'br_netfilter' est chargé.\"\n",
    "lsmod | grep -q overlay && echo \"✅ OK: Module 'overlay' est chargé.\"\n",
    "echo \"\\n🎉 La préparation de ce nœud est validée.\"\n",
    "\"\"\"\n",
    "\n",
    "# 1. On exécute les actions (comme avant)\n",
    "print(\"Lancement de la vérification sur tous les nœuds...\")\n",
    "with en.actions(roles=roles) as p:\n",
    "    p.shell(VERIFY_PREP_SCRIPT)\n",
    "\n",
    "results = p.results\n",
    "verify = results[0].stdout.strip()\n",
    "print(verify)\n",
    "# # 2. ✅ NOUVEAU : On récupère et on affiche les résultats APRÈS le bloc\n",
    "# print(\"\\n--- RÉSULTATS DE LA VÉRIFICATION ---\")\n",
    "# results = p.get_results()\n",
    "\n",
    "# # On boucle sur les résultats de chaque machine\n",
    "# for r in results:\n",
    "#     print(f\"\\n======== Nœud: {r.host} ========\")\n",
    "#     print(r.stdout) # Affiche la sortie standard de la commande\n",
    "    \n",
    "#     # Optionnel : Affiche les erreurs s'il y en a\n",
    "#     if r.stderr:\n",
    "#         print(f\"-------- Erreurs (stderr) pour {r.host} --------\")\n",
    "#         print(r.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3926281",
   "metadata": {},
   "source": [
    "#  Initialisation du Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ddc5e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee98b36c42e4b669ec5ffc2696d8293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/tmp/ipykernel_1772848/3805460087.py:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  MASTER_INIT_SCRIPT = \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisation du master...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-13.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-13.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisation du master terminée.\n"
     ]
    }
   ],
   "source": [
    "# Script d'initialisation du master\n",
    "MASTER_INIT_SCRIPT = \"\"\"\n",
    "#!/bin/bash -xe\n",
    "IFACE=$(ip route | grep default | awk '{print $5}')\n",
    "IPADDR=$(ip -4 addr show $IFACE | grep -oP '(?<=inet\\s)\\d+(\\.\\d+){3}')\n",
    "NODENAME=$(hostname -s)\n",
    "sudo kubeadm init --pod-network-cidr=192.168.0.0/16 --apiserver-advertise-address=$IPADDR --node-name $NODENAME --cri-socket unix:///var/run/crio/crio.sock --ignore-preflight-errors=Swap\n",
    "mkdir -p $HOME/.kube\n",
    "sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n",
    "sudo chown $(id -u):$(id -g) $HOME/.kube/config\n",
    "kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml\n",
    "\"\"\"\n",
    "\n",
    "# Exécution du script sur le master\n",
    "print(\"Initialisation du master...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(MASTER_INIT_SCRIPT)\n",
    "print(\"Initialisation du master terminée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0079e4de",
   "metadata": {},
   "source": [
    "# Jonction des Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "278b9b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd039cb8d4da4389b397e511c1d7afa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération de la commande de jonction depuis le master...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-13.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-13.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76994bcadac84ea4a208350a641a760d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Commande de jonction récupérée: kubeadm join 172.16.101.13:6443 --token b6egm9.uq6zcijjozoxlmoj --discovery-token-ca-cert-hash sha256:bad0fee9f4f6d1d960ce22227c751cb142c3711f31b5e40441c1d3ae71c7118c\n",
      "Les workers rejoignent le cluster...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-26.rennes.grid5000.fr'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-19.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-26.rennes.grid5000.fr'\u001b[0m, \n",
       "\u001b[32m'paradoxe-19.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workers joints. Attente de 60s pour la stabilisation...\n"
     ]
    }
   ],
   "source": [
    "# 1. Récupérer la commande de jonction depuis le master\n",
    "print(\"Récupération de la commande de jonction depuis le master...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(\"sudo kubeadm token create --print-join-command\")\n",
    "\n",
    "# Récupération des résultats après le bloc\n",
    "results = p.results\n",
    "join_command = results[0].stdout.strip()\n",
    "print(f\"✅ Commande de jonction récupérée: {join_command}\")\n",
    "\n",
    "# 2. Exécuter la commande sur les workers\n",
    "print(\"Les workers rejoignent le cluster...\")\n",
    "with en.actions(roles=worker_nodes) as p:\n",
    "    p.shell(f\"sudo {join_command}\")\n",
    "\n",
    "print(\"Workers joints. Attente de 60s pour la stabilisation...\")\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a921f89",
   "metadata": {},
   "source": [
    "# Vérification du Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a7195aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e699ce4f0ca4a53b74d235e2a837ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-13.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-13.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- État du cluster ---\n",
      "NAME          STATUS   ROLES           AGE    VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION       CONTAINER-RUNTIME\n",
      "paradoxe-13   Ready    control-plane   113s   v1.30.0   172.16.101.13   <none>        Ubuntu 22.04.5 LTS   5.15.0-144-generic   cri-o://1.33.0\n",
      "paradoxe-19   Ready    <none>          72s    v1.30.0   172.16.101.19   <none>        Ubuntu 22.04.5 LTS   5.15.0-144-generic   cri-o://1.33.0\n",
      "paradoxe-26   Ready    <none>          72s    v1.30.0   172.16.101.26   <none>        Ubuntu 22.04.5 LTS   5.15.0-144-generic   cri-o://1.33.0\n"
     ]
    }
   ],
   "source": [
    "# Exécution de kubectl get nodes sur le master pour vérifier\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(\"kubectl get nodes -o wide\")\n",
    "\n",
    "results = p.results\n",
    "nodes = results[0].stdout.strip()\n",
    "print(\"--- État du cluster ---\")\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4524c748",
   "metadata": {},
   "source": [
    " ## Installation des Add-ons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c717bd96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11748f482cf848558a321ca97c6d5929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installation des add-ons sur le nœud master...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-13.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-13.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Résultat de l'installation ---\n",
      "--- Installation du Metrics Server ---\n",
      "serviceaccount/metrics-server created\n",
      "clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created\n",
      "clusterrole.rbac.authorization.k8s.io/system:metrics-server created\n",
      "rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created\n",
      "service/metrics-server created\n",
      "deployment.apps/metrics-server created\n",
      "apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created\n",
      "\n",
      "--- Installation d'Ingress-NGINX ---\n",
      "namespace/ingress-nginx created\n",
      "serviceaccount/ingress-nginx created\n",
      "serviceaccount/ingress-nginx-admission created\n",
      "role.rbac.authorization.k8s.io/ingress-nginx created\n",
      "role.rbac.authorization.k8s.io/ingress-nginx-admission created\n",
      "clusterrole.rbac.authorization.k8s.io/ingress-nginx created\n",
      "clusterrole.rbac.authorization.k8s.io/ingress-nginx-admission created\n",
      "rolebinding.rbac.authorization.k8s.io/ingress-nginx created\n",
      "rolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created\n",
      "configmap/ingress-nginx-controller created\n",
      "service/ingress-nginx-controller created\n",
      "service/ingress-nginx-controller-admission created\n",
      "deployment.apps/ingress-nginx-controller created\n",
      "job.batch/ingress-nginx-admission-create created\n",
      "job.batch/ingress-nginx-admission-patch created\n",
      "ingressclass.networking.k8s.io/nginx created\n",
      "validatingwebhookconfiguration.admissionregistration.k8s.io/ingress-nginx-admission created\n",
      "\n",
      "Installation des add-ons terminée.\n"
     ]
    }
   ],
   "source": [
    "# Script pour installer les add-ons\n",
    "ADDONS_SCRIPT = \"\"\"\n",
    "#!/bin/bash -e\n",
    "\n",
    "echo \"--- Installation du Metrics Server ---\"\n",
    "kubectl apply -f https://raw.githubusercontent.com/techiescamp/kubeadm-scripts/main/manifests/metrics-server.yaml\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Installation d'Ingress-NGINX ---\"\n",
    "kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.13.0/deploy/static/provider/baremetal/deploy.yaml\n",
    "\n",
    "echo \"\"\n",
    "echo \"Installation des add-ons terminée.\"\n",
    "\"\"\"\n",
    "\n",
    "# Exécution du script sur le master\n",
    "print(\"Installation des add-ons sur le nœud master...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(ADDONS_SCRIPT)\n",
    "\n",
    "# Récupération de la sortie comme vous l'avez spécifié\n",
    "print(\"\\n--- Résultat de l'installation ---\")\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)\n",
    "else:\n",
    "    print(\"Aucun résultat à afficher. Vérifiez les erreurs potentielles.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6b258c",
   "metadata": {},
   "source": [
    "# Déploiement et Test d'une Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33ab194c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac856a19a9e54fa2b076dc915f793b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Déploiement de l'application de test...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-13.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-13.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Résultat du déploiement ---\n",
      "--- Création du Deployment et du Service pour l'application echoserver ---\n",
      "deployment.apps/echoserver created\n",
      "service/echoserver created\n",
      "\n",
      "--- Attente de 15 secondes pour le démarrage des pods ---\n",
      "\n",
      "--- Vérification du statut du déploiement ---\n",
      "NAME         READY   UP-TO-DATE   AVAILABLE   AGE\n",
      "echoserver   2/2     2            2           15s\n",
      "\n",
      "--- Vérification des pods (devrait en afficher 2) ---\n",
      "NAME                         READY   STATUS    RESTARTS   AGE\n",
      "echoserver-d75ff78c5-7mz85   1/1     Running   0          15s\n",
      "echoserver-d75ff78c5-s9zq6   1/1     Running   0          15s\n",
      "\n",
      "--- Vérification du service (notez le port après '80:') ---\n",
      "NAME         TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\n",
      "echoserver   NodePort   10.105.247.96   <none>        80:31999/TCP   15s\n"
     ]
    }
   ],
   "source": [
    "# Script pour déployer l'application de test et son service\n",
    "APP_DEPLOY_SCRIPT = \"\"\"\n",
    "#!/bin/bash -e\n",
    "\n",
    "echo \"--- Création du Deployment et du Service pour l'application echoserver ---\"\n",
    "\n",
    "# On utilise un 'heredoc' pour passer le YAML directement à kubectl\n",
    "cat <<EOF | kubectl apply -f -\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: echoserver\n",
    "spec:\n",
    "  replicas: 2\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: echoserver\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: echoserver\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: echoserver\n",
    "        image: registry.k8s.io/echoserver:1.10\n",
    "        ports:\n",
    "        - containerPort: 8080\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: echoserver\n",
    "spec:\n",
    "  type: NodePort\n",
    "  selector:\n",
    "    app: echoserver\n",
    "  ports:\n",
    "  - port: 80\n",
    "    targetPort: 8080\n",
    "EOF\n",
    "\n",
    "echo \"\\n--- Attente de 15 secondes pour le démarrage des pods ---\"\n",
    "sleep 15\n",
    "\n",
    "echo \"\\n--- Vérification du statut du déploiement ---\"\n",
    "kubectl get deployment echoserver\n",
    "\n",
    "echo \"\\n--- Vérification des pods (devrait en afficher 2) ---\"\n",
    "kubectl get pods -l app=echoserver\n",
    "\n",
    "echo \"\\n--- Vérification du service (notez le port après '80:') ---\"\n",
    "kubectl get service echoserver\n",
    "\"\"\"\n",
    "\n",
    "# Exécution du script sur le master\n",
    "print(\"Déploiement de l'application de test...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(APP_DEPLOY_SCRIPT)\n",
    "\n",
    "# Affichage du résultat\n",
    "print(\"\\n--- Résultat du déploiement ---\")\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689c83c8",
   "metadata": {},
   "source": [
    "### Envoyez une Requête"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "558e8487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82b48c4370c46e39a0248304593795c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-13.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-13.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Réponse du serveur ---\n",
      "\n",
      "\n",
      "Hostname: echoserver-d75ff78c5-7mz85\n",
      "\n",
      "Pod Information:\n",
      "\t-no pod information available-\n",
      "\n",
      "Server values:\n",
      "\tserver_version=nginx: 1.13.3 - lua: 10008\n",
      "\n",
      "Request Information:\n",
      "\tclient_address=192.168.0.192\n",
      "\tmethod=GET\n",
      "\treal path=/\n",
      "\tquery=\n",
      "\trequest_version=1.1\n",
      "\trequest_scheme=http\n",
      "\trequest_uri=http://paradoxe-13.rennes.grid5000.fr:8080/\n",
      "\n",
      "Request Headers:\n",
      "\taccept=*/*\n",
      "\thost=paradoxe-13.rennes.grid5000.fr:31999\n",
      "\tuser-agent=curl/7.81.0\n",
      "\n",
      "Request Body:\n",
      "\t-no body in request-\n"
     ]
    }
   ],
   "source": [
    "# Récupère l'adresse IP du master\n",
    "master_ip = master_node[0].address \n",
    "\n",
    "# Remplacez 31192 par le port que vous avez obtenu à l'étape 1\n",
    "node_port = 31999 # ⚠️ CHANGEZ CE PORT\n",
    "\n",
    "# Test avec curl depuis le master\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(f\"curl http://{master_ip}:{node_port}\")\n",
    "\n",
    "if p.results:\n",
    "    print(\"--- Réponse du serveur ---\")\n",
    "    print(p.results[0].stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4fcd5b",
   "metadata": {},
   "source": [
    "# Installation de la Suite de Monitoring (Prometheus & Grafana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ad67271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8918c78218504486b8bbbd40abead053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement de l'installation de la suite de monitoring...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-13.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-13.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Résultat de l'installation ---\n",
      "--- Installation de la suite Prometheus + Grafana via kube-prometheus ---\n",
      "Clonage du dépôt kube-prometheus...\n",
      "Étape 1/3 : Application des CRDs et de la configuration 'setup'...\n",
      "customresourcedefinition.apiextensions.k8s.io/alertmanagerconfigs.monitoring.coreos.com serverside-applied\n",
      "customresourcedefinition.apiextensions.k8s.io/alertmanagers.monitoring.coreos.com serverside-applied\n",
      "customresourcedefinition.apiextensions.k8s.io/podmonitors.monitoring.coreos.com serverside-applied\n",
      "customresourcedefinition.apiextensions.k8s.io/probes.monitoring.coreos.com serverside-applied\n",
      "customresourcedefinition.apiextensions.k8s.io/prometheuses.monitoring.coreos.com serverside-applied\n",
      "customresourcedefinition.apiextensions.k8s.io/prometheusagents.monitoring.coreos.com serverside-applied\n",
      "customresourcedefinition.apiextensions.k8s.io/prometheusrules.monitoring.coreos.com serverside-applied\n",
      "customresourcedefinition.apiextensions.k8s.io/scrapeconfigs.monitoring.coreos.com serverside-applied\n",
      "customresourcedefinition.apiextensions.k8s.io/servicemonitors.monitoring.coreos.com serverside-applied\n",
      "customresourcedefinition.apiextensions.k8s.io/thanosrulers.monitoring.coreos.com serverside-applied\n",
      "namespace/monitoring serverside-applied\n",
      "Attente de l'établissement des CRDs...\n",
      "customresourcedefinition.apiextensions.k8s.io/alertmanagerconfigs.monitoring.coreos.com condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/alertmanagers.monitoring.coreos.com condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/caliconodestatuses.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/ipreservations.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/kubecontrollersconfigurations.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/podmonitors.monitoring.coreos.com condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/probes.monitoring.coreos.com condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/prometheusagents.monitoring.coreos.com condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/prometheuses.monitoring.coreos.com condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/prometheusrules.monitoring.coreos.com condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/scrapeconfigs.monitoring.coreos.com condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/servicemonitors.monitoring.coreos.com condition met\n",
      "customresourcedefinition.apiextensions.k8s.io/thanosrulers.monitoring.coreos.com condition met\n",
      "Étape 2/3 : Application des manifestes de la suite de monitoring...\n",
      "alertmanager.monitoring.coreos.com/main created\n",
      "networkpolicy.networking.k8s.io/alertmanager-main created\n",
      "poddisruptionbudget.policy/alertmanager-main created\n",
      "prometheusrule.monitoring.coreos.com/alertmanager-main-rules created\n",
      "secret/alertmanager-main created\n",
      "service/alertmanager-main created\n",
      "serviceaccount/alertmanager-main created\n",
      "servicemonitor.monitoring.coreos.com/alertmanager-main created\n",
      "clusterrole.rbac.authorization.k8s.io/blackbox-exporter created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/blackbox-exporter created\n",
      "configmap/blackbox-exporter-configuration created\n",
      "deployment.apps/blackbox-exporter created\n",
      "networkpolicy.networking.k8s.io/blackbox-exporter created\n",
      "service/blackbox-exporter created\n",
      "serviceaccount/blackbox-exporter created\n",
      "servicemonitor.monitoring.coreos.com/blackbox-exporter created\n",
      "secret/grafana-config created\n",
      "secret/grafana-datasources created\n",
      "configmap/grafana-dashboard-alertmanager-overview created\n",
      "configmap/grafana-dashboard-apiserver created\n",
      "configmap/grafana-dashboard-cluster-total created\n",
      "configmap/grafana-dashboard-controller-manager created\n",
      "configmap/grafana-dashboard-grafana-overview created\n",
      "configmap/grafana-dashboard-k8s-resources-cluster created\n",
      "configmap/grafana-dashboard-k8s-resources-multicluster created\n",
      "configmap/grafana-dashboard-k8s-resources-namespace created\n",
      "configmap/grafana-dashboard-k8s-resources-node created\n",
      "configmap/grafana-dashboard-k8s-resources-pod created\n",
      "configmap/grafana-dashboard-k8s-resources-windows-cluster created\n",
      "configmap/grafana-dashboard-k8s-resources-windows-namespace created\n",
      "configmap/grafana-dashboard-k8s-resources-windows-pod created\n",
      "configmap/grafana-dashboard-k8s-resources-workload created\n",
      "configmap/grafana-dashboard-k8s-resources-workloads-namespace created\n",
      "configmap/grafana-dashboard-k8s-windows-cluster-rsrc-use created\n",
      "configmap/grafana-dashboard-k8s-windows-node-rsrc-use created\n",
      "configmap/grafana-dashboard-kubelet created\n",
      "configmap/grafana-dashboard-namespace-by-pod created\n",
      "configmap/grafana-dashboard-namespace-by-workload created\n",
      "configmap/grafana-dashboard-node-cluster-rsrc-use created\n",
      "configmap/grafana-dashboard-node-rsrc-use created\n",
      "configmap/grafana-dashboard-nodes-aix created\n",
      "configmap/grafana-dashboard-nodes-darwin created\n",
      "configmap/grafana-dashboard-nodes created\n",
      "configmap/grafana-dashboard-persistentvolumesusage created\n",
      "configmap/grafana-dashboard-pod-total created\n",
      "configmap/grafana-dashboard-prometheus-remote-write created\n",
      "configmap/grafana-dashboard-prometheus created\n",
      "configmap/grafana-dashboard-proxy created\n",
      "configmap/grafana-dashboard-scheduler created\n",
      "configmap/grafana-dashboard-workload-total created\n",
      "configmap/grafana-dashboards created\n",
      "deployment.apps/grafana created\n",
      "networkpolicy.networking.k8s.io/grafana created\n",
      "prometheusrule.monitoring.coreos.com/grafana-rules created\n",
      "service/grafana created\n",
      "serviceaccount/grafana created\n",
      "servicemonitor.monitoring.coreos.com/grafana created\n",
      "prometheusrule.monitoring.coreos.com/kube-prometheus-rules created\n",
      "clusterrole.rbac.authorization.k8s.io/kube-state-metrics created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/kube-state-metrics created\n",
      "deployment.apps/kube-state-metrics created\n",
      "networkpolicy.networking.k8s.io/kube-state-metrics created\n",
      "prometheusrule.monitoring.coreos.com/kube-state-metrics-rules created\n",
      "service/kube-state-metrics created\n",
      "serviceaccount/kube-state-metrics created\n",
      "servicemonitor.monitoring.coreos.com/kube-state-metrics created\n",
      "prometheusrule.monitoring.coreos.com/kubernetes-monitoring-rules created\n",
      "servicemonitor.monitoring.coreos.com/kube-apiserver created\n",
      "servicemonitor.monitoring.coreos.com/coredns created\n",
      "servicemonitor.monitoring.coreos.com/kube-controller-manager created\n",
      "servicemonitor.monitoring.coreos.com/kube-scheduler created\n",
      "servicemonitor.monitoring.coreos.com/kubelet created\n",
      "clusterrole.rbac.authorization.k8s.io/node-exporter created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/node-exporter created\n",
      "daemonset.apps/node-exporter created\n",
      "networkpolicy.networking.k8s.io/node-exporter created\n",
      "prometheusrule.monitoring.coreos.com/node-exporter-rules created\n",
      "service/node-exporter created\n",
      "serviceaccount/node-exporter created\n",
      "servicemonitor.monitoring.coreos.com/node-exporter created\n",
      "clusterrole.rbac.authorization.k8s.io/prometheus-k8s created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/prometheus-k8s created\n",
      "networkpolicy.networking.k8s.io/prometheus-k8s created\n",
      "poddisruptionbudget.policy/prometheus-k8s created\n",
      "prometheus.monitoring.coreos.com/k8s created\n",
      "prometheusrule.monitoring.coreos.com/prometheus-k8s-prometheus-rules created\n",
      "rolebinding.rbac.authorization.k8s.io/prometheus-k8s-config created\n",
      "rolebinding.rbac.authorization.k8s.io/prometheus-k8s created\n",
      "rolebinding.rbac.authorization.k8s.io/prometheus-k8s created\n",
      "rolebinding.rbac.authorization.k8s.io/prometheus-k8s created\n",
      "role.rbac.authorization.k8s.io/prometheus-k8s-config created\n",
      "role.rbac.authorization.k8s.io/prometheus-k8s created\n",
      "role.rbac.authorization.k8s.io/prometheus-k8s created\n",
      "role.rbac.authorization.k8s.io/prometheus-k8s created\n",
      "service/prometheus-k8s created\n",
      "serviceaccount/prometheus-k8s created\n",
      "servicemonitor.monitoring.coreos.com/prometheus-k8s created\n",
      "apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io configured\n",
      "clusterrole.rbac.authorization.k8s.io/prometheus-adapter created\n",
      "clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader configured\n",
      "clusterrolebinding.rbac.authorization.k8s.io/prometheus-adapter created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/resource-metrics:system:auth-delegator created\n",
      "clusterrole.rbac.authorization.k8s.io/resource-metrics-server-resources created\n",
      "configmap/adapter-config created\n",
      "deployment.apps/prometheus-adapter created\n",
      "networkpolicy.networking.k8s.io/prometheus-adapter created\n",
      "poddisruptionbudget.policy/prometheus-adapter created\n",
      "rolebinding.rbac.authorization.k8s.io/resource-metrics-auth-reader created\n",
      "service/prometheus-adapter created\n",
      "serviceaccount/prometheus-adapter created\n",
      "servicemonitor.monitoring.coreos.com/prometheus-adapter created\n",
      "clusterrole.rbac.authorization.k8s.io/prometheus-operator created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/prometheus-operator created\n",
      "deployment.apps/prometheus-operator created\n",
      "networkpolicy.networking.k8s.io/prometheus-operator created\n",
      "prometheusrule.monitoring.coreos.com/prometheus-operator-rules created\n",
      "service/prometheus-operator created\n",
      "serviceaccount/prometheus-operator created\n",
      "servicemonitor.monitoring.coreos.com/prometheus-operator created\n",
      "Étape 3/3 : Attente du démarrage de Prometheus et Grafana (peut prendre quelques minutes)...\n",
      "deployment.apps/grafana condition met\n",
      "\n",
      "--- Vérification des pods dans le namespace 'monitoring' ---\n",
      "NAME                                   READY   STATUS            RESTARTS   AGE\n",
      "alertmanager-main-0                    1/2     Running           0          25s\n",
      "alertmanager-main-1                    0/2     PodInitializing   0          25s\n",
      "alertmanager-main-2                    0/2     PodInitializing   0          25s\n",
      "blackbox-exporter-77966b4779-n2g89     3/3     Running           0          42s\n",
      "grafana-5997747455-cxs9s               1/1     Running           0          41s\n",
      "kube-state-metrics-756cd6cb9d-wrwrl    3/3     Running           0          41s\n",
      "node-exporter-2fxqc                    2/2     Running           0          40s\n",
      "node-exporter-j58zq                    2/2     Running           0          40s\n",
      "node-exporter-w6dc4                    2/2     Running           0          40s\n",
      "prometheus-adapter-5794d7d9f5-c2b4x    1/1     Running           0          40s\n",
      "prometheus-adapter-5794d7d9f5-ft59l    1/1     Running           0          40s\n",
      "prometheus-k8s-0                       0/2     Init:0/1          0          25s\n",
      "prometheus-k8s-1                       0/2     PodInitializing   0          25s\n",
      "prometheus-operator-56fd964fb9-hkrm8   2/2     Running           0          40s\n",
      "\n",
      "🎉 Suite de monitoring Prometheus et Grafana installée avec succès !\n"
     ]
    }
   ],
   "source": [
    "# Script pour déployer la suite de monitoring\n",
    "MONITORING_SCRIPT = \"\"\"\n",
    "#!/bin/bash -e\n",
    "\n",
    "echo \"--- Installation de la suite Prometheus + Grafana via kube-prometheus ---\"\n",
    "\n",
    "# 1. Cloner le dépôt qui contient les manifestes\n",
    "if [ ! -d \"kube-prometheus\" ]; then\n",
    "    echo \"Clonage du dépôt kube-prometheus...\"\n",
    "    git clone https://github.com/prometheus-operator/kube-prometheus.git\n",
    "else\n",
    "    echo \"Dépôt kube-prometheus déjà présent.\"\n",
    "fi\n",
    "cd kube-prometheus\n",
    "\n",
    "# 2. Appliquer les définitions de ressources (CRDs) et la configuration de base\n",
    "echo \"Étape 1/3 : Application des CRDs et de la configuration 'setup'...\"\n",
    "kubectl apply --server-side -f manifests/setup\n",
    "\n",
    "# Attendre que les CRDs soient bien enregistrés dans le cluster avant de continuer\n",
    "echo \"Attente de l'établissement des CRDs...\"\n",
    "kubectl wait --for condition=Established --all CustomResourceDefinition --timeout=300s\n",
    "\n",
    "# 3. Appliquer le reste de la suite (Prometheus, Grafana, Alertmanager, etc.)\n",
    "echo \"Étape 2/3 : Application des manifestes de la suite de monitoring...\"\n",
    "kubectl apply -f manifests/\n",
    "\n",
    "# 4. Attendre que les déploiements clés soient prêts dans le namespace 'monitoring'\n",
    "echo \"Étape 3/3 : Attente du démarrage de Prometheus et Grafana (peut prendre quelques minutes)...\"\n",
    "kubectl wait --for=condition=available deployment/prometheus-k8s -n monitoring --timeout=300s\n",
    "kubectl wait --for=condition=available deployment/grafana -n monitoring --timeout=300s\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification des pods dans le namespace 'monitoring' ---\"\n",
    "kubectl get pods -n monitoring\n",
    "\n",
    "echo \"\\n🎉 Suite de monitoring Prometheus et Grafana installée avec succès !\"\n",
    "\"\"\"\n",
    "\n",
    "# Exécution du script sur le master\n",
    "print(\"Lancement de l'installation de la suite de monitoring...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(MONITORING_SCRIPT)\n",
    "\n",
    "# Affichage du résultat\n",
    "print(\"\\n--- Résultat de l'installation ---\")\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43e8a1d",
   "metadata": {},
   "source": [
    "## Vérification des Composants de Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5812a18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51fc769648594ae2b544cd2c652de603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération de l'état des composants de monitoring...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-13.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-13.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pods dans le namespace 'monitoring' ---\n",
      "NAME                                   READY   STATUS    RESTARTS   AGE   IP              NODE          NOMINATED NODE   READINESS GATES\n",
      "alertmanager-main-0                    2/2     Running   0          39m   192.168.64.70   paradoxe-19   <none>           <none>\n",
      "alertmanager-main-1                    2/2     Running   0          39m   192.168.64.8    paradoxe-26   <none>           <none>\n",
      "alertmanager-main-2                    2/2     Running   0          39m   192.168.64.7    paradoxe-26   <none>           <none>\n",
      "blackbox-exporter-77966b4779-n2g89     3/3     Running   0          39m   192.168.64.3    paradoxe-26   <none>           <none>\n",
      "grafana-5997747455-cxs9s               1/1     Running   0          39m   192.168.64.68   paradoxe-19   <none>           <none>\n",
      "kube-state-metrics-756cd6cb9d-wrwrl    3/3     Running   0          39m   192.168.64.4    paradoxe-26   <none>           <none>\n",
      "node-exporter-2fxqc                    2/2     Running   0          39m   172.16.101.13   paradoxe-13   <none>           <none>\n",
      "node-exporter-j58zq                    2/2     Running   0          39m   172.16.101.19   paradoxe-19   <none>           <none>\n",
      "node-exporter-w6dc4                    2/2     Running   0          39m   172.16.101.26   paradoxe-26   <none>           <none>\n",
      "prometheus-adapter-5794d7d9f5-c2b4x    1/1     Running   0          39m   192.168.64.5    paradoxe-26   <none>           <none>\n",
      "prometheus-adapter-5794d7d9f5-ft59l    1/1     Running   0          39m   192.168.64.69   paradoxe-19   <none>           <none>\n",
      "prometheus-k8s-0                       2/2     Running   0          39m   192.168.64.9    paradoxe-26   <none>           <none>\n",
      "prometheus-k8s-1                       2/2     Running   0          39m   192.168.64.71   paradoxe-19   <none>           <none>\n",
      "prometheus-operator-56fd964fb9-hkrm8   2/2     Running   0          39m   192.168.64.6    paradoxe-26   <none>           <none>\n",
      "\n",
      "--- Services dans le namespace 'monitoring' ---\n",
      "NAME                    TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                         AGE\n",
      "alertmanager-main       ClusterIP   10.107.218.114   <none>        9093/TCP,8080/TCP               39m\n",
      "alertmanager-operated   ClusterIP   None             <none>        9093/TCP,9094/TCP,9094/UDP      39m\n",
      "blackbox-exporter       ClusterIP   10.109.154.230   <none>        9115/TCP,19115/TCP              39m\n",
      "grafana                 NodePort    10.101.166.48    <none>        3000:30877/TCP                  39m\n",
      "kube-state-metrics      ClusterIP   None             <none>        8443/TCP,9443/TCP               39m\n",
      "node-exporter           ClusterIP   None             <none>        9100/TCP                        39m\n",
      "prometheus-adapter      ClusterIP   10.103.235.134   <none>        443/TCP                         39m\n",
      "prometheus-k8s          NodePort    10.111.186.71    <none>        9090:31346/TCP,8080:31514/TCP   39m\n",
      "prometheus-operated     ClusterIP   None             <none>        9090/TCP                        39m\n",
      "prometheus-operator     ClusterIP   None             <none>        8443/TCP                        39m\n",
      "\n",
      "--- ServiceAccounts dans le namespace 'monitoring' ---\n",
      "NAME                  SECRETS   AGE\n",
      "alertmanager-main     0         39m\n",
      "blackbox-exporter     0         39m\n",
      "default               0         40m\n",
      "grafana               0         39m\n",
      "kube-state-metrics    0         39m\n",
      "node-exporter         0         39m\n",
      "prometheus-adapter    0         39m\n",
      "prometheus-k8s        0         39m\n",
      "prometheus-operator   0         39m\n"
     ]
    }
   ],
   "source": [
    "# Script pour lister les pods et services de monitoring\n",
    "VERIFY_MONITORING_SCRIPT = \"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "echo \"--- Pods dans le namespace 'monitoring' ---\"\n",
    "kubectl get pods -n monitoring -o wide\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Services dans le namespace 'monitoring' ---\"\n",
    "kubectl get services -n monitoring\n",
    "echo \"\"\n",
    "echo \"--- ServiceAccounts dans le namespace 'monitoring' ---\"\n",
    "kubectl get serviceaccounts -n monitoring\n",
    "\"\"\"\n",
    "\n",
    "# Exécution du script de vérification sur le master\n",
    "print(\"Récupération de l'état des composants de monitoring...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(VERIFY_MONITORING_SCRIPT)\n",
    "\n",
    "# Affichage du résultat\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab78fdd",
   "metadata": {},
   "source": [
    "## Mise à Jour des NetworkPolicies pour l'Accès Externe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34266c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a1539be1164fbbb8258d76788a8e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mise à jour des NetworkPolicies...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-13.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-13.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Mise à jour de la NetworkPolicy de Grafana ---\n",
      "networkpolicy.networking.k8s.io/grafana unchanged\n",
      "\n",
      "--- 2. Mise à jour de la NetworkPolicy de Prometheus ---\n",
      "networkpolicy.networking.k8s.io/prometheus-k8s configured\n",
      "\n",
      "NetworkPolicies mises à jour avec succès pour autoriser l'accès externe.\n"
     ]
    }
   ],
   "source": [
    "# Script pour mettre à jour les NetworkPolicies\n",
    "UPDATE_NP_SCRIPT = \"\"\"\n",
    "#!/bin/bash -e\n",
    "\n",
    "echo \"--- 1. Mise à jour de la NetworkPolicy de Grafana ---\"\n",
    "cat <<EOF | kubectl apply -f -\n",
    "apiVersion: networking.k8s.io/v1\n",
    "kind: NetworkPolicy\n",
    "metadata:\n",
    "  name: grafana\n",
    "  namespace: monitoring\n",
    "  labels:\n",
    "    app.kubernetes.io/component: grafana\n",
    "    app.kubernetes.io/name: grafana\n",
    "    app.kubernetes.io/part-of: kube-prometheus\n",
    "    app.kubernetes.io/version: 12.2.0\n",
    "spec:\n",
    "  podSelector:\n",
    "    matchLabels:\n",
    "      app.kubernetes.io/component: grafana\n",
    "      app.kubernetes.io/name: grafana\n",
    "      app.kubernetes.io/part-of: kube-prometheus\n",
    "  policyTypes:\n",
    "  - Ingress\n",
    "  - Egress\n",
    "  ingress:\n",
    "  - from:\n",
    "    # On autorise le trafic depuis n'importe quelle adresse IP (externe/interne)\n",
    "    - ipBlock:\n",
    "        cidr: 0.0.0.0/0\n",
    "    # On garde la règle existante qui autorise Prometheus\n",
    "    - podSelector:\n",
    "        matchLabels:\n",
    "          app.kubernetes.io/name: prometheus\n",
    "    ports:\n",
    "    - port: 3000\n",
    "      protocol: TCP\n",
    "  egress:\n",
    "  - {}\n",
    "EOF\n",
    "\n",
    "echo \"\\n--- 2. Mise à jour de la NetworkPolicy de Prometheus ---\"\n",
    "cat <<EOF | kubectl apply -f -\n",
    "apiVersion: networking.k8s.io/v1\n",
    "kind: NetworkPolicy\n",
    "metadata:\n",
    "  name: prometheus-k8s\n",
    "  namespace: monitoring\n",
    "  labels:\n",
    "    app.kubernetes.io/component: prometheus\n",
    "    app.kubernetes.io/instance: k8s\n",
    "    app.kubernetes.io/name: prometheus\n",
    "    app.kubernetes.io/part-of: kube-prometheus\n",
    "    app.kubernetes.io/version: 3.6.0\n",
    "spec:\n",
    "  podSelector:\n",
    "    matchLabels:\n",
    "      app.kubernetes.io/component: prometheus\n",
    "      app.kubernetes.io/instance: k8s\n",
    "      app.kubernetes.io/name: prometheus\n",
    "      app.kubernetes.io/part-of: kube-prometheus\n",
    "  policyTypes:\n",
    "  - Ingress\n",
    "  - Egress\n",
    "  ingress:\n",
    "  - from:\n",
    "    # On autorise le trafic depuis n'importe quelle adresse IP\n",
    "    - ipBlock:\n",
    "        cidr: 0.0.0.0/0\n",
    "    # On garde les règles existantes pour la communication interne\n",
    "    - namespaceSelector: {}\n",
    "    - podSelector:\n",
    "        matchLabels:\n",
    "          app.kubernetes.io/name: prometheus\n",
    "    - podSelector:\n",
    "        matchLabels:\n",
    "          app.kubernetes.io/name: prometheus-adapter\n",
    "    - podSelector:\n",
    "        matchLabels:\n",
    "          app.kubernetes.io/name: grafana\n",
    "    ports:\n",
    "    - port: 9090\n",
    "      protocol: TCP\n",
    "    - port: 8080\n",
    "      protocol: TCP\n",
    "  egress:\n",
    "  - {}\n",
    "EOF\n",
    "\n",
    "echo \"\\nNetworkPolicies mises à jour avec succès pour autoriser l'accès externe.\"\n",
    "\"\"\"\n",
    "\n",
    "# Exécution du script sur le master\n",
    "print(\"Mise à jour des NetworkPolicies...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(UPDATE_NP_SCRIPT)\n",
    "\n",
    "# Affichage du résultat\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0306d0cb",
   "metadata": {},
   "source": [
    "## Passage des Services en NodePort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d4963c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8dc0896075d49e380a4a280af897b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch des services Grafana et Prometheus en NodePort...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-13.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-13.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Résultat de la commande patch ---\n",
      "--- 1. Modification du service Grafana en type NodePort ---\n",
      "service/grafana patched\n",
      "\n",
      "--- 2. Modification du service Prometheus en type NodePort ---\n",
      "service/prometheus-k8s patched\n",
      "\n",
      "--- 3. Vérification du résultat ---\n",
      "NAME                    TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                         AGE\n",
      "alertmanager-main       ClusterIP   10.107.218.114   <none>        9093/TCP,8080/TCP               79s\n",
      "alertmanager-operated   ClusterIP   None             <none>        9093/TCP,9094/TCP,9094/UDP      62s\n",
      "blackbox-exporter       ClusterIP   10.109.154.230   <none>        9115/TCP,19115/TCP              79s\n",
      "grafana                 NodePort    10.101.166.48    <none>        3000:30877/TCP                  78s\n",
      "kube-state-metrics      ClusterIP   None             <none>        8443/TCP,9443/TCP               78s\n",
      "node-exporter           ClusterIP   None             <none>        9100/TCP                        77s\n",
      "prometheus-adapter      ClusterIP   10.103.235.134   <none>        443/TCP                         77s\n",
      "prometheus-k8s          NodePort    10.111.186.71    <none>        9090:31346/TCP,8080:31514/TCP   77s\n",
      "prometheus-operated     ClusterIP   None             <none>        9090/TCP                        62s\n",
      "prometheus-operator     ClusterIP   None             <none>        8443/TCP                        77s\n"
     ]
    }
   ],
   "source": [
    "# Script pour patcher les services en NodePort\n",
    "PATCH_SERVICES_SCRIPT = \"\"\"\n",
    "#!/bin/bash -e\n",
    "\n",
    "echo \"--- 1. Modification du service Grafana en type NodePort ---\"\n",
    "kubectl patch service grafana -n monitoring -p '{\"spec\": {\"type\": \"NodePort\"}}'\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 2. Modification du service Prometheus en type NodePort ---\"\n",
    "kubectl patch service prometheus-k8s -n monitoring -p '{\"spec\": {\"type\": \"NodePort\"}}'\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 3. Vérification du résultat ---\"\n",
    "# Petite pause pour s'assurer que l'API server a bien traité les changements\n",
    "sleep 2\n",
    "kubectl get services -n monitoring\n",
    "\"\"\"\n",
    "\n",
    "# Exécution du script sur le master\n",
    "print(\"Patch des services Grafana et Prometheus en NodePort...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(PATCH_SERVICES_SCRIPT)\n",
    "\n",
    "# Affichage du résultat\n",
    "print(\"\\n--- Résultat de la commande patch ---\")\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586d17f3",
   "metadata": {},
   "source": [
    "#  Installation de Kepler pour le Monitoring Énergétique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dadaf99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763bc729cd6b4cdbaa6e3e6a5bfe780b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le script d'installation final a été sauvegardé dans 'install_kepler.sh'.\n",
      "Lancement de la mise à jour de Kepler...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">script</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-13.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mscript\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-13.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helm non trouvé. Installation de Helm...\n",
      "Downloading https://get.helm.sh/helm-v3.19.0-linux-amd64.tar.gz\n",
      "Verifying checksum... Done.\n",
      "Preparing to install helm into /usr/local/bin\n",
      "helm installed into /usr/local/bin/helm\n",
      "\n",
      "--- Ajout et mise à jour du dépôt Helm de Kepler ---\n",
      "\"kepler\" has been added to your repositories\n",
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Successfully got an update from the \"kepler\" chart repository\n",
      "Update Complete. ⎈Happy Helming!⎈\n",
      "\n",
      "--- Déploiement/Mise à jour de Kepler dans le namespace 'kepler' ---\n",
      "Release \"kepler\" does not exist. Installing it now.\n",
      "NAME: kepler\n",
      "LAST DEPLOYED: Wed Oct  8 09:12:34 2025\n",
      "NAMESPACE: kepler\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "\n",
      "--- Attente des composants Kepler ---\n",
      "pod/kepler-bdhn6 condition met\n",
      "pod/kepler-c4s57 condition met\n",
      "pod/kepler-r2xkl condition met\n",
      "\n",
      "--- Vérification des pods Kepler ---\n",
      "NAME           READY   STATUS    RESTARTS   AGE\n",
      "kepler-bdhn6   1/1     Running   0          20s\n",
      "kepler-c4s57   1/1     Running   0          20s\n",
      "kepler-r2xkl   1/1     Running   0          20s\n",
      "\n",
      "--- Vérification que le ServiceMonitor a bien été créé ---\n",
      "NAME                         AGE\n",
      "kepler-prometheus-exporter   21s\n",
      "--- Vérification que le service est bien de type NodePort ---\n",
      "NAME     TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE\n",
      "kepler   NodePort   10.111.61.53   <none>        9102:30187/TCP   21s\n",
      "\n",
      "🎉 Kepler est maintenant correctement configuré avec un ServiceMonitor et un NodePort !\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Script mis à jour avec le bon paramètre pour le ServiceMonitor\n",
    "INSTALL_KEPLER_SCRIPT = \"\"\"\n",
    "#!/bin/bash -e\n",
    "\n",
    "# --- 1. Installation de Helm (si non présent) ---\n",
    "if ! command -v helm &> /dev/null\n",
    "then\n",
    "    echo \"Helm non trouvé. Installation de Helm...\"\n",
    "    curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3\n",
    "    chmod 700 get_helm.sh\n",
    "    ./get_helm.sh\n",
    "else\n",
    "    echo \"Helm est déjà installé.\"\n",
    "fi\n",
    "\n",
    "# --- 2. Ajout du dépôt Helm de Kepler ---\n",
    "echo \"\"\n",
    "echo \"--- Ajout et mise à jour du dépôt Helm de Kepler ---\"\n",
    "helm repo add kepler https://sustainable-computing-io.github.io/kepler-helm-chart\n",
    "helm repo update\n",
    "\n",
    "# --- 3. Installation ou Mise à Jour de Kepler ---\n",
    "echo \"\"\n",
    "echo \"--- Déploiement/Mise à jour de Kepler dans le namespace 'kepler' ---\"\n",
    "# CORRECTION : On utilise 'serviceMonitor.enabled=true'\n",
    "helm upgrade --install kepler kepler/kepler --namespace kepler --create-namespace \\\n",
    "    --set serviceMonitor.enabled=true \\\n",
    "    --set service.type=NodePort\n",
    "\n",
    "# --- 4. Vérification de l'installation ---\n",
    "echo \"\"\n",
    "echo \"--- Attente des composants Kepler ---\"\n",
    "kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=kepler -n kepler --timeout=300s\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification des pods Kepler ---\"\n",
    "kubectl get pods -n kepler\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification que le ServiceMonitor a bien été créé ---\"\n",
    "kubectl get servicemonitor -n kepler\n",
    "\n",
    "echo \"--- Vérification que le service est bien de type NodePort ---\"\n",
    "kubectl get service -n kepler\n",
    "\n",
    "echo \"\"\n",
    "echo \"🎉 Kepler est maintenant correctement configuré avec un ServiceMonitor et un NodePort !\"\n",
    "\"\"\"\n",
    "\n",
    "# --- Étape 1 : Enregistrer le script dans un fichier local ---\n",
    "script_path = \"install_kepler.sh\"\n",
    "with open(script_path, \"w\") as f:\n",
    "    f.write(INSTALL_KEPLER_SCRIPT)\n",
    "os.chmod(script_path, 0o755)\n",
    "print(f\"Le script d'installation final a été sauvegardé dans '{script_path}'.\")\n",
    "\n",
    "\n",
    "# --- Étape 2 : Exécuter le fichier script avec enoslib ---\n",
    "print(\"Lancement de la mise à jour de Kepler...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.script(script_path)\n",
    "\n",
    "# Affichage du résultat\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4e625f",
   "metadata": {},
   "source": [
    "## Vérification des ServiceMonitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "247cec4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa77a8f9785b4cbeb53039a29f7c3d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for ServiceMonitor resources across the cluster...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-5.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-5.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recherche des ServiceMonitors dans tous les namespaces (-A) ---\n",
      "NAMESPACE    NAME                         AGE\n",
      "kepler       kepler-prometheus-exporter   39s\n",
      "monitoring   alertmanager-main            2m39s\n",
      "monitoring   blackbox-exporter            2m39s\n",
      "monitoring   coredns                      2m38s\n",
      "monitoring   grafana                      2m38s\n",
      "monitoring   kube-apiserver               2m38s\n",
      "monitoring   kube-controller-manager      2m38s\n",
      "monitoring   kube-scheduler               2m38s\n",
      "monitoring   kube-state-metrics           2m38s\n",
      "monitoring   kubelet                      2m38s\n",
      "monitoring   node-exporter                2m38s\n",
      "monitoring   prometheus-adapter           2m37s\n",
      "monitoring   prometheus-k8s               2m38s\n",
      "monitoring   prometheus-operator          2m37s\n"
     ]
    }
   ],
   "source": [
    "# Script to list ServiceMonitors\n",
    "CHECK_SM_SCRIPT = \"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "echo \"--- Recherche des ServiceMonitors dans tous les namespaces (-A) ---\"\n",
    "kubectl get servicemonitor -A\n",
    "\"\"\"\n",
    "\n",
    "# Execute the verification script on the master node\n",
    "print(\"Checking for ServiceMonitor resources across the cluster...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(CHECK_SM_SCRIPT)\n",
    "\n",
    "# Display the result\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa1d2e5",
   "metadata": {},
   "source": [
    "## Suppression Complète de Kepler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8e17cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536e9afcf5144102a4f1b881d009d206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement de la suppression complète de Kepler...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-13.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-13.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Désinstallation de la release Helm 'kepler' ---\n",
      "NAME: kepler\n",
      "LAST DEPLOYED: Wed Oct  8 09:12:34 2025\n",
      "NAMESPACE: kepler\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "release \"kepler\" uninstalled\n",
      "\n",
      "--- 2. Suppression du ServiceMonitor dans le namespace 'monitoring' ---\n",
      "\n",
      "--- 3. Suppression du namespace 'kepler' ---\n",
      "namespace \"kepler\" deleted\n",
      "\n",
      "--- 4. Suppression du dépôt Helm de la configuration locale ---\n",
      "\"kepler\" has been removed from your repositories\n",
      "\n",
      "🎉 Nettoyage de Kepler terminé.\n"
     ]
    }
   ],
   "source": [
    "# Script pour supprimer complètement Kepler\n",
    "UNINSTALL_KEPLER_SCRIPT = \"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "echo \"--- 1. Désinstallation de la release Helm 'kepler' ---\"\n",
    "# On vérifie si la release existe avant de tenter de la supprimer\n",
    "if helm status kepler -n kepler &> /dev/null; then\n",
    "    helm uninstall kepler -n kepler\n",
    "else\n",
    "    echo \"Release Helm 'kepler' non trouvée.\"\n",
    "fi\n",
    "\n",
    "echo \"\\n--- 2. Suppression du ServiceMonitor dans le namespace 'monitoring' ---\"\n",
    "# --ignore-not-found=true évite une erreur si la ressource a déjà été supprimée\n",
    "kubectl delete servicemonitor kepler-prometheus-exporter -n monitoring --ignore-not-found=true\n",
    "\n",
    "echo \"\\n--- 3. Suppression du namespace 'kepler' ---\"\n",
    "kubectl delete namespace kepler --ignore-not-found=true\n",
    "\n",
    "echo \"\\n--- 4. Suppression du dépôt Helm de la configuration locale ---\"\n",
    "if helm repo list | grep -q \"kepler\"; then\n",
    "    helm repo remove kepler\n",
    "else\n",
    "    echo \"Dépôt Helm 'kepler' non trouvé.\"\n",
    "fi\n",
    "\n",
    "echo \"\\n🎉 Nettoyage de Kepler terminé.\"\n",
    "\"\"\"\n",
    "\n",
    "# Exécution du script de suppression sur le master\n",
    "print(\"Lancement de la suppression complète de Kepler...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(UNINSTALL_KEPLER_SCRIPT)\n",
    "\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22ef0ab",
   "metadata": {},
   "source": [
    "# Installer Kepler depuis les Manifestes Locaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7236bc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17155fd6de5445cdbf48145fbf331ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Copie du répertoire local 'kepler' vers '/tmp/kepler' sur le master... ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">copy</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-13.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mcopy\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-13.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2692f77f504b43a2a4264091a5c3d1b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répertoire copié avec succès.\n",
      "\n",
      "--- Application des manifestes sur le cluster... ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-13.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-13.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Application de tous les manifestes depuis le répertoire /tmp/kepler ---\n",
      "configmap/kepler unchanged\n",
      "daemonset.apps/kepler unchanged\n",
      "namespace/kepler unchanged\n",
      "role.rbac.authorization.k8s.io/prom-kepler unchanged\n",
      "rolebinding.rbac.authorization.k8s.io/prom-kepler unchanged\n",
      "serviceaccount/kepler unchanged\n",
      "clusterrole.rbac.authorization.k8s.io/kepler unchanged\n",
      "clusterrolebinding.rbac.authorization.k8s.io/kepler unchanged\n",
      "service/kepler unchanged\n",
      "servicemonitor.monitoring.coreos.com/kepler unchanged\n",
      "\n",
      "--- Attente de 30 secondes pour le démarrage des pods ---\n",
      "\n",
      "--- Vérification du statut des pods dans le namespace 'kepler' ---\n",
      "NAME           READY   STATUS    RESTARTS   AGE\n",
      "kepler-6hv64   1/1     Running   0          98s\n",
      "kepler-8nqbt   1/1     Running   0          98s\n",
      "kepler-tdxsq   1/1     Running   0          98s\n",
      "--- Vérification que le Service a bien été créé ---\n",
      "NAME     TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)           AGE     SELECTOR\n",
      "kepler   NodePort   10.111.96.169   <none>        28282:31515/TCP   2m50s   app.kubernetes.io/name=kepler,app.kubernetes.io/part-of=kepler\n",
      "\n",
      "🎉 Kepler a été déployé à partir des manifestes locaux.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# --- Étape 1 : Copier le répertoire local 'kepler' vers le master ---\n",
    "\n",
    "source_dir = \"kepler\"\n",
    "dest_dir = \"/tmp/kepler\"\n",
    "\n",
    "if not os.path.isdir(source_dir):\n",
    "    raise FileNotFoundError(f\"Le répertoire local '{source_dir}' est introuvable.\")\n",
    "\n",
    "print(f\"--- Copie du répertoire local '{source_dir}' vers '{dest_dir}' sur le master... ---\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.copy(src=source_dir, dest=\"/tmp/\")\n",
    "\n",
    "if p.results and p.results[0].status == \"OK\":\n",
    "    print(\"Répertoire copié avec succès.\")\n",
    "else:\n",
    "    print(\"Erreur lors de la copie du répertoire.\")\n",
    "    if p.results:\n",
    "        print(p.results[0].stderr)\n",
    "\n",
    "\n",
    "# --- Étape 2 : Appliquer les manifestes et vérifier ---\n",
    "\n",
    "# Script simplifié : la création du namespace est gérée par les manifestes\n",
    "APPLY_KEPLER_MANIFESTS_SCRIPT = f\"\"\"\n",
    "#!/bin/bash -e\n",
    "\n",
    "echo \"--- Application de tous les manifestes depuis le répertoire {dest_dir} ---\"\n",
    "kubectl apply -f \"{dest_dir}\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Attente de 30 secondes pour le démarrage des pods ---\"\n",
    "sleep 30\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification du statut des pods dans le namespace 'kepler' ---\"\n",
    "kubectl get pods -n kepler\n",
    "\n",
    "echo \"--- Vérification que le Service a bien été créé ---\"\n",
    "kubectl get svc -n kepler -o wide\n",
    "\n",
    "echo \"\"\n",
    "echo \"🎉 Kepler a été déployé à partir des manifestes locaux.\"\n",
    "\"\"\"\n",
    "\n",
    "print(f\"\\n--- Application des manifestes sur le cluster... ---\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(APPLY_KEPLER_MANIFESTS_SCRIPT)\n",
    "\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b551dc",
   "metadata": {},
   "source": [
    "## Diagnostic - Pourquoi Prometheus ne Scrape pas Kepler ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9602aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84a3a73298264035af7d35e4e629cc2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Lancement du diagnostic complet Prometheus ↔ Kepler...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">script</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-13.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mscript\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-13.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "🔍 DIAGNOSTIC COMPLET: Prometheus ↔ Kepler\n",
      "======================================================================\n",
      "\n",
      "--- 1. Vérification des Pods Kepler ---\n",
      "NAME           READY   STATUS    RESTARTS   AGE   IP              NODE          NOMINATED NODE   READINESS GATES\n",
      "kepler-6hv64   1/1     Running   0          47m   192.168.64.10   paradoxe-26   <none>           <none>\n",
      "kepler-8nqbt   1/1     Running   0          47m   192.168.0.196   paradoxe-13   <none>           <none>\n",
      "kepler-tdxsq   1/1     Running   0          47m   192.168.64.72   paradoxe-19   <none>           <none>\n",
      "\n",
      "--- 2. Vérification du Service Kepler ---\n",
      "NAME     TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)           AGE   SELECTOR\n",
      "kepler   NodePort   10.111.96.169   <none>        28282:31515/TCP   48m   app.kubernetes.io/name=kepler,app.kubernetes.io/part-of=kepler\n",
      "\n",
      "--- 3. Vérification des Labels du Service Kepler ---\n",
      "Les labels sont CRITIQUES pour que le ServiceMonitor fonctionne!\n",
      "    labels:\n",
      "      app.kubernetes.io/name: kepler\n",
      "      app.kubernetes.io/part-of: kepler\n",
      "    name: kepler\n",
      "    namespace: kepler\n",
      "    resourceVersion: \"5141\"\n",
      "    uid: 5a752599-4a3f-4d3c-b13f-658671e9b47b\n",
      "  spec:\n",
      "    clusterIP: 10.111.96.169\n",
      "    clusterIPs:\n",
      "    - 10.111.96.169\n",
      "\n",
      "--- 4. Vérification du ServiceMonitor Kepler ---\n",
      "NAME     AGE\n",
      "kepler   48m\n",
      "\n",
      "--- 5. Détails du ServiceMonitor (selector et labels) ---\n",
      "    selector:\n",
      "      matchLabels:\n",
      "        app.kubernetes.io/name: kepler\n",
      "        app.kubernetes.io/part-of: kepler\n",
      "kind: List\n",
      "metadata:\n",
      "  resourceVersion: \"\"\n",
      "\n",
      "--- 6. Vérification que Prometheus-Operator voit le ServiceMonitor ---\n",
      "Prometheus doit être dans le même namespace ou avec les bonnes règles RBAC\n",
      "NAMESPACE    NAME                      AGE\n",
      "kepler       kepler                    48m\n",
      "monitoring   alertmanager-main         78m\n",
      "monitoring   blackbox-exporter         78m\n",
      "monitoring   coredns                   78m\n",
      "monitoring   grafana                   78m\n",
      "monitoring   kube-apiserver            78m\n",
      "monitoring   kube-controller-manager   78m\n",
      "monitoring   kube-scheduler            78m\n",
      "monitoring   kube-state-metrics        78m\n",
      "monitoring   kubelet                   78m\n",
      "monitoring   node-exporter             78m\n",
      "monitoring   prometheus-adapter        78m\n",
      "monitoring   prometheus-k8s            78m\n",
      "monitoring   prometheus-operator       78m\n",
      "\n",
      "--- 7. Configuration de Prometheus pour ServiceMonitor ---\n",
      "Vérification des serviceMonitorSelector dans Prometheus:\n",
      "    serviceMonitorSelector: {}\n",
      "    version: 3.6.0\n",
      "  status:\n",
      "    availableReplicas: 2\n",
      "    conditions:\n",
      "    - lastTransitionTime: \"2025-10-08T07:38:42Z\"\n",
      "\n",
      "--- 8. Vérification des Endpoints Kepler ---\n",
      "Si pas d'endpoints, le service ne pointe vers rien!\n",
      "NAME     ENDPOINTS                                                     AGE\n",
      "kepler   192.168.0.196:28282,192.168.64.10:28282,192.168.64.72:28282   48m\n",
      "\n",
      "--- 9. Test direct du endpoint Kepler ---\n",
      "Test de l'endpoint metrics sur le pod kepler-6hv64:\n",
      "command terminated with exit code 7\n",
      "\n",
      "--- 10. Vérification des Logs Prometheus ---\n",
      "Recherche d'erreurs liées à Kepler dans les logs Prometheus:\n",
      "time=2025-10-08T08:09:45.475Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:09:45.476Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:10:19.375Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:10:19.375Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:11:02.556Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:11:02.556Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:11:44.904Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:11:44.905Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:12:28.690Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:12:28.690Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:13:16.938Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:13:16.938Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:14:07.792Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:14:07.792Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:14:43.975Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:14:43.975Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:15:22.511Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:15:22.511Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:15:57.075Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:15:57.076Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:16:54.319Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:16:54.319Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:17:32.825Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:17:32.825Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:18:21.062Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:18:21.062Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:18:52.692Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:18:52.692Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:19:40.358Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:19:40.358Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:20:38.488Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:20:38.488Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:21:29.916Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:21:29.916Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:22:07.575Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:22:07.576Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:22:45.036Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:22:45.036Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:23:44.884Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:23:44.885Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:24:16.270Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:24:16.270Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:24:48.259Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:24:48.259Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:25:25.859Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:25:25.859Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:26:05.775Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:26:05.775Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "time=2025-10-08T08:27:00.009Z level=INFO source=reflector.go:569 msg=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\" component=k8s_client_runtime\n",
      "time=2025-10-08T08:27:00.010Z level=ERROR source=reflector.go:166 msg=\"Unhandled Error\" component=k8s_client_runtime logger=UnhandledError err=\"pkg/mod/k8s.io/client-go@v0.32.3/tools/cache/reflector.go:251: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: endpointslices.discovery.k8s.io is forbidden: User \\\"system:serviceaccount:monitoring:prometheus-k8s\\\" cannot list resource \\\"endpointslices\\\" in API group \\\"discovery.k8s.io\\\" in the namespace \\\"kepler\\\"\"\n",
      "\n",
      "--- 11. Configuration Actuelle des Targets Prometheus ---\n",
      "Vérifiez si Kepler apparaît dans les targets de Prometheus\n",
      "💡 Accédez à l'UI Prometheus: Status → Targets\n",
      "💡 Ou utilisez l'API: curl http://prometheus-ip:port/api/v1/targets\n",
      "\n",
      "======================================================================\n",
      "🎯 CAUSES COMMUNES ET SOLUTIONS:\n",
      "======================================================================\n",
      "\n",
      "❌ PROBLÈME 1: Labels incompatibles\n",
      "   Le ServiceMonitor cherche des labels spécifiques sur le Service\n",
      "   Solution: Vérifiez que les labels du Service matchent le selector du ServiceMonitor\n",
      "\n",
      "❌ PROBLÈME 2: Namespace incorrect\n",
      "   Le ServiceMonitor doit être dans un namespace que Prometheus surveille\n",
      "   Solution: Soit mettre le ServiceMonitor dans 'monitoring', soit configurer Prometheus\n",
      "\n",
      "❌ PROBLÈME 3: serviceMonitorSelector vide\n",
      "   Prometheus n'est configuré pour surveiller AUCUN ServiceMonitor\n",
      "   Solution: Configurer prometheus.serviceMonitorSelector: {}\n",
      "\n",
      "❌ PROBLÈME 4: Port incorrect\n",
      "   Le ServiceMonitor pointe vers un port qui n'existe pas\n",
      "   Solution: Vérifier que le port dans ServiceMonitor = port du Service\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Script de diagnostic complet pour identifier pourquoi Prometheus ne scrape pas Kepler\n",
    "DIAGNOSTIC_KEPLER_PROMETHEUS = \"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "echo \"======================================================================\"\n",
    "echo \"🔍 DIAGNOSTIC COMPLET: Prometheus ↔ Kepler\"\n",
    "echo \"======================================================================\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 1. Vérification des Pods Kepler ---\"\n",
    "kubectl get pods -n kepler -o wide\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 2. Vérification du Service Kepler ---\"\n",
    "kubectl get svc -n kepler -o wide\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 3. Vérification des Labels du Service Kepler ---\"\n",
    "echo \"Les labels sont CRITIQUES pour que le ServiceMonitor fonctionne!\"\n",
    "kubectl get svc -n kepler -o yaml | grep -A 10 \"labels:\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 4. Vérification du ServiceMonitor Kepler ---\"\n",
    "kubectl get servicemonitor -n kepler -o wide\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 5. Détails du ServiceMonitor (selector et labels) ---\"\n",
    "kubectl get servicemonitor -n kepler -o yaml | grep -A 20 \"selector:\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 6. Vérification que Prometheus-Operator voit le ServiceMonitor ---\"\n",
    "echo \"Prometheus doit être dans le même namespace ou avec les bonnes règles RBAC\"\n",
    "kubectl get servicemonitor -A\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 7. Configuration de Prometheus pour ServiceMonitor ---\"\n",
    "echo \"Vérification des serviceMonitorSelector dans Prometheus:\"\n",
    "kubectl get prometheus -n monitoring -o yaml | grep -A 5 \"serviceMonitorSelector:\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 8. Vérification des Endpoints Kepler ---\"\n",
    "echo \"Si pas d'endpoints, le service ne pointe vers rien!\"\n",
    "kubectl get endpoints -n kepler\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 9. Test direct du endpoint Kepler ---\"\n",
    "KEPLER_POD=`kubectl get pods -n kepler -l app.kubernetes.io/name=kepler -o jsonpath='{.items[0].metadata.name}'`\n",
    "if [ -n \"$KEPLER_POD\" ]; then\n",
    "    echo \"Test de l'endpoint metrics sur le pod $KEPLER_POD:\"\n",
    "    kubectl exec -n kepler $KEPLER_POD -- curl -s localhost:9102/metrics | head -20\n",
    "else\n",
    "    echo \"❌ Aucun pod Kepler trouvé!\"\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 10. Vérification des Logs Prometheus ---\"\n",
    "echo \"Recherche d'erreurs liées à Kepler dans les logs Prometheus:\"\n",
    "PROM_POD=`kubectl get pods -n monitoring -l app.kubernetes.io/name=prometheus -o jsonpath='{.items[0].metadata.name}'`\n",
    "if [ -n \"$PROM_POD\" ]; then\n",
    "    kubectl logs -n monitoring $PROM_POD -c prometheus --tail=50 | grep -i kepler || echo \"Aucune mention de Kepler dans les logs récents\"\n",
    "else\n",
    "    echo \"❌ Pod Prometheus non trouvé!\"\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- 11. Configuration Actuelle des Targets Prometheus ---\"\n",
    "echo \"Vérifiez si Kepler apparaît dans les targets de Prometheus\"\n",
    "echo \"💡 Accédez à l'UI Prometheus: Status → Targets\"\n",
    "echo \"💡 Ou utilisez l'API: curl http://prometheus-ip:port/api/v1/targets\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"======================================================================\"\n",
    "echo \"🎯 CAUSES COMMUNES ET SOLUTIONS:\"\n",
    "echo \"======================================================================\"\n",
    "echo \"\"\n",
    "echo \"❌ PROBLÈME 1: Labels incompatibles\"\n",
    "echo \"   Le ServiceMonitor cherche des labels spécifiques sur le Service\"\n",
    "echo \"   Solution: Vérifiez que les labels du Service matchent le selector du ServiceMonitor\"\n",
    "echo \"\"\n",
    "echo \"❌ PROBLÈME 2: Namespace incorrect\"\n",
    "echo \"   Le ServiceMonitor doit être dans un namespace que Prometheus surveille\"\n",
    "echo \"   Solution: Soit mettre le ServiceMonitor dans 'monitoring', soit configurer Prometheus\"\n",
    "echo \"\"\n",
    "echo \"❌ PROBLÈME 3: serviceMonitorSelector vide\"\n",
    "echo \"   Prometheus n'est configuré pour surveiller AUCUN ServiceMonitor\"\n",
    "echo \"   Solution: Configurer prometheus.serviceMonitorSelector: {}\"\n",
    "echo \"\"\n",
    "echo \"❌ PROBLÈME 4: Port incorrect\"\n",
    "echo \"   Le ServiceMonitor pointe vers un port qui n'existe pas\"\n",
    "echo \"   Solution: Vérifier que le port dans ServiceMonitor = port du Service\"\n",
    "echo \"\"\n",
    "echo \"======================================================================\"\n",
    "\"\"\"\n",
    "\n",
    "# --- Enregistrer le script dans un fichier local ---\n",
    "script_path = \"diagnostic_kepler.sh\"\n",
    "with open(script_path, \"w\") as f:\n",
    "    f.write(DIAGNOSTIC_KEPLER_PROMETHEUS)\n",
    "os.chmod(script_path, 0o755)\n",
    "\n",
    "print(\"🔍 Lancement du diagnostic complet Prometheus ↔ Kepler...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.script(script_path)\n",
    "\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474c1d10",
   "metadata": {},
   "source": [
    "## 🔧 Solution : Donner les Permissions RBAC à Prometheus pour Kepler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d3187c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf213cc4946435ab0ab92a087091dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Application de la correction RBAC...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Finished </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> tasks</span> <span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">shell</span><span style=\"font-weight: bold; font-style: italic\">)</span> on <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'paradoxe-13.rennes.grid5000.fr'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mFinished \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m tasks\u001b[0m \u001b[1;3m(\u001b[0m\u001b[3mshell\u001b[0m\u001b[1;3m)\u001b[0m on \u001b[1m{\u001b[0m\u001b[32m'paradoxe-13.rennes.grid5000.fr'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "🔧 Correction des Permissions RBAC pour Prometheus → Kepler\n",
      "========================================================================\n",
      "\n",
      "--- Création d'un ClusterRole avec les permissions nécessaires ---\n",
      "clusterrole.rbac.authorization.k8s.io/prometheus-kepler-access created\n",
      "\n",
      "--- Liaison du ClusterRole au ServiceAccount prometheus-k8s ---\n",
      "clusterrolebinding.rbac.authorization.k8s.io/prometheus-kepler-access created\n",
      "\n",
      "--- Vérification des permissions créées ---\n",
      "NAME                       CREATED AT\n",
      "prometheus-kepler-access   2025-10-08T08:31:22Z\n",
      "NAME                       ROLE                                   AGE\n",
      "prometheus-kepler-access   ClusterRole/prometheus-kepler-access   0s\n",
      "\n",
      "--- Redémarrage des pods Prometheus pour appliquer les changements ---\n",
      "statefulset.apps/prometheus-k8s restarted\n",
      "\n",
      "--- Attente du redémarrage de Prometheus (30 secondes) ---\n",
      "\n",
      "--- Vérification que Prometheus est prêt ---\n",
      "pod/prometheus-k8s-0 condition met\n",
      "pod/prometheus-k8s-1 condition met\n",
      "\n",
      "========================================================================\n",
      "✅ Permissions RBAC configurées avec succès !\n",
      "========================================================================\n",
      "\n",
      "Prometheus peut maintenant accéder aux EndpointSlices du namespace kepler.\n",
      "Attendez 1-2 minutes puis vérifiez les targets dans l'UI Prometheus.\n"
     ]
    }
   ],
   "source": [
    "# Script pour corriger les permissions RBAC de Prometheus\n",
    "FIX_PROMETHEUS_RBAC = \"\"\"\n",
    "#!/bin/bash -e\n",
    "\n",
    "echo \"========================================================================\"\n",
    "echo \"🔧 Correction des Permissions RBAC pour Prometheus → Kepler\"\n",
    "echo \"========================================================================\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Création d'un ClusterRole avec les permissions nécessaires ---\"\n",
    "cat <<EOF | kubectl apply -f -\n",
    "apiVersion: rbac.authorization.k8s.io/v1\n",
    "kind: ClusterRole\n",
    "metadata:\n",
    "  name: prometheus-kepler-access\n",
    "rules:\n",
    "- apiGroups: [\"\"]\n",
    "  resources:\n",
    "  - services\n",
    "  - endpoints\n",
    "  - pods\n",
    "  verbs: [\"get\", \"list\", \"watch\"]\n",
    "- apiGroups: [\"discovery.k8s.io\"]\n",
    "  resources:\n",
    "  - endpointslices\n",
    "  verbs: [\"get\", \"list\", \"watch\"]\n",
    "EOF\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Liaison du ClusterRole au ServiceAccount prometheus-k8s ---\"\n",
    "cat <<EOF | kubectl apply -f -\n",
    "apiVersion: rbac.authorization.k8s.io/v1\n",
    "kind: ClusterRoleBinding\n",
    "metadata:\n",
    "  name: prometheus-kepler-access\n",
    "roleRef:\n",
    "  apiGroup: rbac.authorization.k8s.io\n",
    "  kind: ClusterRole\n",
    "  name: prometheus-kepler-access\n",
    "subjects:\n",
    "- kind: ServiceAccount\n",
    "  name: prometheus-k8s\n",
    "  namespace: monitoring\n",
    "EOF\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification des permissions créées ---\"\n",
    "kubectl get clusterrole prometheus-kepler-access\n",
    "kubectl get clusterrolebinding prometheus-kepler-access\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Redémarrage des pods Prometheus pour appliquer les changements ---\"\n",
    "kubectl rollout restart statefulset prometheus-k8s -n monitoring\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Attente du redémarrage de Prometheus (30 secondes) ---\"\n",
    "sleep 30\n",
    "\n",
    "echo \"\"\n",
    "echo \"--- Vérification que Prometheus est prêt ---\"\n",
    "kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=prometheus -n monitoring --timeout=120s\n",
    "\n",
    "echo \"\"\n",
    "echo \"========================================================================\"\n",
    "echo \"✅ Permissions RBAC configurées avec succès !\"\n",
    "echo \"========================================================================\"\n",
    "echo \"\"\n",
    "echo \"Prometheus peut maintenant accéder aux EndpointSlices du namespace kepler.\"\n",
    "echo \"Attendez 1-2 minutes puis vérifiez les targets dans l'UI Prometheus.\"\n",
    "\"\"\"\n",
    "\n",
    "print(\"🔧 Application de la correction RBAC...\")\n",
    "with en.actions(roles=master_node) as p:\n",
    "    p.shell(FIX_PROMETHEUS_RBAC)\n",
    "\n",
    "if p.results:\n",
    "    output = p.results[0].stdout.strip()\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2797649d",
   "metadata": {},
   "source": [
    "# # Libération des Ressources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cf720446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libération des ressources sur Grid'5000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:enoslib.log:[G5k] Reloading 3292322 from rennes\n",
      "INFO:enoslib.log:[G5k] Killing the job (rennes, 3292322)\n",
      "INFO:enoslib.log:[G5k] Killing the job (rennes, 3292322)\n",
      "INFO:enoslib.log:[G5k] Job killed (rennes, 3292322)\n",
      "INFO:enoslib.log:[G5k] Job killed (rennes, 3292322)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ressources libérées. ✅\n"
     ]
    }
   ],
   "source": [
    "# Destruction de la réservation\n",
    "print(\"Libération des ressources sur Grid'5000...\")\n",
    "provider.destroy()\n",
    "print(\"Ressources libérées. ✅\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
